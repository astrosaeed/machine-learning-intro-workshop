{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/misc/pyspark_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2enqLgx-JY-",
        "colab_type": "text"
      },
      "source": [
        "## Running Pyspark in Colab\n",
        "\n",
        "To run spark in Colab, first we need to install all the dependencies in Colab environment such as Apache Spark 2.3.2 with hadoop 2.7, Java 8 and Findspark in order to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBBrFKEO-Hbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IPAj_OU-yAT",
        "colab_type": "text"
      },
      "source": [
        "**Note!** This was out of date and had to be updated from [apache spark](https://www-us.apache.org/dist/spark) to 2.4.3 form 2.4.1 before it would install.\n",
        "\n",
        "Now that we have installed Spark and Java in Colab, it is time to set the environment path that enables us to run PySpark in our Colab environment. Set the location of Java and Spark by running the following code:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajkStZmO-RAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "SPARK_HOME = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "\n",
        "def set_os_environ_path(var, val):\n",
        "    os.environ[var] = val\n",
        "    if not os.path.exists(JAVA_HOME):\n",
        "        print(f\"** Yikes! the {var} path {val} does not exist!  Your environment is not valid.\")\n",
        "\n",
        "set_os_environ_path(\"JAVA_HOME\",  JAVA_HOME)\n",
        "set_os_environ_path(\"SPARK_HOME\", SPARK_HOME)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trgpNBGF_d0U",
        "colab_type": "text"
      },
      "source": [
        "**Note!** You **must** check these paths in the **Files** tab on the left side of your notebook page.  \n",
        "\n",
        "We can run a local spark session to test our installation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdScQTEJBI49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uAJ2Kb5_d_z",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression Model\n",
        "\n",
        "Linear Regression model is one the oldest and widely used machine learning approach which assumes a relationship between dependent and independent variables. For example, a modeler might want to predict the forecast of the rain based on the humidity ratio. Linear Regression consists of the best fitting line through the scattered points on the graph and the best fitting line is known as the regression line. Detailed about linear regression can be found here.\n",
        "\n",
        "For our purpose of starting with Pyspark in Colab and to keep things simple, we will use the famous Boston Housing dataset. A full description of this dataset can be found in this [link](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nql50GkBek2",
        "colab_type": "text"
      },
      "source": [
        "### The Boston Housing Dataset\n",
        "\n",
        "A Dataset derived from information collected by the U.S. Census Service concerning housing in the area of Boston Mass.\n",
        "BackUpDelve\n",
        "\n",
        "This dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the [StatLib archive](http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms. However, these comparisons were primarily done outside of Delve and are thus somewhat suspect. The dataset is small in size with only 506 cases.\n",
        "\n",
        "The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.\n",
        "\n",
        "#### Dataset Naming\n",
        "The name for this dataset is simply boston. It has two prototasks: nox, in which the nitrous oxide level is to be predicted; and price, in which the median value of a home is to be predicted\n",
        "\n",
        "#### Miscellaneous Details\n",
        "\n",
        "- Origin : The origin of the boston housing data is Natural.\n",
        "- Usage : This dataset may be used for Assessment.\n",
        "- Number of Cases : The dataset contains a total of 506 cases.\n",
        "- Order : The order of the cases is mysterious.\n",
        "- Variables : There are 14 attributes in each case of the dataset. They are:\n",
        "  - CRIM - per capita crime rate by town\n",
        "  - ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "  - INDUS - proportion of non-retail business acres per town.\n",
        "  - CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
        "  - NOX - nitric oxides concentration (parts per 10 million)\n",
        "  - RM - average number of rooms per dwelling\n",
        "  - AGE - proportion of owner-occupied units built prior to 1940\n",
        "  - DIS - weighted distances to five Boston employment centres\n",
        "  - RAD - index of accessibility to radial highways\n",
        "  - TAX - full-value property-tax rate per 10,000 dollars\n",
        "  - PTRATIO - pupil-teacher ratio by town\n",
        "  - B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "  - LSTAT - % lower status of the population\n",
        "  - MEDV - Median value of owner-occupied homes in $1000's\n",
        "\n",
        "- Note : Variable #14 seems to be censored at 50.00 \\(corresponding to a median price of 50,000 dollars);\n",
        "\n",
        " Censoring is suggested by the fact that the highest median price of exactly 50,000 dollars is reported in 16 cases, while 15 cases have prices between 40,000 dollars  and 50,000 dollars , with prices rounded to the nearest hundred. Harrison and Rubinfeld do not mention any censoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-qkvCx2_eC7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB34REKQ-SCL",
        "colab_type": "text"
      },
      "source": [
        "### End of notebook."
      ]
    }
  ]
}