{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/misc/mask-rcnn-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBR2HwYNqLRl",
        "colab_type": "text"
      },
      "source": [
        "# Mask R-CNN Demo\n",
        "\n",
        "A quick intro to using the pre-trained model to detect and segment objects.\n",
        "\n",
        "- [Converted from github to run standalone in Colab](https://github.com/matterport/Mask_RCNN/blob/master/samples/demo.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQd_2gZ6j_aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77EpaSvOkaQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9a77dcf3-68a0-4ddc-9f5d-de7b8c89b029"
      },
      "source": [
        "!pip install mrcnn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mrcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/3d/56e05c297a1f464a042b2c47bcd9e5f2d452ce0e5eca3894f7cbdcaee758/mrcnn-0.2.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mrcnn\n",
            "  Building wheel for mrcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mrcnn: filename=mrcnn-0.2-cp36-none-any.whl size=54932 sha256=35cf8def28f9c45e1f78628343d20b3238dfa38e58524213bdb5cf5e433fca5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/ed/28/e550ddc897c04c336b923eae4eb35c9aae993d20ce39d9cc40\n",
            "Successfully built mrcnn\n",
            "Installing collected packages: mrcnn\n",
            "Successfully installed mrcnn-0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDIvdfJhln-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ca1af4b5-a110-430b-ea7a-e0832e40ec2a"
      },
      "source": [
        "!pip install imgaug"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.0.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.6.4.post2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.4.7.28)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.3.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.16.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.5.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->imgaug) (0.46)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.0.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (41.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0whIZ3ZkDup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Mask RCNN\n",
        "\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.config import Config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iShyOHDklWH3",
        "colab_type": "text"
      },
      "source": [
        "## Configurations and data loading code for MS COCO.\n",
        "\n",
        "\n",
        "Copyright (c) 2017 Matterport, Inc.\n",
        "Licensed under the MIT License (see LICENSE for details)\n",
        "Written by Waleed Abdulla\n",
        "\n",
        "- [Imported and reformatted from ](https://github.com/matterport/Mask_RCNN/blob/master/samples/coco/coco.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-WskLDskSVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
        "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
        "# fix for Python 3.\n",
        "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
        "# If the PR is merged then use the original repo.\n",
        "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from pycocotools import mask as maskUtils\n",
        "\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf7HZTH9o4da",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "431e43e2-7dbe-481e-ef99-6ccaa9e5e245"
      },
      "source": [
        "cwd = os.getcwd()!wget 'https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-30 19:26:57--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190930T192658Z&X-Amz-Expires=300&X-Amz-Signature=d459e6e38862926f1b5721fa60fa0effe9ef6f435f1b7efd5f590fff12b29618&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-09-30 19:26:58--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190930T192658Z&X-Amz-Expires=300&X-Amz-Signature=d459e6e38862926f1b5721fa60fa0effe9ef6f435f1b7efd5f590fff12b29618&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.8.11\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.8.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco.h5’\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  33.5MB/s    in 7.9s    \n",
            "\n",
            "2019-09-30 19:27:06 (30.9 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wmuP_dAkfdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a1d682b-1c83-4fc9-d878-6cc740b1d5c8"
      },
      "source": [
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "DEFAULT_DATASET_YEAR = \"2014\"\n",
        "\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    print(f\"*** Failed! Sorry, the COCO model ({COCO_MODEL_PATH}) was not loaded!\")\n",
        "else:\n",
        "    print(f\"- The COCO model is {os.path.getsize(COCO_MODEL_PATH)} bytes.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- The COCO model is 257557808 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uit6nTdnP1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d486846b-c1f3-417b-d07b-fdf69e5e3250"
      },
      "source": [
        "COCO_MODEL_PATH"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mask_rcnn_coco.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV7xS2OJmbWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "\n",
        "class CocoConfig(Config):\n",
        "    \"\"\"Configuration for training on MS COCO.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the COCO dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"coco\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Uncomment to train on 8 GPUs (default is 1)\n",
        "    # GPU_COUNT = 8\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 80  # COCO has 80 classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6tmc2fOmdft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class CocoDataset(utils.Dataset):\n",
        "    def load_coco(self, dataset_dir, subset, year=DEFAULT_DATASET_YEAR, class_ids=None,\n",
        "                  class_map=None, return_coco=False, auto_download=False):\n",
        "        \"\"\"Load a subset of the COCO dataset.\n",
        "        dataset_dir: The root directory of the COCO dataset.\n",
        "        subset: What to load (train, val, minival, valminusminival)\n",
        "        year: What dataset year to load (2014, 2017) as a string, not an integer\n",
        "        class_ids: If provided, only loads images that have the given classes.\n",
        "        class_map: TODO: Not implemented yet. Supports maping classes from\n",
        "            different datasets to the same class ID.\n",
        "        return_coco: If True, returns the COCO object.\n",
        "        auto_download: Automatically download and unzip MS-COCO images and annotations\n",
        "        \"\"\"\n",
        "\n",
        "        if auto_download is True:\n",
        "            self.auto_download(dataset_dir, subset, year)\n",
        "\n",
        "        coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, subset, year))\n",
        "        if subset == \"minival\" or subset == \"valminusminival\":\n",
        "            subset = \"val\"\n",
        "        image_dir = \"{}/{}{}\".format(dataset_dir, subset, year)\n",
        "\n",
        "        # Load all classes or a subset?\n",
        "        if not class_ids:\n",
        "            # All classes\n",
        "            class_ids = sorted(coco.getCatIds())\n",
        "\n",
        "        # All images or a subset?\n",
        "        if class_ids:\n",
        "            image_ids = []\n",
        "            for id in class_ids:\n",
        "                image_ids.extend(list(coco.getImgIds(catIds=[id])))\n",
        "            # Remove duplicates\n",
        "            image_ids = list(set(image_ids))\n",
        "        else:\n",
        "            # All images\n",
        "            image_ids = list(coco.imgs.keys())\n",
        "\n",
        "        # Add classes\n",
        "        for i in class_ids:\n",
        "            self.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])\n",
        "\n",
        "        # Add images\n",
        "        for i in image_ids:\n",
        "            self.add_image(\n",
        "                \"coco\", image_id=i,\n",
        "                path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
        "                width=coco.imgs[i][\"width\"],\n",
        "                height=coco.imgs[i][\"height\"],\n",
        "                annotations=coco.loadAnns(coco.getAnnIds(\n",
        "                    imgIds=[i], catIds=class_ids, iscrowd=None)))\n",
        "        if return_coco:\n",
        "            return coco\n",
        "\n",
        "    def auto_download(self, dataDir, dataType, dataYear):\n",
        "        \"\"\"Download the COCO dataset/annotations if requested.\n",
        "        dataDir: The root directory of the COCO dataset.\n",
        "        dataType: What to load (train, val, minival, valminusminival)\n",
        "        dataYear: What dataset year to load (2014, 2017) as a string, not an integer\n",
        "        Note:\n",
        "            For 2014, use \"train\", \"val\", \"minival\", or \"valminusminival\"\n",
        "            For 2017, only \"train\" and \"val\" annotations are available\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup paths and file names\n",
        "        if dataType == \"minival\" or dataType == \"valminusminival\":\n",
        "            imgDir = \"{}/{}{}\".format(dataDir, \"val\", dataYear)\n",
        "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, \"val\", dataYear)\n",
        "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(\"val\", dataYear)\n",
        "        else:\n",
        "            imgDir = \"{}/{}{}\".format(dataDir, dataType, dataYear)\n",
        "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, dataType, dataYear)\n",
        "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(dataType, dataYear)\n",
        "        # print(\"Image paths:\"); print(imgDir); print(imgZipFile); print(imgURL)\n",
        "\n",
        "        # Create main folder if it doesn't exist yet\n",
        "        if not os.path.exists(dataDir):\n",
        "            os.makedirs(dataDir)\n",
        "\n",
        "        # Download images if not available locally\n",
        "        if not os.path.exists(imgDir):\n",
        "            os.makedirs(imgDir)\n",
        "            print(\"Downloading images to \" + imgZipFile + \" ...\")\n",
        "            with urllib.request.urlopen(imgURL) as resp, open(imgZipFile, 'wb') as out:\n",
        "                shutil.copyfileobj(resp, out)\n",
        "            print(\"... done downloading.\")\n",
        "            print(\"Unzipping \" + imgZipFile)\n",
        "            with zipfile.ZipFile(imgZipFile, \"r\") as zip_ref:\n",
        "                zip_ref.extractall(dataDir)\n",
        "            print(\"... done unzipping\")\n",
        "        print(\"Will use images in \" + imgDir)\n",
        "\n",
        "        # Setup annotations data paths\n",
        "        annDir = \"{}/annotations\".format(dataDir)\n",
        "        if dataType == \"minival\":\n",
        "            annZipFile = \"{}/instances_minival2014.json.zip\".format(dataDir)\n",
        "            annFile = \"{}/instances_minival2014.json\".format(annDir)\n",
        "            annURL = \"https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0\"\n",
        "            unZipDir = annDir\n",
        "        elif dataType == \"valminusminival\":\n",
        "            annZipFile = \"{}/instances_valminusminival2014.json.zip\".format(dataDir)\n",
        "            annFile = \"{}/instances_valminusminival2014.json\".format(annDir)\n",
        "            annURL = \"https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0\"\n",
        "            unZipDir = annDir\n",
        "        else:\n",
        "            annZipFile = \"{}/annotations_trainval{}.zip\".format(dataDir, dataYear)\n",
        "            annFile = \"{}/instances_{}{}.json\".format(annDir, dataType, dataYear)\n",
        "            annURL = \"http://images.cocodataset.org/annotations/annotations_trainval{}.zip\".format(dataYear)\n",
        "            unZipDir = dataDir\n",
        "        # print(\"Annotations paths:\"); print(annDir); print(annFile); print(annZipFile); print(annURL)\n",
        "\n",
        "        # Download annotations if not available locally\n",
        "        if not os.path.exists(annDir):\n",
        "            os.makedirs(annDir)\n",
        "        if not os.path.exists(annFile):\n",
        "            if not os.path.exists(annZipFile):\n",
        "                print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n",
        "                with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n",
        "                    shutil.copyfileobj(resp, out)\n",
        "                print(\"... done downloading.\")\n",
        "            print(\"Unzipping \" + annZipFile)\n",
        "            with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n",
        "                zip_ref.extractall(unZipDir)\n",
        "            print(\"... done unzipping\")\n",
        "        print(\"Will use annotations in \" + annFile)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Load instance masks for the given image.\n",
        "        Different datasets use different ways to store masks. This\n",
        "        function converts the different mask format to one format\n",
        "        in the form of a bitmap [height, width, instances].\n",
        "        Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        # If not a COCO image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"coco\":\n",
        "            return super(CocoDataset, self).load_mask(image_id)\n",
        "\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        annotations = self.image_info[image_id][\"annotations\"]\n",
        "        # Build mask of shape [height, width, instance_count] and list\n",
        "        # of class IDs that correspond to each channel of the mask.\n",
        "        for annotation in annotations:\n",
        "            class_id = self.map_source_class_id(\n",
        "                \"coco.{}\".format(annotation['category_id']))\n",
        "            if class_id:\n",
        "                m = self.annToMask(annotation, image_info[\"height\"],\n",
        "                                   image_info[\"width\"])\n",
        "                # Some objects are so small that they're less than 1 pixel area\n",
        "                # and end up rounded out. Skip those objects.\n",
        "                if m.max() < 1:\n",
        "                    continue\n",
        "                # Is it a crowd? If so, use a negative class ID.\n",
        "                if annotation['iscrowd']:\n",
        "                    # Use negative class ID for crowds\n",
        "                    class_id *= -1\n",
        "                    # For crowd masks, annToMask() sometimes returns a mask\n",
        "                    # smaller than the given dimensions. If so, resize it.\n",
        "                    if m.shape[0] != image_info[\"height\"] or m.shape[1] != image_info[\"width\"]:\n",
        "                        m = np.ones([image_info[\"height\"], image_info[\"width\"]], dtype=bool)\n",
        "                instance_masks.append(m)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        # Pack instance masks into an array\n",
        "        if class_ids:\n",
        "            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n",
        "            class_ids = np.array(class_ids, dtype=np.int32)\n",
        "            return mask, class_ids\n",
        "        else:\n",
        "            # Call super class to return an empty mask\n",
        "            return super(CocoDataset, self).load_mask(image_id)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return a link to the image in the COCO Website.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"coco\":\n",
        "            return \"http://cocodataset.org/#explore?id={}\".format(info[\"id\"])\n",
        "        else:\n",
        "            super(CocoDataset, self).image_reference(image_id)\n",
        "\n",
        "    # The following two functions are from pycocotools with a few changes.\n",
        "\n",
        "    def annToRLE(self, ann, height, width):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        segm = ann['segmentation']\n",
        "        if isinstance(segm, list):\n",
        "            # polygon -- a single object might consist of multiple parts\n",
        "            # we merge all parts into one mask rle code\n",
        "            rles = maskUtils.frPyObjects(segm, height, width)\n",
        "            rle = maskUtils.merge(rles)\n",
        "        elif isinstance(segm['counts'], list):\n",
        "            # uncompressed RLE\n",
        "            rle = maskUtils.frPyObjects(segm, height, width)\n",
        "        else:\n",
        "            # rle\n",
        "            rle = ann['segmentation']\n",
        "        return rle\n",
        "\n",
        "    def annToMask(self, ann, height, width):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        rle = self.annToRLE(ann, height, width)\n",
        "        m = maskUtils.decode(rle)\n",
        "        return m\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om5mjR44mknd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "############################################################\n",
        "#  COCO Evaluation\n",
        "############################################################\n",
        "\n",
        "def build_coco_results(dataset, image_ids, rois, class_ids, scores, masks):\n",
        "    \"\"\"Arrange resutls to match COCO specs in http://cocodataset.org/#format\n",
        "    \"\"\"\n",
        "    # If no results, return an empty list\n",
        "    if rois is None:\n",
        "        return []\n",
        "\n",
        "    results = []\n",
        "    for image_id in image_ids:\n",
        "        # Loop through detections\n",
        "        for i in range(rois.shape[0]):\n",
        "            class_id = class_ids[i]\n",
        "            score = scores[i]\n",
        "            bbox = np.around(rois[i], 1)\n",
        "            mask = masks[:, :, i]\n",
        "\n",
        "            result = {\n",
        "                \"image_id\": image_id,\n",
        "                \"category_id\": dataset.get_source_class_id(class_id, \"coco\"),\n",
        "                \"bbox\": [bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0]],\n",
        "                \"score\": score,\n",
        "                \"segmentation\": maskUtils.encode(np.asfortranarray(mask))\n",
        "            }\n",
        "            results.append(result)\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate_coco(model, dataset, coco, eval_type=\"bbox\", limit=0, image_ids=None):\n",
        "    \"\"\"Runs official COCO evaluation.\n",
        "    dataset: A Dataset object with valiadtion data\n",
        "    eval_type: \"bbox\" or \"segm\" for bounding box or segmentation evaluation\n",
        "    limit: if not 0, it's the number of images to use for evaluation\n",
        "    \"\"\"\n",
        "    # Pick COCO images from the dataset\n",
        "    image_ids = image_ids or dataset.image_ids\n",
        "\n",
        "    # Limit to a subset\n",
        "    if limit:\n",
        "        image_ids = image_ids[:limit]\n",
        "\n",
        "    # Get corresponding COCO image IDs.\n",
        "    coco_image_ids = [dataset.image_info[id][\"id\"] for id in image_ids]\n",
        "\n",
        "    t_prediction = 0\n",
        "    t_start = time.time()\n",
        "\n",
        "    results = []\n",
        "    for i, image_id in enumerate(image_ids):\n",
        "        # Load image\n",
        "        image = dataset.load_image(image_id)\n",
        "\n",
        "        # Run detection\n",
        "        t = time.time()\n",
        "        r = model.detect([image], verbose=0)[0]\n",
        "        t_prediction += (time.time() - t)\n",
        "\n",
        "        # Convert results to COCO format\n",
        "        # Cast masks to uint8 because COCO tools errors out on bool\n",
        "        image_results = build_coco_results(dataset, coco_image_ids[i:i + 1],\n",
        "                                           r[\"rois\"], r[\"class_ids\"],\n",
        "                                           r[\"scores\"],\n",
        "                                           r[\"masks\"].astype(np.uint8))\n",
        "        results.extend(image_results)\n",
        "\n",
        "    # Load results. This modifies results with additional attributes.\n",
        "    coco_results = coco.loadRes(results)\n",
        "\n",
        "    # Evaluate\n",
        "    cocoEval = COCOeval(coco, coco_results, eval_type)\n",
        "    cocoEval.params.imgIds = coco_image_ids\n",
        "    cocoEval.evaluate()\n",
        "    cocoEval.accumulate()\n",
        "    cocoEval.summarize()\n",
        "\n",
        "    print(\"Prediction time: {}. Average {}/image\".format(\n",
        "        t_prediction, t_prediction / len(image_ids)))\n",
        "    print(\"Total time: \", time.time() - t_start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i2zUlNJmqhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "############################################################\n",
        "#  Training\n",
        "############################################################\n",
        "\n",
        "def main_coco_train():\n",
        "    import argparse\n",
        "\n",
        "    # Parse command line arguments\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Train Mask R-CNN on MS COCO.')\n",
        "    parser.add_argument(\"command\",\n",
        "                        metavar=\"<command>\",\n",
        "                        help=\"'train' or 'evaluate' on MS COCO\")\n",
        "    parser.add_argument('--dataset', required=True,\n",
        "                        metavar=\"/path/to/coco/\",\n",
        "                        help='Directory of the MS-COCO dataset')\n",
        "    parser.add_argument('--year', required=False,\n",
        "                        default=DEFAULT_DATASET_YEAR,\n",
        "                        metavar=\"<year>\",\n",
        "                        help='Year of the MS-COCO dataset (2014 or 2017) (default=2014)')\n",
        "    parser.add_argument('--model', required=True,\n",
        "                        metavar=\"/path/to/weights.h5\",\n",
        "                        help=\"Path to weights .h5 file or 'coco'\")\n",
        "    parser.add_argument('--logs', required=False,\n",
        "                        default=DEFAULT_LOGS_DIR,\n",
        "                        metavar=\"/path/to/logs/\",\n",
        "                        help='Logs and checkpoints directory (default=logs/)')\n",
        "    parser.add_argument('--limit', required=False,\n",
        "                        default=500,\n",
        "                        metavar=\"<image count>\",\n",
        "                        help='Images to use for evaluation (default=500)')\n",
        "    parser.add_argument('--download', required=False,\n",
        "                        default=False,\n",
        "                        metavar=\"<True|False>\",\n",
        "                        help='Automatically download and unzip MS-COCO files (default=False)',\n",
        "                        type=bool)\n",
        "    args = parser.parse_args()\n",
        "    print(\"Command: \", args.command)\n",
        "    print(\"Model: \", args.model)\n",
        "    print(\"Dataset: \", args.dataset)\n",
        "    print(\"Year: \", args.year)\n",
        "    print(\"Logs: \", args.logs)\n",
        "    print(\"Auto Download: \", args.download)\n",
        "\n",
        "    # Configurations\n",
        "    if args.command == \"train\":\n",
        "        config = CocoConfig()\n",
        "    else:\n",
        "        class InferenceConfig(CocoConfig):\n",
        "            # Set batch size to 1 since we'll be running inference on\n",
        "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "            GPU_COUNT = 1\n",
        "            IMAGES_PER_GPU = 1\n",
        "            DETECTION_MIN_CONFIDENCE = 0\n",
        "        config = InferenceConfig()\n",
        "    config.display()\n",
        "\n",
        "    # Create model\n",
        "    if args.command == \"train\":\n",
        "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=args.logs)\n",
        "    else:\n",
        "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                                  model_dir=args.logs)\n",
        "\n",
        "    # Select weights file to load\n",
        "    if args.model.lower() == \"coco\":\n",
        "        model_path = COCO_MODEL_PATH\n",
        "    elif args.model.lower() == \"last\":\n",
        "        # Find last trained weights\n",
        "        model_path = model.find_last()\n",
        "    elif args.model.lower() == \"imagenet\":\n",
        "        # Start from ImageNet trained weights\n",
        "        model_path = model.get_imagenet_weights()\n",
        "    else:\n",
        "        model_path = args.model\n",
        "\n",
        "    # Load weights\n",
        "    print(\"Loading weights \", model_path)\n",
        "    model.load_weights(model_path, by_name=True)\n",
        "\n",
        "    # Train or evaluate\n",
        "    if args.command == \"train\":\n",
        "        # Training dataset. Use the training set and 35K from the\n",
        "        # validation set, as as in the Mask RCNN paper.\n",
        "        dataset_train = CocoDataset()\n",
        "        dataset_train.load_coco(args.dataset, \"train\", year=args.year, auto_download=args.download)\n",
        "        if args.year in '2014':\n",
        "            dataset_train.load_coco(args.dataset, \"valminusminival\", year=args.year, auto_download=args.download)\n",
        "        dataset_train.prepare()\n",
        "\n",
        "        # Validation dataset\n",
        "        dataset_val = CocoDataset()\n",
        "        val_type = \"val\" if args.year in '2017' else \"minival\"\n",
        "        dataset_val.load_coco(args.dataset, val_type, year=args.year, auto_download=args.download)\n",
        "        dataset_val.prepare()\n",
        "\n",
        "        # Image Augmentation\n",
        "        # Right/Left flip 50% of the time\n",
        "        augmentation = imgaug.augmenters.Fliplr(0.5)\n",
        "\n",
        "        # *** This training schedule is an example. Update to your needs ***\n",
        "\n",
        "        # Training - Stage 1\n",
        "        print(\"Training network heads\")\n",
        "        model.train(dataset_train, dataset_val,\n",
        "                    learning_rate=config.LEARNING_RATE,\n",
        "                    epochs=40,\n",
        "                    layers='heads',\n",
        "                    augmentation=augmentation)\n",
        "\n",
        "        # Training - Stage 2\n",
        "        # Finetune layers from ResNet stage 4 and up\n",
        "        print(\"Fine tune Resnet stage 4 and up\")\n",
        "        model.train(dataset_train, dataset_val,\n",
        "                    learning_rate=config.LEARNING_RATE,\n",
        "                    epochs=120,\n",
        "                    layers='4+',\n",
        "                    augmentation=augmentation)\n",
        "\n",
        "        # Training - Stage 3\n",
        "        # Fine tune all layers\n",
        "        print(\"Fine tune all layers\")\n",
        "        model.train(dataset_train, dataset_val,\n",
        "                    learning_rate=config.LEARNING_RATE / 10,\n",
        "                    epochs=160,\n",
        "                    layers='all',\n",
        "                    augmentation=augmentation)\n",
        "\n",
        "    elif args.command == \"evaluate\":\n",
        "        # Validation dataset\n",
        "        dataset_val = CocoDataset()\n",
        "        val_type = \"val\" if args.year in '2017' else \"minival\"\n",
        "        coco = dataset_val.load_coco(args.dataset, val_type, year=args.year, return_coco=True, auto_download=args.download)\n",
        "        dataset_val.prepare()\n",
        "        print(\"Running COCO evaluation on {} images.\".format(args.limit))\n",
        "        evaluate_coco(model, dataset_val, coco, \"bbox\", limit=int(args.limit))\n",
        "    else:\n",
        "        print(\"'{}' is not recognized. \"\n",
        "              \"Use 'train' or 'evaluate'\".format(args.command))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO5TI_Kzm8_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}