{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/misc/beyond_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uiafOlBb4iIq"
   },
   "source": [
    "# Beyond Gradient Descent\n",
    "\n",
    "- From [Why Gradient descent isn’t enough: A comprehensive introduction to optimization algorithms in neural networks](https://towardsdatascience.com/why-gradient-descent-isnt-enough-a-comprehensive-introduction-to-optimization-algorithms-in-59670fd5c096) in [towardsdatascience.com](https://towardsdatascience.com/) by [vikashraj luhaniwal](https://towardsdatascience.com/@vikashrajluhaniwal?source=post_page-----59670fd5c096----------------------)\n",
    "\n",
    "\n",
    "Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ii-L94B5SN0"
   },
   "source": [
    "The goal of neural networks is to minimize the loss, for producing better and accurate results. In order to minimize the loss, we need to update the internal learning parameters(especially **weights** and **biases**). These parameters are updated based on some *update rule/function*. Generally, we think about **Gradient descent** as an update rule. Now two types of questions arise w.r.t parameters update.\n",
    "\n",
    "- How much/what data should be used for an update?\n",
    "\n",
    "- What update rule should be used?\n",
    "\n",
    "This post revolves around these two questions and answers in the simplest way in the context of better optimization. In this post, I will present an intuitive vision of optimization algorithms, their different types, and variants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27dAdHMU5SRq"
   },
   "source": [
    "### *Additional NOTE*\n",
    "\n",
    "> *This article assumes that the reader has basic knowledge about the concept of the neural network, forward and backward propagation, weight initalization, activation functions, etc. In case you are not familiar then I would recommend you to follow my other articles on these topics.*\n",
    "\n",
    "- [Forward propagation in neural networks — Simplified math and code version](https://towardsdatascience.com/forward-propagation-in-neural-networks-simplified-math-and-code-version-bbcfef6f9250)\n",
    "\n",
    "- [Why better weight initialization is important in neural networks?](https://towardsdatascience.com/why-better-weight-initialization-is-important-in-neural-networks-ff9acf01026d)\n",
    "\n",
    "- [Analyzing different types of activation functions in neural networks — which one to prefer?](https://towardsdatascience.com/analyzing-different-types-of-activation-functions-in-neural-networks-which-one-to-prefer-e11649256209)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guFlFkpW5SWj"
   },
   "source": [
    "## Optimization algorithms\n",
    "\n",
    "An Optimization algorithm tries to minimize the **loss(cost)** by following some update rule. The loss is a *mathematical* function denoting the difference between the **predicted value** and *actual value*. Loss is dependent on the actual value which is derived with the help of **learning parameters** (**weights** and **biases**) and *inputs*. Therefore learning *parameters* are very important for better training and producing accurate results. To find out the optimal value of these parameters we need to continuously update them. There should be some update rule for this purpose. So we use various **optimization algorithms** to follow some update rule and each optimization algorithm has a different approach to calculate, update and find out the optimal value of model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10N-YFvd5SZI"
   },
   "source": [
    "## Types of optimization algorithms\n",
    "\n",
    "Based on our first question **“How much data should be used for an update”** optimization algorithms can be classified as **Gradient Descent**, **Mini batch Gradient Descent**, and **Stochastic Gradient Descent**.\n",
    "\n",
    "In fact, the basic algorithm is *Gradient Descent*. *Mini-batch Gradient descent* and *Stochastic Gradient Descent* are two different strategies based on the amount of the data taken. These two are also known as the variants of *Gradient Descent*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZR-3MGM5Sbp"
   },
   "source": [
    "# Gradient Descent\n",
    "\n",
    "**Gradient descent** is most commonly used and popular **iterative** machine learning algorithm. It is also the foundation for other optimization algorithms. *Gradient descent* has the following *update rule* for weight parameter\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_1.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "Since during *backpropagation* for updating the parameters, the *derivative of loss* w.r.t. a parameter is calculated. This derivative can be dependent on more than one variable so for its calculation **multiplication chain rule** is used.\n",
    "\n",
    "For this purpose, a **Gradient** is required. A **gradient** is a vector indicating the direction of increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6nhXIn15SeV"
   },
   "source": [
    "**For gradient calculation, we need to calculate *derivatives of loss* w.r.t the parameters and update the *parameters* in the opposite direction of the *gradient*.**\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_2.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "The above ideal convex curve image displays the *weight update* in the opposite direction of the gradient. As we can notice for too large and small values of *weights* the *loss* is maximum and our goal is to *minimize* the *loss* so the weights are updated. If the *gradient* is negative then **descent**(dive) towards the positive side and if the *gradient* is positive then descent towards the negative side until the minimal value of *gradient* is found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jahpG9Iv5ShM"
   },
   "source": [
    "### Algorithm for Gradient descent using a single neuron with sigmoid activation function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26h8Tq0b8sMU"
   },
   "outputs": [],
   "source": [
    "def sigmoid(w,b,x):\n",
    "    return 1.0 / (1.0 + np.exp(-w*x + b))\n",
    "\n",
    "def grad_w(w,b,x,y):\n",
    "    fx = sigmoid(w,b,x)\n",
    "    return (fx - y) * fx * (1-fx) * x\n",
    "\n",
    "def grad_b(w,b,x,y):\n",
    "    fx = sigmoid(w,b,x)\n",
    "    return (fx - y) * fx * (1-fx)\n",
    "    \n",
    "def do_gradient_descent():\n",
    "    w,b,eta = -2, -2, 1.0\n",
    "    max_epochs = 1000\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "        w = w - eta * dw\n",
    "        b = b - eta * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stAobvmQ5Sjy"
   },
   "source": [
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_3.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "The above *animation* represents how the algorithm converges after 1000 epochs. The error surface used in this *animation* is as per the input. \n",
    "This error surface is animated in $2D$ space. For $2D$, a contour map is used where the contours represent the third dimension i.e. **error**.\n",
    "\n",
    "- The **red** regions represent the high values of error, the more the intensity of the red region, the more the error. \n",
    "\n",
    "- Similarly, the **blue** regions represent the low values of error, the less the intensity of the blue region, the less the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3s9vYDX5SmB"
   },
   "source": [
    "**Standard Gradient descent** updates the *parameters* only after each epoch i.e. after calculating the derivatives for all the observations it updates the parameters. This phenomenon may lead to the following **caveats**.\n",
    "\n",
    "- It can be very slow for very large datasets because only one-time update for each epoch so large number of epochs is required to have a substantial number of *updates*.\n",
    "\n",
    "\n",
    "- For large datasets, the vectorization of data doesn’t fit into **memory**.\n",
    "\n",
    "\n",
    "- For *non-convex* surfaces, it may only find the **local minimums**.\n",
    "\n",
    "\n",
    "Now let see how **different variations of gradient descent** can address these challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wPleOxuN5So_"
   },
   "source": [
    "## Stochastic gradient descent\n",
    "\n",
    "**Stochastic gradient descent** updates the *parameters* for each *observation* which leads to more number of updates. So it is a faster approach which helps in quicker decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ige7hjyM5SuW"
   },
   "source": [
    "### Algorithm for Stochastic Gradient descent using a single neuron with sigmoid activation function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "So0DHpow-uZD"
   },
   "outputs": [],
   "source": [
    "def do_stochastic_gradient_descent():\n",
    "    w,b,eta = -2, -2, 1.0\n",
    "    max_epochs = 1000\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "            w = w - eta * dw\n",
    "            b = b - eta * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GgoE16q5Sw5"
   },
   "source": [
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_4.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "Quicker updates in different directions can be noticed in this animation. Here, lots of oscillations take place which causes the updates with higher variance i.e. noisy updates. These noisy updates help in finding new and better local minima.\n",
    "\n",
    "### Disadvantages of SGD\n",
    "\n",
    "- Because of the **greedy approach**, it only **approximates (stochastics)** the gradient.\n",
    "\n",
    "- Due to **frequent fluctuations**, it will keep **overshooting** near to the desired **exact minima**.\n",
    "\n",
    "Now let see how another variant of gradient descent can address these challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-rEVbCw5Szx"
   },
   "source": [
    "## Mini Batch Gradient Descent\n",
    "\n",
    "Another variant of **GD** to address the problems of **SGD**, it lies in between **GD** and **SGD**. **Mini-batch Gradient descent** updates the parameters for a finite number of observations. These observations together are referred to a **batch** with some fixed size.\n",
    "\n",
    "**Batch size** is chosen as a multiple of 64 e.g. 64, 128, 256, etc. Many more updates take place in one epoch through *Mini-batch GD*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37a2q6Nd5S2R"
   },
   "source": [
    "### Algorithm for Mini-batch Gradient descent using a single neuron with sigmoid activation function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6FwfuHA_0FM"
   },
   "outputs": [],
   "source": [
    "def do_mini_batch_gradient_descent():\n",
    "    w,b,eta = -2, -2, 1.0\n",
    "    max_epochs = 1000\n",
    "    mini_batch_size = 3\n",
    "    num_of_points_seen = 0\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "            num_of_points_seen += 1\n",
    "        if num_of_points_seen % mini_batch_size == 0:\n",
    "            w = w - eta * dw\n",
    "            b = b - eta * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwmQGiGt5S4_"
   },
   "source": [
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_5.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "As we can see there are fewer oscillations in **Mini-batch** in contrast to **SGD**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPRtt-zB5S7t"
   },
   "source": [
    "### Basic notations\n",
    "\n",
    "- $1 epoch$ = one pass over the entire data\n",
    "\n",
    "- $1 step$ = one update for parameters\n",
    "\n",
    "- $N$ = number of data points\n",
    "\n",
    "- $B$ = Mini-batch size\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_6.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "### Advantages of Mini-batch GD\n",
    "\n",
    "- Updates are less noisy compared to SGD which leads to better convergence.\n",
    "- A high number of updates in a single epoch compared to GD so less number of epochs are required for large datasets.\n",
    "- Fits very well to the processor memory which makes computing faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6QcKQfD5S-2"
   },
   "source": [
    "## Better optimization w.r.t. Gradient Descent\n",
    "\n",
    "The **error surface** contains *more sloppy* as well *less sloppy* areas. During *back propagation*, there will be more update in parameters for the regions with *more slope* whereas less update in parameters for the regions with a *gentle slope*. More change in parameters leads to more change in loss, similarly less change in parameters leads to less change in the loss.\n",
    "\n",
    "If the parameter initialization lands in a *gentle slope* area then it requires a large number of *epochs* to navigate through these areas. It happens so because the gradient will be very small in *gentle slope* regions. So it moves with **small baby steps** in *gentle* regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sYhLkZq5TDM"
   },
   "source": [
    "Consider a case with initialization in a flat surface as shown below where **GD** is used and the **error** is not reducing when the **gradient** is in the **flat surface**.\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_7.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "Even after a large number of epochs for e.g. 10000 the algorithm is ***not converging***.\n",
    "\n",
    "Due to this issue, the *convergence* is not achieved so easily and the learning takes too much time.\n",
    "\n",
    "To overcome this problem **Momentum based gradient descent** is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsgGTL8v5TGO"
   },
   "source": [
    "## Momentum-based gradient descent\n",
    "\n",
    "Consider a case where in order to reach to your desired destination you are continuously being asked to follow the same direction and once you become confident that you are following the right direction then you start taking **bigger steps** and you keep getting **momentum** in that same direction.\n",
    "\n",
    "Similar to this if the **gradient** is in a **flat surfac**e for long term then rather than taking constant steps it should take **bigger steps** and keep the momentum continue. This approach is known as **momentum based gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5R5rU5ut5TJc"
   },
   "source": [
    "Momentum-based gradient descent update rule for weight parameter\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_8.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "**Gamma parameter($γ$)** is the momentum term which indicates how much acceleration you want. Here along with the **current gradient ($η∇w_t$)**, the movement is also done according to history ($γV_{t−1}$) so the **update** becomes larger which leads to faster movement and faster **convergence**.\n",
    "\n",
    "**$v_t$** is **exponentially decaying weighted sum**, as $t$ increases $γ V_{t−1}$ becomes smaller and smaller i.e. this equation holds the farther updates by a small magnitude and recent updates by a large magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfT8p2gd5TQW"
   },
   "source": [
    "### Momentum-based gradient descent in Python for sigmoid neuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5VA3x41AD08T"
   },
   "outputs": [],
   "source": [
    "def do_momentum_based_gradient_descent():\n",
    "    w,b,eta,max_epochs = -2, -2, 1.0, 1000\n",
    "    v_w, v_b = 0, 0\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "        v_w = gamma * v_w + eta * dw\n",
    "        v_b = gamma * v_b + eta * db\n",
    "        w = w - v_w\n",
    "        b = b - v_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9B2QaOc5TVn"
   },
   "source": [
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_9.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "This algorithm **adds momentum** in the direction of **consistent gradients** and **cancels the momentum** if the **gradients** are in **different directions**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "677Si0415TZe"
   },
   "source": [
    "### Issues with momentum based Gradient descent\n",
    "\n",
    "In the **valley** that leads to exact **desired minima**, there are a large number of *oscillations* using *momentum-based GD*. Because it **overshoots** the minima with **larger steps** and takes a **U-turn** but again overshoots so this process repeats. Which means moving with larger steps is not always good.\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_A.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "- **Momentum-based GD** *oscillates* for a **large number of times** in and out of the **minima**.\n",
    "\n",
    "To overcome this issue **Nesterov accelerated Gradient Descent** is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDRclB_45TT3"
   },
   "source": [
    "## Nesterov accelerated Gradient Descent\n",
    "\n",
    "In *momentum based GD* as the *gradient* heads to the valley(minima region), it makes a lot of **U-turns(oscillations)** before it *converges*. This problem was initially identified and responded by a researcher named **Yurii Nesterov**.\n",
    "\n",
    "He suggested, make the *movement* first by **history amount(previous momentum)** then calculate the **temporary gradient** at this point and then *update* the *parameters*. In other words, before making an *update* directly first it looks ahead by moving with the *previous momentum* then it finds what the *gradient* should be.\n",
    "\n",
    "This *looking ahead* helps **NAG** in finishing its job(finding the minima) quicker than **momentum-based GD**. Hence the **oscillations** are **less** compared to **momentum based GD** and also there are fewer chances of missing the **minima**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9BRxuEU5TOh"
   },
   "source": [
    "**NAG update rule** for *weight* parameter\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_B0.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_B.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_cmzPEJFflb"
   },
   "source": [
    "### NAG algorithm in Python for sigmoid neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRSYn-WlFk7Q"
   },
   "outputs": [],
   "source": [
    "def do_nag_gradient_descent():\n",
    "    w,b,eta,max_epochs = -2, -2, 1.0, 1000\n",
    "    v_w, v_b, gamma = 0, 0, 0.9\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        #compute the look ahead value\n",
    "        w = w - gamma * v_w\n",
    "        b = b - gamma * v_b\n",
    " \n",
    "        for x,y in zip(X,Y):\n",
    "            #compute the derivatives using look ahead value\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "\n",
    "        #Now move further in the opposite direction of that gradient\n",
    "        w = w - eta * dw\n",
    "        b = b - eta * db\n",
    " \n",
    "        #Now update the previous momentum\n",
    "        v_w = gamma * v_w + eta * dw\n",
    "        v_b = gamma * v_b + eta * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7A-Rdhkh5TM6"
   },
   "source": [
    "Here v_w and v_b refer to $v_t$ and $v_b$ respectively.\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_C.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZmkdF--5TBN"
   },
   "source": [
    "## Concept of Adaptive learning rate\n",
    "\n",
    "As per the update rule\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_D.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "The update is directly proportional to the **gradient($∇w$)**. Smaller the *gradient* smaller the update and the *gradient* is directly proportional to the **input**. Therefore the *update* is dependent on the *input* also.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3Th9CBCHbN8"
   },
   "source": [
    "**Need for an adaptive learning rate**\n",
    "\n",
    "For the real-time datasets, most of the features are **sparse** i.e. having zero values. Due to this for most of the cases, the corresponding *gradient* is zero and therefore the parameters *update* is also zero. To resonate this problem, these update should be boosted i.e. a **high learning rate** for *sparse* features. Therefore the learning rate should be **adaptive** for fairly *sparse* data.\n",
    "\n",
    "In other words, if we are dealing with **sparse features** then learning rate should be high whereas for **dense features** learning rate should be low.\n",
    "\n",
    "**Adagrad**, **RMSProp**, **Adam** algorithms are based on the concept of *adaptive learning rate*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPTMXODlHbY_"
   },
   "source": [
    "## Adagrad\n",
    "\n",
    "It adopts the learning rate($η$) based on the **sparsity** of features. So the parameters with **small updates(sparse features)** have high *learning rate* whereas the parameters with **large updates(dense features)** have low *learning rate*. Therefore **adagrad** uses a different *learning rate* for each parameter.\n",
    "\n",
    "**Adagrad** update rule for *weight* parameter\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_E.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "$v_t$ accumulates the running sum of square of the gradients. Square of $∇ w_t$ neglects the sign of gradients. $v_t$ indicates accumulated gradient up to time $t$. **Epsilon** in the denominator avoids the chances of **divide by zero error**.\n",
    "\n",
    "So if $v_t$ is low (due to less update up to time $t$) for a parameter then the effective *learning rate* will be **high** and if $v_t$ is high for a parameter then effective *learning rate* will be **less**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNyk96z3Hbgv"
   },
   "source": [
    "### Adagrad algorithm in Python for sigmoid neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Vc8oPSLKGmN"
   },
   "outputs": [],
   "source": [
    "def do_adagrad():\n",
    "    w,b,eta,max_epochs = -2, -2, 1.0, 1000\n",
    "    v_w, v_b = 0, 0\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "        v_w += dw**2\n",
    "        v_b += db**2\n",
    "        self.w -= (eta / np.sqrt(v_w) + eps) * dw\n",
    "        self.b -= (eta / np.sqrt(v_b) + eps) * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGBz0eY8Hbj2"
   },
   "source": [
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_F.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnRrRfT7Hbog"
   },
   "source": [
    "### Disadvantage with Adagrad\n",
    "\n",
    "The learning rate decays very aggressively\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_G.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "For *parameters*(especially *bias*) corresponding to *dense features*, after a few updates, the *learning rate* **decays** rapidly as the denominator grows rapidly due to the accumulation of *squared gradients*. So after a finite number of *updates*, the algorithm refuses to learn and *converges slowly* even if we run it for a large number of *epochs*. The *gradient* reaches to a bad minimum (close to desired *minima*) but not at exact minima. So **adagrad** results in decaying and decreasing learning rate for bias parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVZNIqmdHbwU"
   },
   "source": [
    "## RMSProp\n",
    "\n",
    "**RMSProp** overcomes the **decaying learning rate** problem of **adagrad** and prevents the rapid growth in $v_t$.\n",
    "\n",
    "Instead of accumulating *squared gradients* from the beginning, it accumulates the *previous gradients* in some portion(weight) which prevents rapid growth of $v_t$ and due to this the algorithm keeps learning and tries to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbTSxv2xHb1r"
   },
   "source": [
    "**RMSProp** update rule for weight parameter\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_H.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "Here $v_t$ is exponentially decaying average of all the previous squared gradients. The beta parameter value is set to a similar value as the momentum term. The running average $v_t$ up to time $t$ is dependent on weighted previous average gradients and current gradient. $v_t$ maintains $(∇w_t)^2$ for a fixed window time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjENFO9xHbz8"
   },
   "source": [
    "### RMSprop algorithm in Python for sigmoid neuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_KMExF9L0aK"
   },
   "outputs": [],
   "source": [
    "def do_RMSProp():\n",
    "    w,b,eta,max_epochs = -2, -2, 1.0, 1000\n",
    "    v_w, v_b = 0, 0\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "        v_w = beta * v_w + (1 - beta) * dw**2\n",
    "        v_b = beta * v_b + (1 - beta) * db**2\n",
    "        self.w -= (eta / np.sqrt(v_w) + eps) * dw\n",
    "        self.b -= (eta / np.sqrt(v_b) + eps) * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsX9NEj3Hbtb"
   },
   "source": [
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_I.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "### Issues with RMSProp\n",
    "\n",
    "A large number of oscillations with high learning rate or large gradient\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_J.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "So far in **Adagrad**, **RMSProp** we were calculating different **learning rates** for different parameters, can we have different **momentums** for different parameters. **Adam** algorithm introduces the concept of **adaptive momentum** along with **adaptive learning rate**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YA4h6oRKHbrg"
   },
   "source": [
    "### Adam\n",
    "\n",
    "**Adaptive Moment Estimation (Adam)** computes the exponentially decaying average of previous gradients $m_t$ along with an **adaptive learning rate**. **Adam** is a combined form of **Momentum-based GD** and RMSProp.\n",
    "\n",
    "In **Momentum-based GD**, previous gradients(history) are used to compute the current gradient whereas, in RMSProp previous gradients(history) are used to adjust the learning rate based on the features. Therefore **Adam** deals with adaptive learning rate and adaptive momentum where **RMSProp** ensures $v_t$ does not grow rapidly to avoid the chances of decaying learning rate and $m_t$ from **Momentum-based GD** ensures it calculates the *exponentially decaying average of previous gradients*, not the current gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g47Ae60bHbm1"
   },
   "source": [
    "**Adam** update rule for weight parameter\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_K.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "Here $m_t$ and $v_t$ are values of the mean obtained from the first moment.\n",
    "\n",
    "**Adam** uses **bias corrected values (uncentered variance)** of gradients for *update rule* and these values are obtained through the second moment.\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_K2.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "The final *update rule* is given as\n",
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_K3.png\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ug-rZ53bHbel"
   },
   "source": [
    "### Adam algorithm in Python for sigmoid neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POm-yBkQNs9b"
   },
   "outputs": [],
   "source": [
    "def do_Adam():\n",
    "    w,b,eta,max_epochs = -2, -2, 1.0, 1000\n",
    "    v_w, v_b = 0, 0\n",
    "    m_w, m_b = 0, 0\n",
    "    num_updates = 0\n",
    "    for i in range(epochs):\n",
    "        dw, db = 0, 0\n",
    "        for x, y in zip(X, Y):\n",
    "            dw = self.grad_w(x, y)\n",
    "            db = self.grad_b(x, y)\n",
    "        num_updates += 1\n",
    "        m_w = beta1 * m_w + (1-beta1) * dw\n",
    "        m_b = beta1 * m_b + (1-beta1) * db\n",
    "        v_w = beta2 * v_w + (1-beta2) * dw**2\n",
    "        v_b = beta2 * v_b + (1-beta2) * db**2\n",
    "        #m_w_c, m_b_c, v_w_c and v_b_c for bias correction   \n",
    "        m_w_c = m_w / (1 - np.power(beta1, num_updates))\n",
    "        m_b_c = m_b / (1 - np.power(beta1, num_updates))\n",
    "        v_w_c = v_w / (1 - np.power(beta2, num_updates))\n",
    "        v_b_c = v_b / (1 - np.power(beta2, num_updates))\n",
    "        self.w -= (eta / np.sqrt(v_w_c) + eps) * m_w_c\n",
    "        self.b -= (eta / np.sqrt(v_b_c) + eps) * m_b_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GW7JpM72Hbb3"
   },
   "source": [
    "\n",
    "<figure>\n",
    "  <br><center>\n",
    "    <img src=\"../images/bgd_L.gif\" />\n",
    "    <figcaption></figcaption>     \n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "So in **Adam** unlike **RMSProp** fewer oscil*l*ations and it moves more deterministically in the right direction which leads to **faster convergence** and **better optimization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyuRTZrXOFJR"
   },
   "source": [
    "## End Notes\n",
    "\n",
    "In this article, I have discussed the different types of optimization algorithms and the common issues one might encounter while using each of them. \n",
    "\n",
    "> Generally, **Adam** with **mini-batch** is preferred for the training of **deep neural networks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bq5vxsQ8OFV6"
   },
   "source": [
    "### End of notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "beyond_gradient_descent.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
