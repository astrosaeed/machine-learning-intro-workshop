{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/misc/pytorch_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSUl5xCwoGN9",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch with GPU in Colab\n",
        "\n",
        "- From [Getting Started With Pytorch In Google Collab With Free GPU](https://www.marktechpost.com/2019/06/09/getting-started-with-pytorch-in-google-collab-with-free-gpu/) by Niranjan Kumar in [www.marktechpost.com](https://www.marktechpost.com).\n",
        "\n",
        "Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation.\n",
        "\n",
        "**NOTE** This is currently a **Colab only** notebook. It will need significant changes to work locally.\n",
        "\n",
        "## Colab has pytorch support built-in for Python 3 kernels.\n",
        "\n",
        "You don't need to install any extra stuff.  Very nice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahqZyO0JoH2V",
        "colab_type": "text"
      },
      "source": [
        "## Pytorch – Tensors\n",
        "\n",
        "Numpy based operations are not optimized to utilize GPUs to accelerate its numerical computations. For modern deep neural networks, GPUs often provide speedups of 50x or greater. So, unfortunately, numpy won’t be enough for modern deep learning. \n",
        "\n",
        "This is where Pytorch introduces the concept of **Tensor**. A Pytorch Tensor is conceptually identical to an n-dimensional numpy array. Unlike numpy, **PyTorch Tensors can utilize GPUs to accelerate their numeric computations**\n",
        "\n",
        "Let’s see how you can create a Pytorch Tensor. First, we will import the required libraries. Remember that torch, numpy and matplotlib are pre-installed in Colab’s virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XZ2Xcumn9y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dna7ETjoSQF",
        "colab_type": "text"
      },
      "source": [
        "The default tensor type in PyTorch is a float tensor defined as **torch.FloatTensor**. We can create tensors by using the inbuilt functions present inside the torch package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2GcYjE4oRk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "76eb0522-5abd-472c-903e-ec98deb3e4a4"
      },
      "source": [
        "## creating a tensor of 3 rows and 2 columns consisting of ones\n",
        "x = torch.ones(3,2)\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQDZQNkgoiV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0566307b-2322-41a9-d8fc-7ff398893870"
      },
      "source": [
        "## creating a tensor of 3 rows and 2 columns consisting of zeros\n",
        "x = torch.zeros(3,2)\n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOe5Hc9Qonv1",
        "colab_type": "text"
      },
      "source": [
        "### Creating tensors by random initialization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMtDkoaVoRo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6577f21a-87c0-4b21-9e6d-76020ec0a772"
      },
      "source": [
        "# To increase the reproducibility, we often set the random seed to a specific value first.\n",
        "torch.manual_seed(2)\n",
        "\n",
        "x = torch.rand(3, 2) \n",
        "print(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6147, 0.3810],\n",
            "        [0.6371, 0.4745],\n",
            "        [0.7136, 0.6190]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV9C6ZJgo0bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "21cba49d-44ba-4e84-f0e5-bffc4cf735f0"
      },
      "source": [
        "#generating tensor randomly from normal distribution\n",
        "x = torch.randn(3,3)\n",
        "print(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.1409, -0.5534, -0.5000],\n",
            "        [-0.0815, -0.1633,  1.5277],\n",
            "        [-0.4023,  0.0972, -0.5682]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql4jr6NwrlET",
        "colab_type": "text"
      },
      "source": [
        "## Simple Tensor Operations\n",
        "\n",
        "### Slicing of Tensors\n",
        "You can slice PyTorch tensors the same way you slice ndarrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAcXbbman-xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "83c3034b-1482-473f-9bea-b239186f9008"
      },
      "source": [
        "#create a tensor\n",
        "x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]])\n",
        "print(x)\n",
        "print(f\"- Every row, only the last column : {x[:, 1]}\")\n",
        "print(f\"-       Every column in first row : {x[0, :]}\") \n",
        "\n",
        "y = x[1, 1] # take the element in first row and first column and create a another tensor\n",
        "print(y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "- Every row, only the last column : tensor([2, 4, 6])\n",
            "-       Every column in first row : tensor([1, 2])\n",
            "tensor(4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ysqg8MBsXK9",
        "colab_type": "text"
      },
      "source": [
        "### Reshape Tensor\n",
        "\n",
        "Reshape a Tensor to different shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D629LWHsbvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "69e05950-4454-4b9f-8788-d88331d4aec4"
      },
      "source": [
        " x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]]) #(3 rows and 2 columns)\n",
        "print(x)\n",
        "\n",
        "print(\"\\n- reshaping to 2 rows and 3 columns\")\n",
        "y = x.view(2, 3) #reshaping to 2 rows and 3 columns\n",
        "y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "- reshaping to 2 rows and 3 columns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK61HD4Lst8E",
        "colab_type": "text"
      },
      "source": [
        "Use of -1 to reshape the tensors.\n",
        "\n",
        "-1 indicates that the shape will be inferred from previous dimensions. \n",
        "\n",
        "In the below code snippet `x.view(6,-1)` will result in a tensor of shape 6x1 because we have fixed the size of rows to be 6, Pytorch will now infer the best possible dimension for the column such that it will be able to accommodate all the values present in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quLXzrbMs28E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "df4bf5c5-8069-4e5c-af07-61da4bb4ecf2"
      },
      "source": [
        "x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]]) #(3 rows and 2 columns\n",
        "print(x)\n",
        "\n",
        "print(\"- y shape will be 6x1\")\n",
        "y = x.view(6,-1)\n",
        "y"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "- y shape will be 6x1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3],\n",
              "        [4],\n",
              "        [5],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHVDjLfWtF80",
        "colab_type": "text"
      },
      "source": [
        "## Mathematical Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLwYpSdmtJmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "16cd4cca-1454-42f7-c407-7499051a7f10"
      },
      "source": [
        "#Create two tensors\n",
        "x = torch.ones([3, 2])\n",
        "y = torch.ones([3, 2])\n",
        "\n",
        "#adding two tensors\n",
        "z = x + y #method 1\n",
        "z = torch.add(x,y) #method 2\n",
        "print(f\"X\\n{x}\\n+\\nY\\n{y}\\nis\\n{z}\")\n",
        "\n",
        "#subtracting two tensors\n",
        "z = x - y #method 1\n",
        "\n",
        "print(\"\\nElement-wise subtraction:\")\n",
        "torch.sub(x,y) #method 2"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "+\n",
            "Y\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "is\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "\n",
            "Element-wise subtraction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhsIE2k3uUfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3fc33a07-0db0-45f3-9741-74d4e9531e3f"
      },
      "source": [
        "# Scalar element-wise divison\n",
        "x / 2"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.5000],\n",
              "        [0.5000, 0.5000],\n",
              "        [0.5000, 0.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VQT8eJTukys",
        "colab_type": "text"
      },
      "source": [
        "### Inplace Operations\n",
        "\n",
        "In Pytorch all operations on the tensor that operate in-place on it will have an **`_` postfix**. For example, **`add`** is the out-of-place version, and **`add_`** is the in-place version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDLoYuW7u4Jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5db956af-03a9-455b-87e3-52747c9a5b0d"
      },
      "source": [
        "y.add_(x) #tensor y added with x and result will be stored in y"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGKS5lQtu3Ms",
        "colab_type": "text"
      },
      "source": [
        "## Pytorch to Numpy Bridge\n",
        "\n",
        "Converting an **Pytorch tensor** to **numpy ndarray** is very useful sometimes. By using `.numpy()` on a tensor, we can easily convert tensor to ndarray."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGi7F8D1vNGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "934acfaa-3095-4f85-faa8-9955761074af"
      },
      "source": [
        "x = torch.linspace(0 , 1, steps = 5) #creating a tensor using linspace\n",
        "x_np = x.numpy() #convert tensor to numpy\n",
        "print(type(x), type(x_np)) #check the types "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohQu-MPqvToz",
        "colab_type": "text"
      },
      "source": [
        "To convert numpy ndarray to pytorch tensor, we can use .from_numpy() to convert ndarray to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km-ak8akvV3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a42a6038-0b9d-4312-82aa-3fe9076bc0ee"
      },
      "source": [
        "import numpy as np\n",
        "a = np.random.randn(5) #generate a random numpy array\n",
        "a_pt = torch.from_numpy(a) #convert numpy array to a tensor\n",
        "print(type(a), type(a_pt)) "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vg1fhF0vrHN",
        "colab_type": "text"
      },
      "source": [
        "During the conversion, Pytorch tensor and numpy ndarray will share their underlying memory locations and changing one will change the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3LFwMZIvtdV",
        "colab_type": "text"
      },
      "source": [
        "## CUDA Support\n",
        "\n",
        "# IMPORTANT!\n",
        "\n",
        "You **must** enable GPU support with **Runtime** | **Change Runtime Type** | **GPU** from the Colab menu before this will work.\n",
        "\n",
        "To check how many CUDA supported GPU’s are connected to the machine, you can use below code snippet. If you are executing the code in Colab you will get 1, that means that the Colab virtual machine is connected to one GPU. torch.cuda is used to set up and run CUDA operations. It keeps track of the currently selected GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_W_vsifvxgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a64c0953-5f7a-4fff-802b-a5bed8e66f43"
      },
      "source": [
        "import torch\n",
        "n = torch.cuda.device_count()\n",
        "print(f\"The number of CUDA devices available to Torch is {n}.\")\n",
        "if n == 0:\n",
        "    print(\"*** ERROR! You need to enable GPU support first using Runtime | Change Runtime Type | GPU\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of CUDA devices available to Torch is 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFxcvSKSwgCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "37042359-fbb9-4d32-8786-86036304efb6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 16 23:33:19 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    16W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaBuAGHrv02U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "225aa08e-e573-4e33-9ec9-109d4e84eb4e"
      },
      "source": [
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHvVdHqix85e",
        "colab_type": "text"
      },
      "source": [
        "The important thing to note is that we can reference this CUDA supported GPU card to a variable and use this variable for any Pytorch Operations.\n",
        "\n",
        "All CUDA tensors you allocate will be created on that device. The selected GPU device can be changed with a [torch.cuda.device](https://pytorch.org/docs/stable/cuda.html#torch.cuda.device) context manager."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bqn8eJvyH6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8f959816-a010-40be-d80e-e93e821aee90"
      },
      "source": [
        "#Assign cuda GPU located at location '0' to a variable\n",
        "cuda0 = torch.device('cuda:0')\n",
        "\n",
        "#Performing the addition on GPU\n",
        "a = torch.ones(3, 2, device=cuda0) #creating a tensor 'a' on GPU\n",
        "b = torch.ones(3, 2, device=cuda0) #creating a tensor 'b' on GPU\n",
        "c = a + b\n",
        "print(c)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XcARtBZyWKb",
        "colab_type": "text"
      },
      "source": [
        "## Automatic Differentiation\n",
        "\n",
        "In this section, we will discuss the important package called automatic differentiation or autograd in Pytorch. The `autograd` package gives us the ability to perform automatic differentiation or automatic gradient computation for all operations on tensors. It is a define-by-run framework, which means that your back-propagation is defined by how your code is run.\n",
        "\n",
        "Let’s see how to perform automatic differentiation by using a simple example. First, we create a tensor with `requires_grad` parameter set to `True` because we want to track all the operations performing on that tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnsZuGWfypqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "acb68b07-03f4-455e-cae0-4be699af28c9"
      },
      "source": [
        "#create a tensor with requires_grad = True\n",
        "x = torch.ones([3,2], requires_grad = True)\n",
        "print(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOQ7sPuKy5sT",
        "colab_type": "text"
      },
      "source": [
        "Perform a simple tensor addition operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAMRtMJUy9A8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d861b283-e5d6-49a1-f971-f7aba6d2216d"
      },
      "source": [
        "y = x + 5 #tensor addition\n",
        "print(y) #check the result"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOcAZfX4zB8E",
        "colab_type": "text"
      },
      "source": [
        "Because $y$ was created as a result of an operation on $x$, so it has a $grad\\_fn$. \n",
        "\n",
        "Perform more operations on $y$ and create a new tensor $z$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqr1TcHNzQ6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f6bb4369-85b4-4c54-c9ab-1309c80d515c"
      },
      "source": [
        "z = y*y + 1\n",
        "print(z)\n",
        "\n",
        "print(\"- adding all the values in z\")\n",
        "t = torch.sum(z) \n",
        "print(t)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n",
            "- adding all the values in z\n",
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDQtcrgXzg3l",
        "colab_type": "text"
      },
      "source": [
        "## Back-Propagation\n",
        "\n",
        "To perform back-propagation, you can just call `t.backward()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sejHQFPnzm-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " t.backward() #peform backpropagation but pytorch will not print any output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sulcgj62zvC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23a8759b-8b01-4f65-c93a-75a9e543824c"
      },
      "source": [
        "t"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(222., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jvu8MRwz3h7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "436a39a6-5c7e-4a61-e118-03fca9602650"
      },
      "source": [
        "x"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkZb5Dqdz8Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU89LfKw0IUE",
        "colab_type": "text"
      },
      "source": [
        "Print gradients: $$\\frac{d(t)}{dx}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrtGpjpqz5g0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7038f87-f5ba-44c0-8447-1be0669235db"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.],\n",
            "        [12., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiJlTG4v0YAl",
        "colab_type": "text"
      },
      "source": [
        "`x.grad` will give you the **partial derivative of t with respect to x** : $\\partial t / \\partial x$\n",
        "\n",
        "If you are able to figure out how we got a tensor with all the values equal to 12, then you have understood the automatic differentiation. If not don’t worry just follow along, when we execute `t.backward()` we are calculating the partial derivate of t with respect to x. \n",
        "\n",
        "Remember that $t$ is a function of $z$, which in turn is a function of $x$.\n",
        "\n",
        "$$\n",
        "d(t)/dx = 2y + 1\\ \\text{at}\\ x = 1\\ \\text{and}\\ y = 6,\\ \\text{where}\\ y = x + 5\n",
        "$$\n",
        "\n",
        "The important point to note is that the value of the derivative is calculated at the point where we initialized the tensor $x$.\n",
        "\n",
        "Since we initialized $x$ at a value equal to one, we get an output tensor with all the values equal to 12."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XYLFk-npWon",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this post, we briefly looked at the Pytorch & Google Colab and we also saw how to enable GPU hardware accelerator in Colab. Then we have seen how to create tensors in Pytorch and perform some basic operations on those tensors by utilizing CUDA supported GPU. After that, we discussed the Pytorch autograd package which gives us the ability to perform automatic gradient computation on tensors by taking a simple example. If you any issues or doubts while implementing the above code, feel free to ask them in the comment section below or send me a message in LinkedIn citing this article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD4lMMhpy7F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAqipv1jvage",
        "colab_type": "text"
      },
      "source": [
        "### End of notebook."
      ]
    }
  ]
}