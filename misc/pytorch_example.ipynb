{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pytorch_example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/misc/pytorch_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WSUl5xCwoGN9"
      },
      "source": [
        "# PyTorch with GPU in Colab\n",
        "\n",
        "- From [Getting Started With Pytorch In Google Collab With Free GPU](https://www.marktechpost.com/2019/06/09/getting-started-with-pytorch-in-google-collab-with-free-gpu/) by Niranjan Kumar in [www.marktechpost.com](https://www.marktechpost.com).\n",
        "\n",
        "Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation.\n",
        "\n",
        "**NOTE** This is currently a **Colab only** notebook. It will need significant changes to work locally.\n",
        "\n",
        "## Colab has pytorch support built-in for Python 3 kernels.\n",
        "\n",
        "You don't need to install any extra stuff.  Very nice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ahqZyO0JoH2V"
      },
      "source": [
        "## Pytorch – Tensors\n",
        "\n",
        "Numpy based operations are not optimized to utilize GPUs to accelerate its numerical computations. For modern deep neural networks, GPUs often provide speedups of 50x or greater. So, unfortunately, numpy won’t be enough for modern deep learning. \n",
        "\n",
        "This is where Pytorch introduces the concept of **Tensor**. A Pytorch Tensor is conceptually identical to an n-dimensional numpy array. Unlike numpy, **PyTorch Tensors can utilize GPUs to accelerate their numeric computations**\n",
        "\n",
        "Let’s see how you can create a Pytorch Tensor. First, we will import the required libraries. Remember that torch, numpy and matplotlib are pre-installed in Colab’s virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4XZ2Xcumn9y0",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "import torch\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Dna7ETjoSQF"
      },
      "source": [
        "The default tensor type in PyTorch is a float tensor defined as **torch.FloatTensor**. We can create tensors by using the inbuilt functions present inside the torch package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_2GcYjE4oRk1",
        "outputId": "b701135a-706e-4f1d-ea51-b5de69099abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "cellView": "both"
      },
      "source": [
        "## creating a tensor of 3 rows and 2 columns consisting of ones\n",
        "x = torch.ones(3,2)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pQDZQNkgoiV0",
        "outputId": "a5ff3006-8e2e-48e4-b413-5fcc8930c533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "cellView": "both"
      },
      "source": [
        "## creating a tensor of 3 rows and 2 columns consisting of zeros\n",
        "x = torch.zeros(3,2)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sOe5Hc9Qonv1"
      },
      "source": [
        "### Creating tensors by random initialization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QMtDkoaVoRo0",
        "outputId": "d7bc3a54-41e4-4d9a-bb77-c479455f84ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "cellView": "both"
      },
      "source": [
        "# To increase the reproducibility, we often set the random seed to a specific value first.\n",
        "torch.manual_seed(2)\n",
        "\n",
        "x = torch.rand(3, 2) \n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6147, 0.3810],\n",
            "        [0.6371, 0.4745],\n",
            "        [0.7136, 0.6190]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DV9C6ZJgo0bd",
        "outputId": "1f37f782-d117-492e-ef6d-7c0205593e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "cellView": "both"
      },
      "source": [
        "#generating tensor randomly from normal distribution\n",
        "x = torch.randn(3,3)\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.1409, -0.5534, -0.5000],\n",
            "        [-0.0815, -0.1633,  1.5277],\n",
            "        [-0.4023,  0.0972, -0.5682]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ql4jr6NwrlET"
      },
      "source": [
        "## Simple Tensor Operations\n",
        "\n",
        "### Slicing of Tensors\n",
        "You can slice PyTorch tensors the same way you slice ndarrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAcXbbman-xd",
        "outputId": "6bf701a7-afb2-423b-ca14-ed2b3a0b6d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "cellView": "both"
      },
      "source": [
        "#create a tensor\n",
        "x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]])\n",
        "print(x)\n",
        "print(f\"- Every row, only the last column : {x[:, 1]}\")\n",
        "print(f\"-       Every column in first row : {x[0, :]}\") \n",
        "\n",
        "y = x[1, 1] # take the element in first row and first column and create a another tensor\n",
        "print(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "- Every row, only the last column : tensor([2, 4, 6])\n",
            "-       Every column in first row : tensor([1, 2])\n",
            "tensor(4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Ysqg8MBsXK9"
      },
      "source": [
        "### Reshape Tensor\n",
        "\n",
        "Reshape a Tensor to different shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6D629LWHsbvc",
        "outputId": "67f80dd9-34bb-4767-9c7d-7e4e7e32909a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "cellView": "both"
      },
      "source": [
        "x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]]) #(3 rows and 2 columns)\n",
        "print(x)\n",
        "\n",
        "print(\"\\n- reshaping to 2 rows and 3 columns\")\n",
        "y = x.view(2, 3) #reshaping to 2 rows and 3 columns\n",
        "y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "- reshaping to 2 rows and 3 columns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iK61HD4Lst8E"
      },
      "source": [
        "Use of -1 to reshape the tensors.\n",
        "\n",
        "-1 indicates that the shape will be inferred from previous dimensions. \n",
        "\n",
        "In the below code snippet `x.view(6,-1)` will result in a tensor of shape 6x1 because we have fixed the size of rows to be 6, Pytorch will now infer the best possible dimension for the column such that it will be able to accommodate all the values present in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "quLXzrbMs28E",
        "outputId": "8bcd18e0-6881-4ed3-9a12-0db1da8c3b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "cellView": "both"
      },
      "source": [
        "x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]]) #(3 rows and 2 columns\n",
        "print(x)\n",
        "\n",
        "print(\"- y shape will be 6x1\")\n",
        "y = x.view(6,-1)\n",
        "y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "- y shape will be 6x1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3],\n",
              "        [4],\n",
              "        [5],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZHVDjLfWtF80"
      },
      "source": [
        "## Mathematical Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLwYpSdmtJmJ",
        "outputId": "31cc22f9-732c-4cbf-d9fe-9f2cd2ad6b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "#@title\n",
        "#Create two tensors\n",
        "x = torch.ones([3, 2])\n",
        "y = torch.ones([3, 2])\n",
        "\n",
        "#adding two tensors\n",
        "z = x + y #method 1\n",
        "z = torch.add(x,y) #method 2\n",
        "print(f\"X\\n{x}\\n+\\nY\\n{y}\\nis\\n{z}\")\n",
        "\n",
        "#subtracting two tensors\n",
        "z = x - y #method 1\n",
        "\n",
        "print(\"\\nElement-wise subtraction:\")\n",
        "torch.sub(x,y) #method 2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "+\n",
            "Y\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "is\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "\n",
            "Element-wise subtraction:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mhsIE2k3uUfc",
        "outputId": "c1e392d0-0562-43e2-b5fa-129b9555f106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#@title\n",
        "# Scalar element-wise divison\n",
        "x / 2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.5000],\n",
              "        [0.5000, 0.5000],\n",
              "        [0.5000, 0.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5VQT8eJTukys"
      },
      "source": [
        "### Inplace Operations\n",
        "\n",
        "In Pytorch all operations on the tensor that operate in-place on it will have an **`_` postfix**. For example, **`add`** is the out-of-place version, and **`add_`** is the in-place version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nDLoYuW7u4Jt",
        "outputId": "7a898665-46eb-4fbc-9b57-2d19f6ed0882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#@title\n",
        "y.add_(x) #tensor y added with x and result will be stored in y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGKS5lQtu3Ms"
      },
      "source": [
        "## Pytorch to Numpy Bridge\n",
        "\n",
        "Converting an **Pytorch tensor** to **numpy ndarray** is very useful sometimes. By using `.numpy()` on a tensor, we can easily convert tensor to ndarray."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RGi7F8D1vNGE",
        "outputId": "57f2f890-1f33-4d46-910e-64254ebf3c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title\n",
        "x = torch.linspace(0 , 1, steps = 5) #creating a tensor using linspace\n",
        "x_np = x.numpy() #convert tensor to numpy\n",
        "print(type(x), type(x_np)) #check the types "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ohQu-MPqvToz"
      },
      "source": [
        "To convert numpy ndarray to pytorch tensor, we can use .from_numpy() to convert ndarray to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "km-ak8akvV3k",
        "outputId": "f0a4a1ed-088d-4504-b1c6-f69c4c2c51c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "a = np.random.randn(5) #generate a random numpy array\n",
        "a_pt = torch.from_numpy(a) #convert numpy array to a tensor\n",
        "print(type(a), type(a_pt)) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4vg1fhF0vrHN"
      },
      "source": [
        "During the conversion, Pytorch tensor and numpy ndarray will share their underlying memory locations and changing one will change the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x3LFwMZIvtdV"
      },
      "source": [
        "## CUDA Support\n",
        "\n",
        "# IMPORTANT!\n",
        "\n",
        "You **must** enable GPU support with **Runtime** | **Change Runtime Type** | **GPU** from the Colab menu before this will work.\n",
        "\n",
        "To check how many CUDA supported GPU’s are connected to the machine, you can use below code snippet. If you are executing the code in Colab you will get 1, that means that the Colab virtual machine is connected to one GPU. torch.cuda is used to set up and run CUDA operations. It keeps track of the currently selected GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2_W_vsifvxgM",
        "outputId": "2bffb054-f3ed-4b23-d662-4da22db7b32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title\n",
        "import torch\n",
        "n = torch.cuda.device_count()\n",
        "print(f\"The number of CUDA devices available to Torch is {n}.\")\n",
        "if n == 0:\n",
        "    print(\"*** ERROR! You need to enable GPU support first using Runtime | Change Runtime Type | GPU\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of CUDA devices available to Torch is 1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFxcvSKSwgCD",
        "outputId": "a59e351b-9353-4731-9d23-7e6d307a6609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#@title\n",
        "!nvidia-smi"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 26 23:40:12 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HaBuAGHrv02U",
        "outputId": "920a2ad1-7baf-4724-893d-3f018daae7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LHvVdHqix85e"
      },
      "source": [
        "The important thing to note is that we can reference this CUDA supported GPU card to a variable and use this variable for any Pytorch Operations.\n",
        "\n",
        "All CUDA tensors you allocate will be created on that device. The selected GPU device can be changed with a [torch.cuda.device](https://pytorch.org/docs/stable/cuda.html#torch.cuda.device) context manager."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Bqn8eJvyH6D",
        "outputId": "f38e62e5-c5f5-474d-8a74-c98d152949d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#@title\n",
        "#Assign cuda GPU located at location '0' to a variable\n",
        "cuda0 = torch.device('cuda:0')\n",
        "\n",
        "#Performing the addition on GPU\n",
        "a = torch.ones(3, 2, device=cuda0) #creating a tensor 'a' on GPU\n",
        "b = torch.ones(3, 2, device=cuda0) #creating a tensor 'b' on GPU\n",
        "c = a + b\n",
        "print(c)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0XcARtBZyWKb"
      },
      "source": [
        "## Automatic Differentiation\n",
        "\n",
        "In this section, we will discuss the important package called automatic differentiation or autograd in Pytorch. The `autograd` package gives us the ability to perform automatic differentiation or automatic gradient computation for all operations on tensors. It is a define-by-run framework, which means that your back-propagation is defined by how your code is run.\n",
        "\n",
        "Let’s see how to perform automatic differentiation by using a simple example. First, we create a tensor with `requires_grad` parameter set to `True` because we want to track all the operations performing on that tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KnsZuGWfypqa",
        "outputId": "8e094afe-59d5-45c7-cb4b-f65634bc5600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#@title\n",
        "#create a tensor with requires_grad = True\n",
        "x = torch.ones([3,2], requires_grad = True)\n",
        "print(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lOQ7sPuKy5sT"
      },
      "source": [
        "Perform a simple tensor addition operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XAMRtMJUy9A8",
        "outputId": "00cf758c-d62f-4857-834a-1a80041e5413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#@title\n",
        "y = x + 5 #tensor addition\n",
        "print(y) #check the result"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XOcAZfX4zB8E"
      },
      "source": [
        "Because $y$ was created as a result of an operation on $x$, so it has a $grad\\_fn$. \n",
        "\n",
        "Perform more operations on $y$ and create a new tensor $z$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nqr1TcHNzQ6U",
        "outputId": "b232931d-5cdb-4010-ea9f-6bd2dfe43f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#@title\n",
        "z = y*y + 1\n",
        "print(z)\n",
        "\n",
        "print(\"- adding all the values in z\")\n",
        "t = torch.sum(z) \n",
        "print(t)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n",
            "- adding all the values in z\n",
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uDQtcrgXzg3l"
      },
      "source": [
        "## Back-Propagation\n",
        "\n",
        "To perform back-propagation, you can just call `t.backward()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sejHQFPnzm-Y",
        "colab": {}
      },
      "source": [
        "#@title\n",
        " t.backward() #peform backpropagation but pytorch will not print any output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sulcgj62zvC1",
        "outputId": "d43c23fc-8688-4752-9417-38a37850081b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title\n",
        "t"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(222., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5jvu8MRwz3h7",
        "outputId": "649216eb-6e76-4ac3-a397-8f75a67c25a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#@title\n",
        "x"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aU89LfKw0IUE"
      },
      "source": [
        "Print gradients: $$\\frac{d(t)}{dx}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UrtGpjpqz5g0",
        "outputId": "652649da-acc8-4007-f6fc-9fc9ea08a801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#@title\n",
        "print(x.grad)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.],\n",
            "        [12., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UiJlTG4v0YAl"
      },
      "source": [
        "`x.grad` will give you the **partial derivative of t with respect to x** : $\\partial t / \\partial x$\n",
        "\n",
        "If you are able to figure out how we got a tensor with all the values equal to 12, then you have understood the automatic differentiation. If not don’t worry just follow along, when we execute `t.backward()` we are calculating the partial derivate of t with respect to x. \n",
        "\n",
        "Remember that $t$ is a function of $z$, which in turn is a function of $x$.\n",
        "\n",
        "$$\n",
        "d(t)/dx = 2y + 1\\ \\text{at}\\ x = 1\\ \\text{and}\\ y = 6,\\ \\text{where}\\ y = x + 5\n",
        "$$\n",
        "\n",
        "The important point to note is that the value of the derivative is calculated at the point where we initialized the tensor $x$.\n",
        "\n",
        "Since we initialized $x$ at a value equal to one, we get an output tensor with all the values equal to 12."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9XYLFk-npWon"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this post, we briefly looked at the Pytorch & Google Colab and we also saw how to enable GPU hardware accelerator in Colab. Then we have seen how to create tensors in Pytorch and perform some basic operations on those tensors by utilizing CUDA supported GPU. After that, we discussed the Pytorch autograd package which gives us the ability to perform automatic gradient computation on tensors by taking a simple example. If you any issues or doubts while implementing the above code, feel free to ask them in the comment section below or send me a message in LinkedIn citing this article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zzp7gGHqDHL0"
      },
      "source": [
        "# BONUS!  TorchVision FNN Example\n",
        "\n",
        "Let's try to get some actual work done with PyTorch.  Here we do a Feed Forward Network using the GPU if it's enabled. Very nice.\n",
        "\n",
        "- From [Using PyTorch with GPU in Google Colab](https://jovianlin.io/pytorch-with-gpu-in-google-colab/) by Jovian Lin in [jovianlin.io](https://jovianlin.io).\n",
        "\n",
        "- [This was his orignal Colan notebook](https://goo.gl/4U46tA) but it no longer works, out-of-the-box. Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FcuVoLNy7ZMs"
      },
      "source": [
        "### Upgrade to torchvision 0.4.0 first!\n",
        "\n",
        "This was required to get around the following error; **[YMMV](https://dictionary.cambridge.org/us/dictionary/english/ymm)**\n",
        "```\n",
        "ImportError: /usr/local/lib/python3.6/dist-packages/torchvision/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at7getTypeERKNS_6TensorE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "palGFNbx6af9",
        "outputId": "d1e3394f-8107-48be-e49f-2792a80ee895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#@title\n",
        "!pip install -U torchvision==0.4.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torchvision==0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: torch==1.2.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.4.0) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aD4lMMhpy7F9",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4QpkJxEa7_TL"
      },
      "source": [
        "## Initialize Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p6Q7iOsL78k-",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "input_size    = 784   # The image size = 28 x 28 = 784\n",
        "hidden_size   = 500   # The number of nodes at the hidden layer\n",
        "num_classes   = 10    # The number of output classes. In this case, from 0 to 9\n",
        "num_epochs    = 5     # The number of times entire dataset is trained\n",
        "batch_size    = 100   # The size of input data took for one iteration\n",
        "learning_rate = 1e-3  # The speed of convergence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Mcm6Ivp8DdS"
      },
      "source": [
        "## Download MNIST Dataset\n",
        "MNIST is a huge database of handwritten digits (i.e. 0 to 9) that is often used in image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VH2iCUQD8JRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e14699f9-6ad5-49ab-bf1f-fd78f5ddf32e"
      },
      "source": [
        "#@title\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                           train=True,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 20033839.31it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 329537.66it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5279523.24it/s]                           \n",
            "8192it [00:00, 129627.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7Jr96Aq-8gc"
      },
      "source": [
        "## Load the Dataset\n",
        "\n",
        "Note: We shuffle the loading process of train_dataset to make the learning process independent of data order, but the order of test_loader remains so as to examine whether we can handle unspecified bias order of inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aYVQvEqT_BMT",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cuwDKRI_8OMM"
      },
      "source": [
        "## Build the Feedforward Neural Network\n",
        "\n",
        "Feedforward Neural Network Model Structure\n",
        "The FNN includes two fully-connected layers (i.e. fc1 & fc2) and a non-linear ReLU layer in between. Normally we call this structure 1-hidden layer FNN, without counting the output layer (fc2) in.\n",
        "\n",
        "By running the forward pass, the input images ($$) can go through the neural network and generate a output ($out$) demonstrating how are likey it is to belongs to each of the 10 classes.\n",
        "\n",
        "For example, a cat image can have 0.8 factor to a dog class and a 0.3 factor to a airplane class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gcbbW83u8nrT",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
        "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
        "    \n",
        "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r3ixczDK8t1U"
      },
      "source": [
        "## Instantiate the FNN\n",
        "\n",
        "We now create a real FNN based on our structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kyqHjrvB9D8q",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "net = Net(input_size, hidden_size, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tp_W0YDi9KdH"
      },
      "source": [
        "## Enable GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZqkAN0xT85pV",
        "outputId": "00029926-2756-4c0e-aeeb-c35f52b81746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "both"
      },
      "source": [
        "import torch\n",
        "n = torch.cuda.device_count()\n",
        "print(f\"The number of CUDA devices available to Torch is {n}.\")\n",
        "use_cuda = n > 0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of CUDA devices available to Torch is 1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2-EYw7bp9YI6",
        "outputId": "072e456d-6631-4e70-ac58-4b2c2ff3e189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "both"
      },
      "source": [
        "if use_cuda and torch.cuda.is_available():\n",
        "    print(\"- Woo hoo! CUDA GPU is enabled and available.\")\n",
        "    net.cuda()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Woo hoo! CUDA GPU is enabled and available.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ZBiNAaT9qHE"
      },
      "source": [
        "## Choose the Loss Function and Optimizer\n",
        "\n",
        "Loss function (criterion) decides how the output can be compared to a class, which determines how good or bad the neural network performs. And the optimizer chooses a way to update the weight in order to converge to find the best weights in this neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kl2QM3e-9xYM",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ELLDP0kG9yf-"
      },
      "source": [
        "## Training the FNN Model\n",
        "\n",
        "This process might take around **3 to 5** minutes depending on the backend machine. The detailed explanations are listed as comments (#) in the following codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-P5Z4TgI98QT",
        "outputId": "45baa9cb-3502-4046-c9ee-e61dc7bf493d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "#@title\n",
        "print(\"Training Feed Forward Network.\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
        "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            steps = len(train_dataset)//batch_size\n",
        "            print(f'---- Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{steps}], Loss: {loss.data.item():.4f}')\n",
        "            # JF - Note change in tensor structure. Zero indexing no longer allowed.\n",
        "            #print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "            #     %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
        "    print(f\"-- Completed Epoch [{epoch+1}/{num_epochs}]\")\n",
        "print(\"Training complete.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Feed Forward Network.\n",
            "---- Epoch [1/5], Step [100/600], Loss: 0.3739\n",
            "---- Epoch [1/5], Step [200/600], Loss: 0.2592\n",
            "---- Epoch [1/5], Step [300/600], Loss: 0.1842\n",
            "---- Epoch [1/5], Step [400/600], Loss: 0.1349\n",
            "---- Epoch [1/5], Step [500/600], Loss: 0.3893\n",
            "---- Epoch [1/5], Step [600/600], Loss: 0.1328\n",
            "-- Completed Epoch [1/5]\n",
            "---- Epoch [2/5], Step [100/600], Loss: 0.1239\n",
            "---- Epoch [2/5], Step [200/600], Loss: 0.2006\n",
            "---- Epoch [2/5], Step [300/600], Loss: 0.1211\n",
            "---- Epoch [2/5], Step [400/600], Loss: 0.1401\n",
            "---- Epoch [2/5], Step [500/600], Loss: 0.1915\n",
            "---- Epoch [2/5], Step [600/600], Loss: 0.1226\n",
            "-- Completed Epoch [2/5]\n",
            "---- Epoch [3/5], Step [100/600], Loss: 0.0809\n",
            "---- Epoch [3/5], Step [200/600], Loss: 0.0658\n",
            "---- Epoch [3/5], Step [300/600], Loss: 0.0954\n",
            "---- Epoch [3/5], Step [400/600], Loss: 0.1334\n",
            "---- Epoch [3/5], Step [500/600], Loss: 0.0107\n",
            "---- Epoch [3/5], Step [600/600], Loss: 0.1574\n",
            "-- Completed Epoch [3/5]\n",
            "---- Epoch [4/5], Step [100/600], Loss: 0.0369\n",
            "---- Epoch [4/5], Step [200/600], Loss: 0.0292\n",
            "---- Epoch [4/5], Step [300/600], Loss: 0.0180\n",
            "---- Epoch [4/5], Step [400/600], Loss: 0.0743\n",
            "---- Epoch [4/5], Step [500/600], Loss: 0.0081\n",
            "---- Epoch [4/5], Step [600/600], Loss: 0.0837\n",
            "-- Completed Epoch [4/5]\n",
            "---- Epoch [5/5], Step [100/600], Loss: 0.0353\n",
            "---- Epoch [5/5], Step [200/600], Loss: 0.0462\n",
            "---- Epoch [5/5], Step [300/600], Loss: 0.0365\n",
            "---- Epoch [5/5], Step [400/600], Loss: 0.0625\n",
            "---- Epoch [5/5], Step [500/600], Loss: 0.0320\n",
            "---- Epoch [5/5], Step [600/600], Loss: 0.0503\n",
            "-- Completed Epoch [5/5]\n",
            "Training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mXH8TlQK-F8z"
      },
      "source": [
        "## Testing the FNN Model\n",
        "Similar to training the neural network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
        "\n",
        "1. No loss & weights calculation\n",
        "2. No weights update\n",
        "3. Has correct prediction calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ecuK9Uhv-QkW",
        "outputId": "09fe0c38-b946-4822-8469-f7ea0df68588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.view(-1, 28*28))\n",
        "    \n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "    \n",
        "    \n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "    total += labels.size(0)                    # Increment the total count\n",
        "    correct += (predicted == labels).sum()     # Increment the correct count\n",
        "    \n",
        "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10K test images: 98 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "euUuBcsv-Ubj"
      },
      "source": [
        "## Save the trained FNN Model for future use\n",
        "\n",
        "We save the trained model as a pickle that can be loaded and used later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R7cwJ42h-YFS",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "torch.save(net.state_dict(), 'fnn_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G_vAhL6mHYRs"
      },
      "source": [
        "The PyTorch serialization format is built off of pickle (.pkl) but it overrides some functionality to handle tensors that share the same backing storage.\n",
        "\n",
        "You can use [`torch.load`](https://pytorch.org/docs/stable/torch.html) to reload this model if you've saved this file.\n",
        "\n",
        "Note that if you call `torch.load() `on a file which contains GPU tensors, those tensors will be loaded to GPU by default. You can call torch.load(.., map_location='cpu') and then load_state_dict() to avoid GPU RAM surge when loading a model checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "66-h_Nhk-crO"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "You have done building your first Feedforward Neural Network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1suaQhD2-Aps"
      },
      "source": [
        "### End of notebook."
      ]
    }
  ]
}