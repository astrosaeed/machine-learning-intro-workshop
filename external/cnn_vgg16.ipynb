{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/external/cnn_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow only VGG16 CNN on Cifar10\n",
    "\n",
    "- From Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
    "    - Author: Sebastian Raschka\n",
    "    - GitHub Repository: https://github.com/rasbt/deeplearning-models\n",
    "\n",
    "Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "477SRaeM2R2d"
   },
   "source": [
    "# Model Zoo -- Convolutional Neural Network (VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1VdEiRD2R2i"
   },
   "source": [
    "The VGG-16 Convolutional Neural Network Architecture [1] implemented in TensorFlow and trained on Cifar-10 [2, 3] images.\n",
    "\n",
    "References:\n",
    "\n",
    "- [1] Simonyan, K., & Zisserman, A. (2015). [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556). International Conference on Learning Representations (ICRL), 1–14. https://doi.org/10.1016/j.infsof.2008.09.005\n",
    "- [2] Krizhevsky, A. (2009). [Learning Multiple Layers of Features from Tiny Images](https://doi.org/10.1.1.222.9220 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.222.9220&rep=rep1&type=pdf). Science Department, University of Toronto.\n",
    "- [3] https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yv_9rqxGA4ec"
   },
   "source": [
    "## VGG16 – Convolutional Network for Classification and Detection\n",
    "\n",
    "VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”. \n",
    "\n",
    "The model achieves **92.7% top-5 test accuracy** in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. It was one of the famous model submitted to ILSVRC-2014. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3×3 kernel-sized filters one after another.\n",
    "\n",
    "VGG16 was **trained for weeks** while using NVIDIA Titan Black GPU’s.\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <center><img src=\"../images/vgg16-1.png\" />\n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "  <center><img src=\"../images/vgg16-2.png\" />\n",
    "  <figcaption>Figure 1</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipyNZpesB5Qr"
   },
   "source": [
    "## ImageNet DataSet\n",
    "\n",
    "[**ImageNet**](http://www.image-net.org/) is a dataset of over 15 million labeled high-resolution images belonging to roughly 22,000 categories. The images were collected from the web and labeled by human labelers using Amazon’s Mechanical Turk crowd-sourcing tool. Starting in 2010, as part of the Pascal Visual Object Challenge, an annual competition called the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) has been held. ILSVRC uses a subset of ImageNet with roughly 1000 images in each of 1000 categories. In all, there are roughly 1.2 million training images, 50,000 validation images, and 150,000 testing images. ImageNet consists of variable-resolution images. Therefore, the images have been down-sampled to a fixed resolution of 256×256. Given a rectangular image, the image is rescaled and cropped out the central 256×256 patch from the resulting image.\n",
    "\n",
    "<figure>\n",
    "  <center><img src=\"../images/imageNet-easy-hard.png\" />\n",
    "  <figcaption>Figure 2</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "This set is **way too big** to train in this Colab notebook, so we'll use the much smaller (but still non-trivai CIFAR-10 set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boasd7FJCMu9"
   },
   "source": [
    "## CIFAR-10 DataSet\n",
    "\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <center><img src=\"../images/cifar10-classes.png\" />\n",
    "  <figcaption>Figure 2</figcaption></center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow only Convolutional Neural Network (VGG16)\n",
    "\n",
    "**Usage NOTE!** Use `Shift+Enter` to step through this notebook, executing the code as you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    VERBOSE=False    # True for extensive logging during execution.\n",
    "    QUIET=False      # True for minimal logging during execution.\n",
    "    WARNINGS=False   # True to enable display of annoying but rarely useful messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Trd1h_Zx7BbJ",
    "outputId": "e868d5c8-eff2-4fbd-8d23-f163c63e2a31"
   },
   "outputs": [],
   "source": [
    "#@title Check Runtime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import timeit\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# Suppress Tensorflow log spew.\n",
    "if not Context.WARNINGS:\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "try:\n",
    "   device_name = os.environ['COLAB_TPU_ADDR']\n",
    "   TPU_ADDRESS = 'grpc://' + device_name\n",
    "   print(f'Running with TPU acceleration at {TPU_ADDRESS}')\n",
    "except KeyError:\n",
    "  GPU_NAME = tf.test.gpu_device_name()\n",
    "  if GPU_NAME.startswith('/device:GPU'): \n",
    "      print(f\"Running with GPU acceleration at {GPU_NAME}\")\n",
    "  else:\n",
    "      print(\"Running on normal CPU without GPU acceleration.\")\n",
    "      print(\"This will be VERY VERY slow.\")\n",
    "      print(\"Consider changing the runtime type to GPU or NPU\")\n",
    "        \n",
    "def elapsed_time(func, *args, msg=''):\n",
    "    ''' Display the elapsed time of the function.\n",
    "        Return the function value.\n",
    "    '''\n",
    "    stime = time.time()\n",
    "    result = func(*args)\n",
    "    etime = time.time() - stime\n",
    "    log(msg + \"Elapsed test time: {0}\", timedelta(seconds=etime))\n",
    "    return result          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "labO2Cuu3IRV"
   },
   "outputs": [],
   "source": [
    "#@title Imports and Utility functions\n",
    "from urllib.request import urlretrieve\n",
    "import shutil\n",
    "import glob\n",
    "import tarfile\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "def download_and_extract_cifar(target_dir,\n",
    "                               cifar_url='http://www.cs.toronto.edu/'\n",
    "                               '~kriz/cifar-10-python.tar.gz'):\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "\n",
    "    fbase = os.path.basename(cifar_url)\n",
    "    fpath = os.path.join(target_dir, fbase)\n",
    "\n",
    "    if not os.path.exists(fpath):\n",
    "        def get_progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading ... %s %d%%' % (fbase,\n",
    "                             float(count * block_size) /\n",
    "                             float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        local_filename, headers = urlretrieve(cifar_url,\n",
    "                                              fpath,\n",
    "                                              reporthook=get_progress)\n",
    "        sys.stdout.write('\\nDownloaded')\n",
    "\n",
    "    else:\n",
    "        sys.stdout.write('Found existing')\n",
    "\n",
    "    statinfo = os.stat(fpath)\n",
    "    file_size = statinfo.st_size / 1024**2\n",
    "    sys.stdout.write(' %s (%.1f Mb)\\n' % (fbase, file_size))\n",
    "    sys.stdout.write('Extracting %s ...\\n' % fbase)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    with tarfile.open(fpath, 'r:gz') as t:\n",
    "        t.extractall(target_dir)\n",
    "\n",
    "    return fpath.replace('cifar-10-python.tar.gz', 'cifar-10-batches-py')\n",
    "\n",
    "def unpickle_cifar(fpath):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        dct = pickle.load(f, encoding='bytes')\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "McnOS2sq3VTs"
   },
   "outputs": [],
   "source": [
    "#@title Ciphar10Loader utility class\n",
    "\n",
    "class Cifar10Loader():\n",
    "    def __init__(self, cifar_path, normalize=False,\n",
    "                 channel_mean_center=False, zero_center=False):\n",
    "        self.cifar_path = cifar_path\n",
    "        self.batchnames = [os.path.join(self.cifar_path, f)\n",
    "                           for f in os.listdir(self.cifar_path)\n",
    "                           if f.startswith('data_batch')]\n",
    "        self.testname = os.path.join(self.cifar_path, 'test_batch')\n",
    "        self.num_train = self.count_train()\n",
    "        self.num_test = self.count_test()\n",
    "        self.normalize = normalize\n",
    "        self.channel_mean_center = channel_mean_center\n",
    "        self.zero_center = zero_center\n",
    "        self.train_mean = None\n",
    "\n",
    "    def _compute_train_mean(self):\n",
    "\n",
    "        cum_mean = np.zeros((1, 1, 1, 3))\n",
    "\n",
    "        for batch in self.batchnames:\n",
    "            dct = unpickle_cifar(batch)\n",
    "            dct[b'labels'] = np.array(dct[b'labels'], dtype=int)\n",
    "            dct[b'data'] = dct[b'data'].reshape(\n",
    "                dct[b'data'].shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "            mean = dct[b'data'].mean(axis=(0, 1, 2), keepdims=True)\n",
    "            cum_mean += mean\n",
    "\n",
    "        self.train_mean = cum_mean / len(self.batchnames)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def load_test(self, onehot=True):\n",
    "        dct = unpickle_cifar(self.testname)\n",
    "        dct[b'labels'] = np.array(dct[b'labels'], dtype=int)\n",
    "\n",
    "        dct[b'data'] = dct[b'data'].reshape(\n",
    "            dct[b'data'].shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "        if onehot:\n",
    "            dct[b'labels'] = (np.arange(10) ==\n",
    "                              dct[b'labels'][:, None]).astype(int)\n",
    "\n",
    "        if self.normalize:\n",
    "            dct[b'data'] = dct[b'data'].astype(np.float32)\n",
    "            dct[b'data'] = dct[b'data'] / 255.0\n",
    "\n",
    "        if self.channel_mean_center:\n",
    "            if self.train_mean is None:\n",
    "                self._compute_train_mean()\n",
    "            dct[b'data'] -= self.train_mean\n",
    "\n",
    "        if self.zero_center:\n",
    "            if self.normalize:\n",
    "                dct[b'data'] -= .5\n",
    "            else:\n",
    "                dct[b'data'] -= 127.5\n",
    "\n",
    "        return dct[b'data'], dct[b'labels']\n",
    "\n",
    "    def load_train_epoch(self, batch_size=50, onehot=True,\n",
    "                         shuffle=False, seed=None):\n",
    "\n",
    "        rgen = np.random.RandomState(seed)\n",
    "\n",
    "        for batch in self.batchnames:\n",
    "            dct = unpickle_cifar(batch)\n",
    "            dct[b'labels'] = np.array(dct[b'labels'], dtype=int)\n",
    "            dct[b'data'] = dct[b'data'].reshape(\n",
    "                dct[b'data'].shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "            if onehot:\n",
    "                dct[b'labels'] = (np.arange(10) ==\n",
    "                                  dct[b'labels'][:, None]).astype(int)\n",
    "\n",
    "            if self.normalize:\n",
    "                dct[b'data'] = dct[b'data'].astype(np.float32)\n",
    "                dct[b'data'] = dct[b'data'] / 255.0\n",
    "\n",
    "            if self.channel_mean_center:\n",
    "                if self.train_mean is None:\n",
    "                    self._compute_train_mean()\n",
    "                dct[b'data'] -= self.train_mean\n",
    "\n",
    "            if self.zero_center:\n",
    "                if self.normalize:\n",
    "                    dct[b'data'] -= .5\n",
    "                else:\n",
    "                    dct[b'data'] -= 127.5\n",
    "\n",
    "            arrays = [dct[b'data'], dct[b'labels']]\n",
    "            del dct\n",
    "            indices = np.arange(arrays[0].shape[0])\n",
    "\n",
    "            if shuffle:\n",
    "                rgen.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - batch_size + 1,\n",
    "                                   batch_size):\n",
    "                index_slice = indices[start_idx:start_idx + batch_size]\n",
    "                yield (ary[index_slice] for ary in arrays)\n",
    "\n",
    "    def count_train(self):\n",
    "        cnt = 0\n",
    "        for f in self.batchnames:\n",
    "            dct = unpickle_cifar(f)\n",
    "            cnt += len(dct[b'labels'])\n",
    "        return cnt\n",
    "\n",
    "    def count_test(self):\n",
    "        dct = unpickle_cifar(self.testname)\n",
    "        return len(dct[b'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "iQmKsdZD2R2l",
    "outputId": "d4e946b2-ff5a-4469-96f4-76b1e5c17b97"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "dest = download_and_extract_cifar('./cifar-10')\n",
    "cifar = Cifar10Loader(dest, normalize=True, \n",
    "                      zero_center=True,\n",
    "                      channel_mean_center=False)\n",
    "cifar.num_train\n",
    "\n",
    "X, y = cifar.load_test()\n",
    "half = cifar.num_test // 2\n",
    "X_test, X_valid = X[:half], X[half:]\n",
    "y_test, y_valid = y[:half], y[half:]\n",
    "\n",
    "del X, y\n",
    "\n",
    "print(\"Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# Other\n",
    "print_interval = 200\n",
    "\n",
    "# Architecture\n",
    "image_width, image_height, image_depth = 32, 32, 3\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### WRAPPER FUNCTIONS\n",
    "##########################\n",
    "\n",
    "def conv_layer(input, input_channels, output_channels, \n",
    "               kernel_size, strides, scope, padding='SAME'):\n",
    "    with tf.name_scope(scope):\n",
    "        weights_shape = kernel_size + [input_channels, output_channels]\n",
    "        weights = tf.Variable(tf.truncated_normal(shape=weights_shape,\n",
    "                                                  mean=0.0,\n",
    "                                                  stddev=0.1,\n",
    "                                                  dtype=tf.float32),\n",
    "                                                  name='weights')\n",
    "        biases = tf.Variable(tf.zeros(shape=[output_channels]),\n",
    "                             name='biases')\n",
    "        conv = tf.nn.conv2d(input=input,\n",
    "                            filter=weights,\n",
    "                            strides=strides,\n",
    "                            padding=padding,\n",
    "                            name='convolution')\n",
    "        out = tf.nn.bias_add(conv, biases, name='logits')\n",
    "        out = tf.nn.relu(out, name='activation')\n",
    "        return out\n",
    "\n",
    "\n",
    "def fc_layer(input, output_nodes, scope,\n",
    "             activation=None, seed=None):\n",
    "    with tf.name_scope(scope):\n",
    "        shape = int(np.prod(input.get_shape()[1:]))\n",
    "        flat_input = tf.reshape(input, [-1, shape])\n",
    "        weights = tf.Variable(tf.truncated_normal(shape=[shape,\n",
    "                                                         output_nodes],\n",
    "                                                  mean=0.0,\n",
    "                                                  stddev=0.1,\n",
    "                                                  dtype=tf.float32,\n",
    "                                                  seed=seed),\n",
    "                                                  name='weights')\n",
    "        biases = tf.Variable(tf.zeros(shape=[output_nodes]),\n",
    "                             name='biases')\n",
    "        act = tf.nn.bias_add(tf.matmul(flat_input, weights), biases, \n",
    "                             name='logits')\n",
    "\n",
    "        if activation is not None:\n",
    "            act = activation(act, name='activation')\n",
    "\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### GRAPH DEFINITION\n",
    "##########################\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "\n",
    "    # Input data\n",
    "    tf_x = tf.placeholder(tf.float32, [None, image_width, image_height, image_depth], name='features')\n",
    "    tf_y = tf.placeholder(tf.float32, [None, n_classes], name='targets')\n",
    "     \n",
    "    ##########################\n",
    "    ### VGG16 Model\n",
    "    ##########################\n",
    "\n",
    "    # =========\n",
    "    # BLOCK 1\n",
    "    # =========\n",
    "    conv_layer_1 = conv_layer(input=tf_x,\n",
    "                              input_channels=3,\n",
    "                              output_channels=64,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv1')\n",
    "    \n",
    "    conv_layer_2 = conv_layer(input=conv_layer_1,\n",
    "                              input_channels=64,\n",
    "                              output_channels=64,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv2')    \n",
    "    \n",
    "    pool_layer_1 = tf.nn.max_pool(conv_layer_2,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool1') \n",
    "    # =========\n",
    "    # BLOCK 2\n",
    "    # =========\n",
    "    conv_layer_3 = conv_layer(input=pool_layer_1,\n",
    "                              input_channels=64,\n",
    "                              output_channels=128,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv3')    \n",
    "    \n",
    "    conv_layer_4 = conv_layer(input=conv_layer_3,\n",
    "                              input_channels=128,\n",
    "                              output_channels=128,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv4')    \n",
    "    \n",
    "    pool_layer_2 = tf.nn.max_pool(conv_layer_4,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool2') \n",
    "    # =========\n",
    "    # BLOCK 3\n",
    "    # =========\n",
    "    conv_layer_5 = conv_layer(input=pool_layer_2,\n",
    "                              input_channels=128,\n",
    "                              output_channels=256,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv5')        \n",
    "    \n",
    "    conv_layer_6 = conv_layer(input=conv_layer_5,\n",
    "                              input_channels=256,\n",
    "                              output_channels=256,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv6')      \n",
    "    \n",
    "    conv_layer_7 = conv_layer(input=conv_layer_6,\n",
    "                              input_channels=256,\n",
    "                              output_channels=256,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv7')\n",
    "    \n",
    "    pool_layer_3 = tf.nn.max_pool(conv_layer_7,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool3') \n",
    "    # =========\n",
    "    # BLOCK 4\n",
    "    # =========\n",
    "    conv_layer_8 = conv_layer(input=pool_layer_3,\n",
    "                              input_channels=256,\n",
    "                              output_channels=512,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv8')      \n",
    "    \n",
    "    conv_layer_9 = conv_layer(input=conv_layer_8,\n",
    "                              input_channels=512,\n",
    "                              output_channels=512,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv9')     \n",
    "    \n",
    "    conv_layer_10 = conv_layer(input=conv_layer_9,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv10')   \n",
    "    \n",
    "    pool_layer_4 = tf.nn.max_pool(conv_layer_10,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool4') \n",
    "    # =========\n",
    "    # BLOCK 5\n",
    "    # =========\n",
    "    conv_layer_11 = conv_layer(input=pool_layer_4,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv11')   \n",
    "    \n",
    "    conv_layer_12 = conv_layer(input=conv_layer_11,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv12')   \n",
    "\n",
    "    conv_layer_13 = conv_layer(input=conv_layer_12,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv13') \n",
    "    \n",
    "    pool_layer_5 = tf.nn.max_pool(conv_layer_12,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool5')     \n",
    "    # ===========\n",
    "    # CLASSIFIER\n",
    "    # ===========\n",
    "    \n",
    "    fc_layer_1 = fc_layer(input=pool_layer_5, \n",
    "                          output_nodes=4096,\n",
    "                          activation=tf.nn.relu,\n",
    "                          scope='fc1')\n",
    "    \n",
    "    fc_layer_2 = fc_layer(input=fc_layer_1, \n",
    "                          output_nodes=4096,\n",
    "                          activation=tf.nn.relu,\n",
    "                          scope='fc2')\n",
    "\n",
    "    out_layer = fc_layer(input=fc_layer_2, \n",
    "                         output_nodes=n_classes,\n",
    "                         activation=None,\n",
    "                         scope='output_layer')\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=tf_y)\n",
    "    cost = tf.reduce_mean(loss, name='cost')\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost, name='train')\n",
    "\n",
    "    # Prediction\n",
    "    correct_prediction = tf.equal(tf.argmax(tf_y, 1), tf.argmax(out_layer, 1), \n",
    "                                  name='correct_predictions')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "    # Saver to save session for reuse\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ma-caY_G2R22",
    "outputId": "981eab5a-006e-4984-ab31-a2a60daeb0f6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TRAINING & EVALUATION\n",
    "##########################\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        avg_cost = 0.\n",
    "        mbatch_cnt = 0\n",
    "        for batch_x, batch_y in cifar.load_train_epoch(shuffle=True, batch_size=batch_size):\n",
    "            \n",
    "            mbatch_cnt += 1\n",
    "            _, c = sess.run(['train', 'cost:0'], feed_dict={'features:0': batch_x,\n",
    "                                                            'targets:0': batch_y})\n",
    "            avg_cost += c\n",
    "\n",
    "            if not mbatch_cnt % print_interval:\n",
    "                print(\"Minibatch: %04d | Cost: %.3f\" % (mbatch_cnt, c))\n",
    "                \n",
    "\n",
    "        # ===================\n",
    "        # Training Accuracy\n",
    "        # ===================\n",
    "        n_predictions, n_correct = 0, 0\n",
    "        for batch_x, batch_y in cifar.load_train_epoch(batch_size=batch_size):\n",
    "        \n",
    "            p = sess.run('correct_predictions:0', \n",
    "                         feed_dict={'features:0': batch_x,\n",
    "                                    'targets:0':  batch_y})\n",
    "            n_correct += np.sum(p)\n",
    "            n_predictions += p.shape[0]\n",
    "        train_acc = n_correct / n_predictions\n",
    "        \n",
    "        \n",
    "        # ===================\n",
    "        # Validation Accuracy\n",
    "        # ===================\n",
    "        #valid_acc = sess.run('accuracy:0', feed_dict={'features:0': X_valid,\n",
    "        #                                              'targets:0': y_valid})\n",
    "        # ---------------------------------------\n",
    "        # workaround for GPUs with <= 4 Gb memory\n",
    "        n_predictions, n_correct = 0, 0\n",
    "        indices = np.arange(y_valid.shape[0])\n",
    "        chunksize = 500\n",
    "        for start_idx in range(0, indices.shape[0] - chunksize + 1, chunksize):\n",
    "            index_slice = indices[start_idx:start_idx + chunksize]\n",
    "            p = sess.run('correct_predictions:0', \n",
    "                         feed_dict={'features:0': X_valid[index_slice],\n",
    "                                    'targets:0': y_valid[index_slice]})\n",
    "            n_correct += np.sum(p)\n",
    "            n_predictions += p.shape[0]\n",
    "        valid_acc = n_correct / n_predictions\n",
    "        # ---------------------------------------\n",
    "                                                \n",
    "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / mbatch_cnt), end=\"\")\n",
    "        print(\" | Train/Valid ACC: %.3f/%.3f\" % (train_acc, valid_acc))\n",
    "    \n",
    "    saver.save(sess, save_path='./convnet-vgg16.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxHwQnC493Wi"
   },
   "source": [
    "### Training Times\n",
    "\n",
    "- Even with a Colab GPU enabled, the 30 epochs for this set will take some time.\n",
    "\n",
    "- Expect this to take about 45 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "Ix78XNyU2R28",
    "outputId": "dcfddebd-adfd-416d-886b-4ec10214ced0"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### RELOAD & TEST\n",
    "##########################\n",
    "\n",
    "def train(g):\n",
    "    with tf.Session(graph=g) as sess:\n",
    "        saver.restore(sess, save_path='./convnet-vgg16.ckpt')\n",
    "\n",
    "        # test_acc = sess.run('accuracy:0', feed_dict={'features:0': X_test,\n",
    "        #                                              'targets:0': y_test})\n",
    "        # ---------------------------------------\n",
    "        # workaround for GPUs with <= 4 Gb memory\n",
    "        n_predictions, n_correct = 0, 0\n",
    "        indices = np.arange(y_test.shape[0])\n",
    "        chunksize = 500\n",
    "        for start_idx in range(0, indices.shape[0] - chunksize + 1, chunksize):\n",
    "            index_slice = indices[start_idx:start_idx + chunksize]\n",
    "            p = sess.run('correct_predictions:0', \n",
    "                         feed_dict={'features:0': X_test[index_slice],\n",
    "                                    'targets:0': y_test[index_slice]})\n",
    "            n_correct += np.sum(p)\n",
    "            n_predictions += p.shape[0]\n",
    "        test_acc = n_correct / n_predictions\n",
    "        # ---------------------------------------\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = time.time()\n",
    "\n",
    "test_acc = train(g)        \n",
    "\n",
    "etime = time.time() - stime\n",
    "print(f\"- Total training time: {timedelta(seconds=etime)}\")\n",
    "print(f'- Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HD1HqbuIEX-8"
   },
   "source": [
    "### Results\n",
    "\n",
    "With 30 epochs on a GPU in about 40 minutes, this model achieves about **78% test accuracy** in Cifar-10.  This very respectable for the limited training time.\n",
    "\n",
    "- The [best performance so far](https://benchmarks.ai/cifar-10) is well beyond human at 99%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BQR_DcFEaw6"
   },
   "source": [
    "### End of notebook."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "cnn_vgg16.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
