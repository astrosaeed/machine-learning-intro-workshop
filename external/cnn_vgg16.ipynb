{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "cnn_vgg16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/external/cnn_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXGRwMfa2R1j",
        "colab_type": "text"
      },
      "source": [
        "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
        "- Author: Sebastian Raschka\n",
        "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "477SRaeM2R2d",
        "colab_type": "text"
      },
      "source": [
        "# Model Zoo -- Convolutional Neural Network (VGG16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1VdEiRD2R2i",
        "colab_type": "text"
      },
      "source": [
        "The VGG-16 Convolutional Neural Network Architecture [1] implemented in TensorFlow and trained on Cifar-10 [2, 3] images.\n",
        "\n",
        "References:\n",
        "\n",
        "- [1] Simonyan, K., & Zisserman, A. (2015). [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556). International Conference on Learning Representations (ICRL), 1–14. https://doi.org/10.1016/j.infsof.2008.09.005\n",
        "- [2] Krizhevsky, A. (2009). [Learning Multiple Layers of Features from Tiny Images](https://doi.org/10.1.1.222.9220 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.222.9220&rep=rep1&type=pdf). Science Department, University of Toronto.\n",
        "- [3] https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv_9rqxGA4ec",
        "colab_type": "text"
      },
      "source": [
        "## VGG16 – Convolutional Network for Classification and Detection\n",
        "\n",
        "VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”. \n",
        "\n",
        "The model achieves **92.7% top-5 test accuracy** in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. It was one of the famous model submitted to ILSVRC-2014. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3×3 kernel-sized filters one after another.\n",
        "\n",
        "VGG16 was **trained for weeks** while using NVIDIA Titan Black GPU’s.\n",
        "\n",
        "\n",
        "<figure>\n",
        "  <center><img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\" />\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "<figure>\n",
        "  <center><img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16.png\" />\n",
        "  <figcaption>Figure 1</figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipyNZpesB5Qr",
        "colab_type": "text"
      },
      "source": [
        "## ImageNet DataSet\n",
        "\n",
        "[**ImageNet**](http://www.image-net.org/) is a dataset of over 15 million labeled high-resolution images belonging to roughly 22,000 categories. The images were collected from the web and labeled by human labelers using Amazon’s Mechanical Turk crowd-sourcing tool. Starting in 2010, as part of the Pascal Visual Object Challenge, an annual competition called the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) has been held. ILSVRC uses a subset of ImageNet with roughly 1000 images in each of 1000 categories. In all, there are roughly 1.2 million training images, 50,000 validation images, and 150,000 testing images. ImageNet consists of variable-resolution images. Therefore, the images have been down-sampled to a fixed resolution of 256×256. Given a rectangular image, the image is rescaled and cropped out the central 256×256 patch from the resulting image.\n",
        "\n",
        "<figure>\n",
        "  <center><img src=\"https://cdn.technologyreview.com/i/images/Object%20recognition.png\" />\n",
        "  <figcaption>Figure 2</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "This set is **way too big** to train in this Colab notebook, so we'll use the much smaller (but still non-trivai CIFAR-10 set).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boasd7FJCMu9",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR-10 DataSet\n",
        "\n",
        "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
        "\n",
        "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
        "\n",
        "Here are the classes in the dataset, as well as 10 random images from each:\n",
        "\n",
        "\n",
        "<figure>\n",
        "  <center><img src=\"https://cafe-and-cookies.tokyo/wp/wp-content/uploads/2019/03/img_5c828f2715196.png\" />\n",
        "  <figcaption>Figure 2</figcaption></center>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trd1h_Zx7BbJ",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "e868d5c8-eff2-4fbd-8d23-f163c63e2a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Check Runtime\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "   device_name = os.environ['COLAB_TPU_ADDR']\n",
        "   TPU_ADDRESS = 'grpc://' + device_name\n",
        "   print(f'Running with TPU acceleration at {TPU_ADDRESS}')\n",
        "except KeyError:\n",
        "  GPU_NAME = tf.test.gpu_device_name()\n",
        "  if GPU_NAME.startswith('/device:GPU'): \n",
        "      print(f\"Running with GPU acceleration at {GPU_NAME}\")\n",
        "  else:\n",
        "      print(\"Running on normal CPU without GPU acceleration.\")\n",
        "      print(\"This will be VERY VERY slow.\")\n",
        "      print(\"Consider changing the runtime type to GPU or NPU\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running with GPU acceleration at /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "labO2Cuu3IRV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Imports and Utility functions\n",
        "from urllib.request import urlretrieve\n",
        "import shutil\n",
        "import glob\n",
        "import tarfile\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "def download_and_extract_cifar(target_dir,\n",
        "                               cifar_url='http://www.cs.toronto.edu/'\n",
        "                               '~kriz/cifar-10-python.tar.gz'):\n",
        "\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.mkdir(target_dir)\n",
        "\n",
        "    fbase = os.path.basename(cifar_url)\n",
        "    fpath = os.path.join(target_dir, fbase)\n",
        "\n",
        "    if not os.path.exists(fpath):\n",
        "        def get_progress(count, block_size, total_size):\n",
        "            sys.stdout.write('\\rDownloading ... %s %d%%' % (fbase,\n",
        "                             float(count * block_size) /\n",
        "                             float(total_size) * 100.0))\n",
        "            sys.stdout.flush()\n",
        "        local_filename, headers = urlretrieve(cifar_url,\n",
        "                                              fpath,\n",
        "                                              reporthook=get_progress)\n",
        "        sys.stdout.write('\\nDownloaded')\n",
        "\n",
        "    else:\n",
        "        sys.stdout.write('Found existing')\n",
        "\n",
        "    statinfo = os.stat(fpath)\n",
        "    file_size = statinfo.st_size / 1024**2\n",
        "    sys.stdout.write(' %s (%.1f Mb)\\n' % (fbase, file_size))\n",
        "    sys.stdout.write('Extracting %s ...\\n' % fbase)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    with tarfile.open(fpath, 'r:gz') as t:\n",
        "        t.extractall(target_dir)\n",
        "\n",
        "    return fpath.replace('cifar-10-python.tar.gz', 'cifar-10-batches-py')\n",
        "\n",
        "def unpickle_cifar(fpath):\n",
        "    with open(fpath, 'rb') as f:\n",
        "        dct = pickle.load(f, encoding='bytes')\n",
        "    return dct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McnOS2sq3VTs",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Ciphar10Loader utility class\n",
        "\n",
        "class Cifar10Loader():\n",
        "    def __init__(self, cifar_path, normalize=False,\n",
        "                 channel_mean_center=False, zero_center=False):\n",
        "        self.cifar_path = cifar_path\n",
        "        self.batchnames = [os.path.join(self.cifar_path, f)\n",
        "                           for f in os.listdir(self.cifar_path)\n",
        "                           if f.startswith('data_batch')]\n",
        "        self.testname = os.path.join(self.cifar_path, 'test_batch')\n",
        "        self.num_train = self.count_train()\n",
        "        self.num_test = self.count_test()\n",
        "        self.normalize = normalize\n",
        "        self.channel_mean_center = channel_mean_center\n",
        "        self.zero_center = zero_center\n",
        "        self.train_mean = None\n",
        "\n",
        "    def _compute_train_mean(self):\n",
        "\n",
        "        cum_mean = np.zeros((1, 1, 1, 3))\n",
        "\n",
        "        for batch in self.batchnames:\n",
        "            dct = unpickle_cifar(batch)\n",
        "            dct[b'labels'] = np.array(dct[b'labels'], dtype=int)\n",
        "            dct[b'data'] = dct[b'data'].reshape(\n",
        "                dct[b'data'].shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "            mean = dct[b'data'].mean(axis=(0, 1, 2), keepdims=True)\n",
        "            cum_mean += mean\n",
        "\n",
        "        self.train_mean = cum_mean / len(self.batchnames)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def load_test(self, onehot=True):\n",
        "        dct = unpickle_cifar(self.testname)\n",
        "        dct[b'labels'] = np.array(dct[b'labels'], dtype=int)\n",
        "\n",
        "        dct[b'data'] = dct[b'data'].reshape(\n",
        "            dct[b'data'].shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "\n",
        "        if onehot:\n",
        "            dct[b'labels'] = (np.arange(10) ==\n",
        "                              dct[b'labels'][:, None]).astype(int)\n",
        "\n",
        "        if self.normalize:\n",
        "            dct[b'data'] = dct[b'data'].astype(np.float32)\n",
        "            dct[b'data'] = dct[b'data'] / 255.0\n",
        "\n",
        "        if self.channel_mean_center:\n",
        "            if self.train_mean is None:\n",
        "                self._compute_train_mean()\n",
        "            dct[b'data'] -= self.train_mean\n",
        "\n",
        "        if self.zero_center:\n",
        "            if self.normalize:\n",
        "                dct[b'data'] -= .5\n",
        "            else:\n",
        "                dct[b'data'] -= 127.5\n",
        "\n",
        "        return dct[b'data'], dct[b'labels']\n",
        "\n",
        "    def load_train_epoch(self, batch_size=50, onehot=True,\n",
        "                         shuffle=False, seed=None):\n",
        "\n",
        "        rgen = np.random.RandomState(seed)\n",
        "\n",
        "        for batch in self.batchnames:\n",
        "            dct = unpickle_cifar(batch)\n",
        "            dct[b'labels'] = np.array(dct[b'labels'], dtype=int)\n",
        "            dct[b'data'] = dct[b'data'].reshape(\n",
        "                dct[b'data'].shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "\n",
        "            if onehot:\n",
        "                dct[b'labels'] = (np.arange(10) ==\n",
        "                                  dct[b'labels'][:, None]).astype(int)\n",
        "\n",
        "            if self.normalize:\n",
        "                dct[b'data'] = dct[b'data'].astype(np.float32)\n",
        "                dct[b'data'] = dct[b'data'] / 255.0\n",
        "\n",
        "            if self.channel_mean_center:\n",
        "                if self.train_mean is None:\n",
        "                    self._compute_train_mean()\n",
        "                dct[b'data'] -= self.train_mean\n",
        "\n",
        "            if self.zero_center:\n",
        "                if self.normalize:\n",
        "                    dct[b'data'] -= .5\n",
        "                else:\n",
        "                    dct[b'data'] -= 127.5\n",
        "\n",
        "            arrays = [dct[b'data'], dct[b'labels']]\n",
        "            del dct\n",
        "            indices = np.arange(arrays[0].shape[0])\n",
        "\n",
        "            if shuffle:\n",
        "                rgen.shuffle(indices)\n",
        "\n",
        "            for start_idx in range(0, indices.shape[0] - batch_size + 1,\n",
        "                                   batch_size):\n",
        "                index_slice = indices[start_idx:start_idx + batch_size]\n",
        "                yield (ary[index_slice] for ary in arrays)\n",
        "\n",
        "    def count_train(self):\n",
        "        cnt = 0\n",
        "        for f in self.batchnames:\n",
        "            dct = unpickle_cifar(f)\n",
        "            cnt += len(dct[b'labels'])\n",
        "        return cnt\n",
        "\n",
        "    def count_test(self):\n",
        "        dct = unpickle_cifar(self.testname)\n",
        "        return len(dct[b'labels'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQmKsdZD2R2l",
        "colab_type": "code",
        "outputId": "d4e946b2-ff5a-4469-96f4-76b1e5c17b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "##########################\n",
        "### DATASET\n",
        "##########################\n",
        "\n",
        "dest = download_and_extract_cifar('./cifar-10')\n",
        "cifar = Cifar10Loader(dest, normalize=True, \n",
        "                      zero_center=True,\n",
        "                      channel_mean_center=False)\n",
        "cifar.num_train\n",
        "\n",
        "X, y = cifar.load_test()\n",
        "half = cifar.num_test // 2\n",
        "X_test, X_valid = X[:half], X[half:]\n",
        "y_test, y_valid = y[:half], y[half:]\n",
        "\n",
        "del X, y\n",
        "\n",
        "print(\"Ready.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ... cifar-10-python.tar.gz 100%\n",
            "Downloaded cifar-10-python.tar.gz (162.6 Mb)\n",
            "Extracting cifar-10-python.tar.gz ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Ma-caY_G2R22",
        "colab_type": "code",
        "outputId": "981eab5a-006e-4984-ab31-a2a60daeb0f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# Other\n",
        "print_interval = 200\n",
        "\n",
        "# Architecture\n",
        "image_width, image_height, image_depth = 32, 32, 3\n",
        "n_classes = 10\n",
        "\n",
        "\n",
        "##########################\n",
        "### WRAPPER FUNCTIONS\n",
        "##########################\n",
        "\n",
        "def conv_layer(input, input_channels, output_channels, \n",
        "               kernel_size, strides, scope, padding='SAME'):\n",
        "    with tf.name_scope(scope):\n",
        "        weights_shape = kernel_size + [input_channels, output_channels]\n",
        "        weights = tf.Variable(tf.truncated_normal(shape=weights_shape,\n",
        "                                                  mean=0.0,\n",
        "                                                  stddev=0.1,\n",
        "                                                  dtype=tf.float32),\n",
        "                                                  name='weights')\n",
        "        biases = tf.Variable(tf.zeros(shape=[output_channels]),\n",
        "                             name='biases')\n",
        "        conv = tf.nn.conv2d(input=input,\n",
        "                            filter=weights,\n",
        "                            strides=strides,\n",
        "                            padding=padding,\n",
        "                            name='convolution')\n",
        "        out = tf.nn.bias_add(conv, biases, name='logits')\n",
        "        out = tf.nn.relu(out, name='activation')\n",
        "        return out\n",
        "\n",
        "\n",
        "def fc_layer(input, output_nodes, scope,\n",
        "             activation=None, seed=None):\n",
        "    with tf.name_scope(scope):\n",
        "        shape = int(np.prod(input.get_shape()[1:]))\n",
        "        flat_input = tf.reshape(input, [-1, shape])\n",
        "        weights = tf.Variable(tf.truncated_normal(shape=[shape,\n",
        "                                                         output_nodes],\n",
        "                                                  mean=0.0,\n",
        "                                                  stddev=0.1,\n",
        "                                                  dtype=tf.float32,\n",
        "                                                  seed=seed),\n",
        "                                                  name='weights')\n",
        "        biases = tf.Variable(tf.zeros(shape=[output_nodes]),\n",
        "                             name='biases')\n",
        "        act = tf.nn.bias_add(tf.matmul(flat_input, weights), biases, \n",
        "                             name='logits')\n",
        "\n",
        "        if activation is not None:\n",
        "            act = activation(act, name='activation')\n",
        "\n",
        "        return act\n",
        "\n",
        "\n",
        "##########################\n",
        "### GRAPH DEFINITION\n",
        "##########################\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "\n",
        "    # Input data\n",
        "    tf_x = tf.placeholder(tf.float32, [None, image_width, image_height, image_depth], name='features')\n",
        "    tf_y = tf.placeholder(tf.float32, [None, n_classes], name='targets')\n",
        "     \n",
        "    ##########################\n",
        "    ### VGG16 Model\n",
        "    ##########################\n",
        "\n",
        "    # =========\n",
        "    # BLOCK 1\n",
        "    # =========\n",
        "    conv_layer_1 = conv_layer(input=tf_x,\n",
        "                              input_channels=3,\n",
        "                              output_channels=64,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv1')\n",
        "    \n",
        "    conv_layer_2 = conv_layer(input=conv_layer_1,\n",
        "                              input_channels=64,\n",
        "                              output_channels=64,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv2')    \n",
        "    \n",
        "    pool_layer_1 = tf.nn.max_pool(conv_layer_2,\n",
        "                                  ksize=[1, 2, 2, 1], \n",
        "                                  strides=[1, 2, 2, 1],\n",
        "                                  padding='SAME',\n",
        "                                  name='pool1') \n",
        "    # =========\n",
        "    # BLOCK 2\n",
        "    # =========\n",
        "    conv_layer_3 = conv_layer(input=pool_layer_1,\n",
        "                              input_channels=64,\n",
        "                              output_channels=128,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv3')    \n",
        "    \n",
        "    conv_layer_4 = conv_layer(input=conv_layer_3,\n",
        "                              input_channels=128,\n",
        "                              output_channels=128,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv4')    \n",
        "    \n",
        "    pool_layer_2 = tf.nn.max_pool(conv_layer_4,\n",
        "                                  ksize=[1, 2, 2, 1], \n",
        "                                  strides=[1, 2, 2, 1],\n",
        "                                  padding='SAME',\n",
        "                                  name='pool2') \n",
        "    # =========\n",
        "    # BLOCK 3\n",
        "    # =========\n",
        "    conv_layer_5 = conv_layer(input=pool_layer_2,\n",
        "                              input_channels=128,\n",
        "                              output_channels=256,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv5')        \n",
        "    \n",
        "    conv_layer_6 = conv_layer(input=conv_layer_5,\n",
        "                              input_channels=256,\n",
        "                              output_channels=256,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv6')      \n",
        "    \n",
        "    conv_layer_7 = conv_layer(input=conv_layer_6,\n",
        "                              input_channels=256,\n",
        "                              output_channels=256,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv7')\n",
        "    \n",
        "    pool_layer_3 = tf.nn.max_pool(conv_layer_7,\n",
        "                                  ksize=[1, 2, 2, 1], \n",
        "                                  strides=[1, 2, 2, 1],\n",
        "                                  padding='SAME',\n",
        "                                  name='pool3') \n",
        "    # =========\n",
        "    # BLOCK 4\n",
        "    # =========\n",
        "    conv_layer_8 = conv_layer(input=pool_layer_3,\n",
        "                              input_channels=256,\n",
        "                              output_channels=512,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv8')      \n",
        "    \n",
        "    conv_layer_9 = conv_layer(input=conv_layer_8,\n",
        "                              input_channels=512,\n",
        "                              output_channels=512,\n",
        "                              kernel_size=[3, 3],\n",
        "                              strides=[1, 1, 1, 1],\n",
        "                              scope='conv9')     \n",
        "    \n",
        "    conv_layer_10 = conv_layer(input=conv_layer_9,\n",
        "                               input_channels=512,\n",
        "                               output_channels=512,\n",
        "                               kernel_size=[3, 3],\n",
        "                               strides=[1, 1, 1, 1],\n",
        "                               scope='conv10')   \n",
        "    \n",
        "    pool_layer_4 = tf.nn.max_pool(conv_layer_10,\n",
        "                                  ksize=[1, 2, 2, 1], \n",
        "                                  strides=[1, 2, 2, 1],\n",
        "                                  padding='SAME',\n",
        "                                  name='pool4') \n",
        "    # =========\n",
        "    # BLOCK 5\n",
        "    # =========\n",
        "    conv_layer_11 = conv_layer(input=pool_layer_4,\n",
        "                               input_channels=512,\n",
        "                               output_channels=512,\n",
        "                               kernel_size=[3, 3],\n",
        "                               strides=[1, 1, 1, 1],\n",
        "                               scope='conv11')   \n",
        "    \n",
        "    conv_layer_12 = conv_layer(input=conv_layer_11,\n",
        "                               input_channels=512,\n",
        "                               output_channels=512,\n",
        "                               kernel_size=[3, 3],\n",
        "                               strides=[1, 1, 1, 1],\n",
        "                               scope='conv12')   \n",
        "\n",
        "    conv_layer_13 = conv_layer(input=conv_layer_12,\n",
        "                               input_channels=512,\n",
        "                               output_channels=512,\n",
        "                               kernel_size=[3, 3],\n",
        "                               strides=[1, 1, 1, 1],\n",
        "                               scope='conv13') \n",
        "    \n",
        "    pool_layer_5 = tf.nn.max_pool(conv_layer_12,\n",
        "                                  ksize=[1, 2, 2, 1], \n",
        "                                  strides=[1, 2, 2, 1],\n",
        "                                  padding='SAME',\n",
        "                                  name='pool5')     \n",
        "    # ===========\n",
        "    # CLASSIFIER\n",
        "    # ===========\n",
        "    \n",
        "    fc_layer_1 = fc_layer(input=pool_layer_5, \n",
        "                          output_nodes=4096,\n",
        "                          activation=tf.nn.relu,\n",
        "                          scope='fc1')\n",
        "    \n",
        "    fc_layer_2 = fc_layer(input=fc_layer_1, \n",
        "                          output_nodes=4096,\n",
        "                          activation=tf.nn.relu,\n",
        "                          scope='fc2')\n",
        "\n",
        "    out_layer = fc_layer(input=fc_layer_2, \n",
        "                         output_nodes=n_classes,\n",
        "                         activation=None,\n",
        "                         scope='output_layer')\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=tf_y)\n",
        "    cost = tf.reduce_mean(loss, name='cost')\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train = optimizer.minimize(cost, name='train')\n",
        "\n",
        "    # Prediction\n",
        "    correct_prediction = tf.equal(tf.argmax(tf_y, 1), tf.argmax(out_layer, 1), \n",
        "                                  name='correct_predictions')\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "\n",
        "    # Saver to save session for reuse\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    \n",
        "##########################\n",
        "### TRAINING & EVALUATION\n",
        "##########################\n",
        "\n",
        "with tf.Session(graph=g) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        avg_cost = 0.\n",
        "        mbatch_cnt = 0\n",
        "        for batch_x, batch_y in cifar.load_train_epoch(shuffle=True, batch_size=batch_size):\n",
        "            \n",
        "            mbatch_cnt += 1\n",
        "            _, c = sess.run(['train', 'cost:0'], feed_dict={'features:0': batch_x,\n",
        "                                                            'targets:0': batch_y})\n",
        "            avg_cost += c\n",
        "\n",
        "            if not mbatch_cnt % print_interval:\n",
        "                print(\"Minibatch: %04d | Cost: %.3f\" % (mbatch_cnt, c))\n",
        "                \n",
        "\n",
        "        # ===================\n",
        "        # Training Accuracy\n",
        "        # ===================\n",
        "        n_predictions, n_correct = 0, 0\n",
        "        for batch_x, batch_y in cifar.load_train_epoch(batch_size=batch_size):\n",
        "        \n",
        "            p = sess.run('correct_predictions:0', \n",
        "                         feed_dict={'features:0': batch_x,\n",
        "                                    'targets:0':  batch_y})\n",
        "            n_correct += np.sum(p)\n",
        "            n_predictions += p.shape[0]\n",
        "        train_acc = n_correct / n_predictions\n",
        "        \n",
        "        \n",
        "        # ===================\n",
        "        # Validation Accuracy\n",
        "        # ===================\n",
        "        #valid_acc = sess.run('accuracy:0', feed_dict={'features:0': X_valid,\n",
        "        #                                              'targets:0': y_valid})\n",
        "        # ---------------------------------------\n",
        "        # workaround for GPUs with <= 4 Gb memory\n",
        "        n_predictions, n_correct = 0, 0\n",
        "        indices = np.arange(y_valid.shape[0])\n",
        "        chunksize = 500\n",
        "        for start_idx in range(0, indices.shape[0] - chunksize + 1, chunksize):\n",
        "            index_slice = indices[start_idx:start_idx + chunksize]\n",
        "            p = sess.run('correct_predictions:0', \n",
        "                         feed_dict={'features:0': X_valid[index_slice],\n",
        "                                    'targets:0': y_valid[index_slice]})\n",
        "            n_correct += np.sum(p)\n",
        "            n_predictions += p.shape[0]\n",
        "        valid_acc = n_correct / n_predictions\n",
        "        # ---------------------------------------\n",
        "                                                \n",
        "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / mbatch_cnt), end=\"\")\n",
        "        print(\" | Train/Valid ACC: %.3f/%.3f\" % (train_acc, valid_acc))\n",
        "    \n",
        "    saver.save(sess, save_path='./convnet-vgg16.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0813 21:47:31.524140 140361440728960 deprecation.py:323] From <ipython-input-7-6aaaad946b04>:227: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Minibatch: 0200 | Cost: 5.968\n",
            "Minibatch: 0400 | Cost: 3.273\n",
            "Minibatch: 0600 | Cost: 2.727\n",
            "Minibatch: 0800 | Cost: 2.259\n",
            "Minibatch: 1000 | Cost: 2.265\n",
            "Minibatch: 1200 | Cost: 2.474\n",
            "Minibatch: 1400 | Cost: 2.419\n",
            "Epoch: 001 | AvgCost: 1905.048 | Train/Valid ACC: 0.220/0.217\n",
            "Minibatch: 0200 | Cost: 2.247\n",
            "Minibatch: 0400 | Cost: 2.108\n",
            "Minibatch: 0600 | Cost: 2.337\n",
            "Minibatch: 0800 | Cost: 2.016\n",
            "Minibatch: 1000 | Cost: 2.184\n",
            "Minibatch: 1200 | Cost: 1.755\n",
            "Minibatch: 1400 | Cost: 1.791\n",
            "Epoch: 002 | AvgCost: 2.068 | Train/Valid ACC: 0.258/0.259\n",
            "Minibatch: 0200 | Cost: 1.890\n",
            "Minibatch: 0400 | Cost: 2.112\n",
            "Minibatch: 0600 | Cost: 2.091\n",
            "Minibatch: 0800 | Cost: 1.867\n",
            "Minibatch: 1000 | Cost: 1.530\n",
            "Minibatch: 1200 | Cost: 1.793\n",
            "Minibatch: 1400 | Cost: 1.827\n",
            "Epoch: 003 | AvgCost: 1.908 | Train/Valid ACC: 0.290/0.285\n",
            "Minibatch: 0200 | Cost: 1.942\n",
            "Minibatch: 0400 | Cost: 1.841\n",
            "Minibatch: 0600 | Cost: 1.783\n",
            "Minibatch: 0800 | Cost: 1.823\n",
            "Minibatch: 1000 | Cost: 1.741\n",
            "Minibatch: 1200 | Cost: 2.216\n",
            "Minibatch: 1400 | Cost: 1.604\n",
            "Epoch: 004 | AvgCost: 1.798 | Train/Valid ACC: 0.361/0.355\n",
            "Minibatch: 0200 | Cost: 1.762\n",
            "Minibatch: 0400 | Cost: 1.781\n",
            "Minibatch: 0600 | Cost: 1.891\n",
            "Minibatch: 0800 | Cost: 1.786\n",
            "Minibatch: 1000 | Cost: 1.812\n",
            "Minibatch: 1200 | Cost: 1.616\n",
            "Minibatch: 1400 | Cost: 1.686\n",
            "Epoch: 005 | AvgCost: 1.703 | Train/Valid ACC: 0.400/0.378\n",
            "Minibatch: 0200 | Cost: 1.558\n",
            "Minibatch: 0400 | Cost: 1.719\n",
            "Minibatch: 0600 | Cost: 1.187\n",
            "Minibatch: 0800 | Cost: 1.341\n",
            "Minibatch: 1000 | Cost: 1.644\n",
            "Minibatch: 1200 | Cost: 1.494\n",
            "Minibatch: 1400 | Cost: 1.634\n",
            "Epoch: 006 | AvgCost: 1.627 | Train/Valid ACC: 0.430/0.416\n",
            "Minibatch: 0200 | Cost: 1.618\n",
            "Minibatch: 0400 | Cost: 1.593\n",
            "Minibatch: 0600 | Cost: 1.041\n",
            "Minibatch: 0800 | Cost: 1.496\n",
            "Minibatch: 1000 | Cost: 1.589\n",
            "Minibatch: 1200 | Cost: 1.508\n",
            "Minibatch: 1400 | Cost: 1.493\n",
            "Epoch: 007 | AvgCost: 1.540 | Train/Valid ACC: 0.485/0.472\n",
            "Minibatch: 0200 | Cost: 1.646\n",
            "Minibatch: 0400 | Cost: 1.460\n",
            "Minibatch: 0600 | Cost: 1.683\n",
            "Minibatch: 0800 | Cost: 1.387\n",
            "Minibatch: 1000 | Cost: 1.273\n",
            "Minibatch: 1200 | Cost: 1.857\n",
            "Minibatch: 1400 | Cost: 1.757\n",
            "Epoch: 008 | AvgCost: 1.459 | Train/Valid ACC: 0.474/0.462\n",
            "Minibatch: 0200 | Cost: 1.479\n",
            "Minibatch: 0400 | Cost: 1.350\n",
            "Minibatch: 0600 | Cost: 1.531\n",
            "Minibatch: 0800 | Cost: 1.260\n",
            "Minibatch: 1000 | Cost: 1.275\n",
            "Minibatch: 1200 | Cost: 1.317\n",
            "Minibatch: 1400 | Cost: 1.410\n",
            "Epoch: 009 | AvgCost: 1.359 | Train/Valid ACC: 0.546/0.521\n",
            "Minibatch: 0200 | Cost: 1.229\n",
            "Minibatch: 0400 | Cost: 1.389\n",
            "Minibatch: 0600 | Cost: 1.076\n",
            "Minibatch: 0800 | Cost: 1.371\n",
            "Minibatch: 1000 | Cost: 1.044\n",
            "Minibatch: 1200 | Cost: 1.595\n",
            "Minibatch: 1400 | Cost: 1.177\n",
            "Epoch: 010 | AvgCost: 1.244 | Train/Valid ACC: 0.574/0.553\n",
            "Minibatch: 0200 | Cost: 1.082\n",
            "Minibatch: 0400 | Cost: 1.061\n",
            "Minibatch: 0600 | Cost: 1.188\n",
            "Minibatch: 0800 | Cost: 1.144\n",
            "Minibatch: 1000 | Cost: 1.433\n",
            "Minibatch: 1200 | Cost: 1.544\n",
            "Minibatch: 1400 | Cost: 1.011\n",
            "Epoch: 011 | AvgCost: 1.143 | Train/Valid ACC: 0.638/0.610\n",
            "Minibatch: 0200 | Cost: 1.164\n",
            "Minibatch: 0400 | Cost: 0.954\n",
            "Minibatch: 0600 | Cost: 0.975\n",
            "Minibatch: 0800 | Cost: 0.740\n",
            "Minibatch: 1000 | Cost: 1.106\n",
            "Minibatch: 1200 | Cost: 0.976\n",
            "Minibatch: 1400 | Cost: 0.925\n",
            "Epoch: 012 | AvgCost: 1.055 | Train/Valid ACC: 0.662/0.633\n",
            "Minibatch: 0200 | Cost: 0.978\n",
            "Minibatch: 0400 | Cost: 0.662\n",
            "Minibatch: 0600 | Cost: 0.905\n",
            "Minibatch: 0800 | Cost: 0.808\n",
            "Minibatch: 1000 | Cost: 1.088\n",
            "Minibatch: 1200 | Cost: 1.054\n",
            "Minibatch: 1400 | Cost: 0.771\n",
            "Epoch: 013 | AvgCost: 0.999 | Train/Valid ACC: 0.679/0.651\n",
            "Minibatch: 0200 | Cost: 0.585\n",
            "Minibatch: 0400 | Cost: 0.739\n",
            "Minibatch: 0600 | Cost: 0.754\n",
            "Minibatch: 0800 | Cost: 0.917\n",
            "Minibatch: 1000 | Cost: 1.074\n",
            "Minibatch: 1200 | Cost: 0.916\n",
            "Minibatch: 1400 | Cost: 0.697\n",
            "Epoch: 014 | AvgCost: 0.919 | Train/Valid ACC: 0.711/0.671\n",
            "Minibatch: 0200 | Cost: 0.725\n",
            "Minibatch: 0400 | Cost: 0.905\n",
            "Minibatch: 0600 | Cost: 0.727\n",
            "Minibatch: 0800 | Cost: 0.748\n",
            "Minibatch: 1000 | Cost: 0.902\n",
            "Minibatch: 1200 | Cost: 1.115\n",
            "Minibatch: 1400 | Cost: 0.921\n",
            "Epoch: 015 | AvgCost: 0.852 | Train/Valid ACC: 0.747/0.694\n",
            "Minibatch: 0200 | Cost: 0.870\n",
            "Minibatch: 0400 | Cost: 0.773\n",
            "Minibatch: 0600 | Cost: 0.922\n",
            "Minibatch: 0800 | Cost: 0.587\n",
            "Minibatch: 1000 | Cost: 0.403\n",
            "Minibatch: 1200 | Cost: 0.696\n",
            "Minibatch: 1400 | Cost: 0.981\n",
            "Epoch: 016 | AvgCost: 0.795 | Train/Valid ACC: 0.726/0.678\n",
            "Minibatch: 0200 | Cost: 0.773\n",
            "Minibatch: 0400 | Cost: 1.268\n",
            "Minibatch: 0600 | Cost: 0.978\n",
            "Minibatch: 0800 | Cost: 0.864\n",
            "Minibatch: 1000 | Cost: 0.658\n",
            "Minibatch: 1200 | Cost: 0.856\n",
            "Minibatch: 1400 | Cost: 0.628\n",
            "Epoch: 017 | AvgCost: 0.743 | Train/Valid ACC: 0.785/0.724\n",
            "Minibatch: 0200 | Cost: 0.738\n",
            "Minibatch: 0400 | Cost: 0.749\n",
            "Minibatch: 0600 | Cost: 0.602\n",
            "Minibatch: 0800 | Cost: 0.687\n",
            "Minibatch: 1000 | Cost: 0.491\n",
            "Minibatch: 1200 | Cost: 0.845\n",
            "Minibatch: 1400 | Cost: 0.627\n",
            "Epoch: 018 | AvgCost: 0.685 | Train/Valid ACC: 0.776/0.706\n",
            "Minibatch: 0200 | Cost: 0.683\n",
            "Minibatch: 0400 | Cost: 0.775\n",
            "Minibatch: 0600 | Cost: 0.754\n",
            "Minibatch: 0800 | Cost: 0.609\n",
            "Minibatch: 1000 | Cost: 0.974\n",
            "Minibatch: 1200 | Cost: 0.497\n",
            "Minibatch: 1400 | Cost: 0.683\n",
            "Epoch: 019 | AvgCost: 0.649 | Train/Valid ACC: 0.796/0.721\n",
            "Minibatch: 0200 | Cost: 0.396\n",
            "Minibatch: 0400 | Cost: 0.410\n",
            "Minibatch: 0600 | Cost: 0.557\n",
            "Minibatch: 0800 | Cost: 0.675\n",
            "Minibatch: 1000 | Cost: 0.418\n",
            "Minibatch: 1200 | Cost: 0.553\n",
            "Minibatch: 1400 | Cost: 0.811\n",
            "Epoch: 020 | AvgCost: 0.600 | Train/Valid ACC: 0.841/0.745\n",
            "Minibatch: 0200 | Cost: 0.638\n",
            "Minibatch: 0400 | Cost: 0.621\n",
            "Minibatch: 0600 | Cost: 0.583\n",
            "Minibatch: 0800 | Cost: 0.637\n",
            "Minibatch: 1000 | Cost: 0.511\n",
            "Minibatch: 1200 | Cost: 0.435\n",
            "Minibatch: 1400 | Cost: 0.396\n",
            "Epoch: 021 | AvgCost: 0.564 | Train/Valid ACC: 0.829/0.737\n",
            "Minibatch: 0200 | Cost: 0.520\n",
            "Minibatch: 0400 | Cost: 0.663\n",
            "Minibatch: 0600 | Cost: 0.403\n",
            "Minibatch: 0800 | Cost: 0.716\n",
            "Minibatch: 1000 | Cost: 0.509\n",
            "Minibatch: 1200 | Cost: 0.430\n",
            "Minibatch: 1400 | Cost: 0.725\n",
            "Epoch: 022 | AvgCost: 0.539 | Train/Valid ACC: 0.854/0.754\n",
            "Minibatch: 0200 | Cost: 0.397\n",
            "Minibatch: 0400 | Cost: 0.364\n",
            "Minibatch: 0600 | Cost: 0.635\n",
            "Minibatch: 0800 | Cost: 0.441\n",
            "Minibatch: 1000 | Cost: 0.491\n",
            "Minibatch: 1200 | Cost: 0.168\n",
            "Minibatch: 1400 | Cost: 0.657\n",
            "Epoch: 023 | AvgCost: 0.494 | Train/Valid ACC: 0.856/0.748\n",
            "Minibatch: 0200 | Cost: 0.299\n",
            "Minibatch: 0400 | Cost: 0.461\n",
            "Minibatch: 0600 | Cost: 0.364\n",
            "Minibatch: 0800 | Cost: 0.342\n",
            "Minibatch: 1000 | Cost: 0.625\n",
            "Minibatch: 1200 | Cost: 0.717\n",
            "Minibatch: 1400 | Cost: 0.539\n",
            "Epoch: 024 | AvgCost: 0.494 | Train/Valid ACC: 0.829/0.735\n",
            "Minibatch: 0200 | Cost: 0.839\n",
            "Minibatch: 0400 | Cost: 0.048\n",
            "Minibatch: 0600 | Cost: 0.281\n",
            "Minibatch: 0800 | Cost: 0.321\n",
            "Minibatch: 1000 | Cost: 0.125\n",
            "Minibatch: 1200 | Cost: 0.188\n",
            "Minibatch: 1400 | Cost: 0.772\n",
            "Epoch: 025 | AvgCost: 0.479 | Train/Valid ACC: 0.864/0.750\n",
            "Minibatch: 0200 | Cost: 1.318\n",
            "Minibatch: 0400 | Cost: 0.516\n",
            "Minibatch: 0600 | Cost: 0.611\n",
            "Minibatch: 0800 | Cost: 0.457\n",
            "Minibatch: 1000 | Cost: 0.442\n",
            "Minibatch: 1200 | Cost: 0.492\n",
            "Minibatch: 1400 | Cost: 0.501\n",
            "Epoch: 026 | AvgCost: 0.506 | Train/Valid ACC: 0.880/0.761\n",
            "Minibatch: 0200 | Cost: 1.167\n",
            "Minibatch: 0400 | Cost: 0.464\n",
            "Minibatch: 0600 | Cost: 0.470\n",
            "Minibatch: 0800 | Cost: 0.561\n",
            "Minibatch: 1000 | Cost: 0.915\n",
            "Minibatch: 1200 | Cost: 0.731\n",
            "Minibatch: 1400 | Cost: 0.679\n",
            "Epoch: 027 | AvgCost: 0.625 | Train/Valid ACC: 0.828/0.729\n",
            "Minibatch: 0200 | Cost: 0.292\n",
            "Minibatch: 0400 | Cost: 0.316\n",
            "Minibatch: 0600 | Cost: 0.480\n",
            "Minibatch: 0800 | Cost: 0.242\n",
            "Minibatch: 1000 | Cost: 0.422\n",
            "Minibatch: 1200 | Cost: 0.361\n",
            "Minibatch: 1400 | Cost: 0.279\n",
            "Epoch: 028 | AvgCost: 0.446 | Train/Valid ACC: 0.890/0.758\n",
            "Minibatch: 0200 | Cost: 0.429\n",
            "Minibatch: 0400 | Cost: 0.203\n",
            "Minibatch: 0600 | Cost: 0.227\n",
            "Minibatch: 0800 | Cost: 0.526\n",
            "Minibatch: 1000 | Cost: 0.625\n",
            "Minibatch: 1200 | Cost: 0.263\n",
            "Minibatch: 1400 | Cost: 0.323\n",
            "Epoch: 029 | AvgCost: 0.364 | Train/Valid ACC: 0.918/0.779\n",
            "Minibatch: 0200 | Cost: 0.081\n",
            "Minibatch: 0400 | Cost: 0.021\n",
            "Minibatch: 0600 | Cost: 0.293\n",
            "Minibatch: 0800 | Cost: 0.731\n",
            "Minibatch: 1000 | Cost: 0.331\n",
            "Minibatch: 1200 | Cost: 0.453\n",
            "Minibatch: 1400 | Cost: 0.395\n",
            "Epoch: 030 | AvgCost: 0.443 | Train/Valid ACC: 0.911/0.777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxHwQnC493Wi",
        "colab_type": "text"
      },
      "source": [
        "### Training Times\n",
        "\n",
        "- Even with a Colab GPU enabled, the 30 epochs for this set will take some time.\n",
        "\n",
        "- Expect this to take about 45 minutes to finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix78XNyU2R28",
        "colab_type": "code",
        "outputId": "dcfddebd-adfd-416d-886b-4ec10214ced0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "##########################\n",
        "### RELOAD & TEST\n",
        "##########################\n",
        "\n",
        "with tf.Session(graph=g) as sess:\n",
        "    saver.restore(sess, save_path='./convnet-vgg16.ckpt')\n",
        "    \n",
        "    # test_acc = sess.run('accuracy:0', feed_dict={'features:0': X_test,\n",
        "    #                                              'targets:0': y_test})\n",
        "    # ---------------------------------------\n",
        "    # workaround for GPUs with <= 4 Gb memory\n",
        "    n_predictions, n_correct = 0, 0\n",
        "    indices = np.arange(y_test.shape[0])\n",
        "    chunksize = 500\n",
        "    for start_idx in range(0, indices.shape[0] - chunksize + 1, chunksize):\n",
        "        index_slice = indices[start_idx:start_idx + chunksize]\n",
        "        p = sess.run('correct_predictions:0', \n",
        "                     feed_dict={'features:0': X_test[index_slice],\n",
        "                                'targets:0': y_test[index_slice]})\n",
        "        n_correct += np.sum(p)\n",
        "        n_predictions += p.shape[0]\n",
        "    test_acc = n_correct / n_predictions\n",
        "    # ---------------------------------------\n",
        "\n",
        "    print('Test ACC: %.3f' % test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0813 22:18:38.424992 140361440728960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test ACC: 0.781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD1HqbuIEX-8",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "With 30 epochs on a GPU in about 40 minutes, this model achieves about **78% test accuracy** in Cifar-10.  This very respectable for the limited training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BQR_DcFEaw6",
        "colab_type": "text"
      },
      "source": [
        "### End of notebook."
      ]
    }
  ]
}