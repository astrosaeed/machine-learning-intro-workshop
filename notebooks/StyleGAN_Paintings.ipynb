{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN_Paintings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/notebooks/StyleGAN_Paintings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrkxdqNfxTYe",
        "colab_type": "text"
      },
      "source": [
        "Originally taken from https://colab.research.google.com/drive/1cFKK0CBnev2BF8z9BOHxePk7E-f7TtUi\n",
        "which was foind on this Reddit post by user _C0D32_:\n",
        "https://www.reddit.com/r/MachineLearning/comments/bagnq6/p_stylegan_trained_on_paintings_512x512/\n",
        "\n",
        "Other neat resources pointed out in that reddit post are:\n",
        "- Sample of 999 generated images (512x512): https://imgur.com/a/8nkMmeB\n",
        "- Training data based on (only took images >= 1024x1024 (~30k)): https://www.kaggle.com/c/painter-by-numbers/data\n",
        "- quick latent space interpolation between 2 random vectors: https://imgur.com/a/VXt0Fhs\n",
        "- trained model: https://mega.nz/#!PsIQAYyD!g1No7FDZngIsYjavOvwxRG2Myyw1n5_U9CCpsWzQpIo\n",
        "\n",
        "Mildly modified by Kevin Sikorski"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dth87ejLUErS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFDqNCtbVFRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd stylegan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_D6JUMwX0uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/parameter-pollution/stylegan_paintings/releases/download/v0.1/network-snapshot-008040.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJRPjAU3Tn-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURu1JHLTn-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tflib.init_tf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_deS5kycTn-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = \"./network-snapshot-008040.pkl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j62EfW7MTn-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(model_path,\"rb\") as f:\n",
        "        _G, _D, Gs = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8espVfz2Tn-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfgcqoVd9SOI",
        "colab_type": "text"
      },
      "source": [
        "Set the random number seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFTTlYAaTn-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change this number to get a different image \n",
        "rnd = np.random.RandomState(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k1Whau7Tn-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rerun this line to get a different image\n",
        "latent_vector1 = rnd.randn(1, Gs.input_shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L59bqd2WarsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = Gs.run(latent_vector1, None, truncation_psi=1, randomize_noise=False, output_transform=fmt)\n",
        "PIL.Image.fromarray(images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVBXsCLw1_QH",
        "colab_type": "text"
      },
      "source": [
        "# Modifications by Kevin Sikorski below this section\n",
        "\n",
        "I leveraged the stylegan-encoder mentioned in the Game of Thrones styleGAN notebook at  https://colab.research.google.com/github/iyaja/stylegan-encoder/blob/master/generate_GoT_characters_with_StyleGAN.ipynb\n",
        "to make movies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLJxQK1A2CVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rerun this line to get a different image\n",
        "skip_this_many_images = 20\n",
        "for i in range(skip_this_many_images):\n",
        "  latent_vector1 = rnd.randn(1, Gs.input_shape[1])\n",
        "latent_vector1 = rnd.randn(1, Gs.input_shape[1])\n",
        "images = Gs.run(latent_vector1, None, truncation_psi=1, randomize_noise=False, output_transform=fmt)\n",
        "PIL.Image.fromarray(images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6OquGA4k9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(latent_vector1.shape)\n",
        "#print(latent_vector1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmcYa2DAB7en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/iyaja/stylegan-encoder.git\n",
        "import os\n",
        "os.chdir(\"stylegan-encoder\")\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "from encoder.generator_model import Generator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import moviepy.editor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atVdXTkfQtSE",
        "colab_type": "text"
      },
      "source": [
        "# Making a movie\n",
        "Define some convenience functions that will help us make a movie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byzfWhqiQwcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_image_for_video(latent_vector):\n",
        "    images = Gs.run(latent_vector, None, truncation_psi=1, randomize_noise=False, output_transform=fmt)\n",
        "    return images[0]\n",
        "\n",
        "\n",
        "# This function used only for translation along a direction\n",
        "def move_for_video(latent_vector, direction, coeff):\n",
        "  \n",
        "  new_latent_vector = latent_vector.copy()\n",
        "  new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "  img_array = generate_image(new_latent_vector)  \n",
        "  return img_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3E_fuAzPayv",
        "colab_type": "text"
      },
      "source": [
        "### Setting parameters\n",
        "\n",
        "Set the parameters for our movie: length, fps, etc.\n",
        "\n",
        "Change your random seed, realign us off images, or skip some images if you want a different movie.\n",
        "\n",
        "Pick the latent vectors that define our start and stop points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRf6nyCXQlfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnd = np.random.RandomState(10)\n",
        "skip_this_many_images = 20\n",
        "for i in range(skip_this_many_images):\n",
        "  latent_vector1 = rnd.randn(1, Gs.input_shape[1])\n",
        "skip_for_realignment = 5\n",
        "for i in range(skip_for_realignment):\n",
        "  rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "\n",
        "duration_sec = 30.0\n",
        "smoothing_sec = 1.0\n",
        "mp4_fps = 20\n",
        "num_frames = int(np.rint(duration_sec * mp4_fps))\n",
        "\n",
        "\n",
        "start_latent = rnd.randn(1, Gs.input_shape[1])\n",
        "end_latent = rnd.randn(1, Gs.input_shape[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFuENRxzRRjc",
        "colab_type": "text"
      },
      "source": [
        "### Make the movie\n",
        "\n",
        "Your final video will be under Files tab.  Go up as far as you can, then go to /content.  Double-click interpolate.mp4 to download, and be amazed.  And maybe a little horrified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjVRMCeb2KxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# This creates an nd array that stores all the image frames for cross-character interpolation\n",
        "print(\"Generating {frames} images for movie\".format(frames=int(duration_sec*mp4_fps)))\n",
        "src_images = np.stack(generate_image_for_video(((1/num_frames)*alpha*end_latent)+((1-((1/num_frames)*alpha))*start_latent)) for alpha in range (num_frames))\n",
        "\n",
        "\n",
        "# Uncomment the next line if you want to do a character transformation video, and choose the arguments as per your requirement\n",
        "#src_images = np.stack(move_for_video(dany_meme, smile_direction, (0.02*alpha)) for alpha in range (-100,100))\n",
        "\n",
        "\n",
        "def make_frame(t):\n",
        "    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
        "    src_image = src_images[frame_idx]\n",
        "    return np.array(src_image)\n",
        "\n",
        "# Generate video.\n",
        "mp4_file = '/content/interpolate.mp4'\n",
        "mp4_codec = 'libx264'\n",
        "mp4_bitrate = '5M'\n",
        "\n",
        "video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
        "video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}