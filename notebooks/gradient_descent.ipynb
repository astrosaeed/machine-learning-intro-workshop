{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Gradient-descent.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0VzvfBxFWBQ"
      },
      "source": [
        "# An introduction to Gradient Descent\n",
        "\n",
        "- From [Implementation of gradient-descent-in-python](https://medium.com/coinmonks/implementation-of-gradient-descent-in-python-a43f160ec521) at [medium.com](https://medium.com) by Deepak Battini.\n",
        "- And [Implement Gradient Descent in Python](https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1) at [TowardDatascience.com](https://towardsdatascience.com) by Rohan Joseph.\n",
        "- And [A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/) at [machinelearningmastery.com](https://machinelearningmastery.com) by  Jason Brownlee\n",
        "\n",
        "Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjInBsK3Jfu",
        "colab_type": "text"
      },
      "source": [
        "Every machine learning engineer is always looking to improve their model’s performance. This is where optimization, one of the most important fields in machine learning, comes in. Optimization allows us to select the best parameters, associated with the machine learning algorithm or method we are using, for our problem case. There are several types of optimization algorithms. Perhaps the most popular one is the Gradient Descent optimization algorithm. The first encounter of Gradient Descent for many machine learning engineers is in their introduction to neural networks. In this tutorial, we will teach you how to implement Gradient Descent from scratch in Python. \n",
        "\n",
        "But first, what exactly is Gradient Descent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7myUH-b3Jfv",
        "colab_type": "text"
      },
      "source": [
        "## What is Gradient Descent?\n",
        "\n",
        "It is an optimization algorithm to find the minimum of a function. We start with a random point on the function and move in the negative direction of the gradient of the function to reach the local/global minima.\n",
        "\n",
        "<figure>\n",
        "  <br><center>\n",
        "    <img src=\"https://github.com/jfogarty/machine-learning-intro-workshop/blob/master/images/homer-descending.gif?raw=1\" />\n",
        "    <figcaption>Homer descending!</figcaption>     \n",
        "  </center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar0iQ3lW3Jfw",
        "colab_type": "text"
      },
      "source": [
        "Gradient descent is an optimization algorithm that helps machine learning models converge at a minimum value through repeated steps. Essentially, gradient descent is used to minimize a function by finding the value that gives the lowest output of that function. Often times, this function is usually a loss function. Loss functions measure how bad our model performs compared to actual occurrences. Hence, it only makes sense that we should reduce this loss. One way to do this is via gradient descent.\n",
        "\n",
        "A simple gradient descent algorithm is as follows:\n",
        "\n",
        "1. Obtain a function to minimize F(x)\n",
        "1. Initialize a value x from which to start the descent or optimization from\n",
        "1. Specify a **learning rate** that will determine how much of a step to descend by or how quickly you converge to the minimum value\n",
        "1. Obtain the derivative of that value x (the descent)\n",
        "1. Proceed to descend by the derivative of that value multiplied by the learning rate\n",
        "1. Update the value of x with the new value descended to\n",
        "1. Check your stop condition to see whether to stop\n",
        "1. If condition satisfied, stop. If not, proceed to step 4 with the new x value and keep repeating algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmu6JM1V3Jfx",
        "colab_type": "text"
      },
      "source": [
        "### Heres an Example by hand :\n",
        "\n",
        "Question : Find the local minima of the function: $y=(x+5)^2$ starting from the point $x=3$\n",
        "    \n",
        "<figure>\n",
        "  <br><center>\n",
        "    <img src=\"https://github.com/jfogarty/machine-learning-intro-workshop/blob/master/images/graph_x+5_squared.png?raw=1\" />\n",
        "  </center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gnj63qY3Jfy",
        "colab_type": "text"
      },
      "source": [
        "### Solution\n",
        "\n",
        "We know the answer just by looking at the graph. $y = (x+5)^2$ reaches its minimum value when $x = -5$ (i.e when $x=-5$, $y=0$). Hence $x=-5$ is the \n",
        "local and global minima of the function.\n",
        "\n",
        "Now, let’s see how to obtain the same numerically using gradient descent.\n",
        "\n",
        "- Step 1 : Initialize x =3. \n",
        "$$x_0 = 3$$\n",
        "Then, find the gradient of the function, \n",
        "$$\n",
        "  \\frac{dy}{dx} = \\frac{dy}{dx}(x+5)^2 \n",
        "                = 2(x+5) \n",
        "$$.\n",
        "- Step 3 : Move in the direction of the negative of the gradient (Why?). But wait, how much to move? For that, we require a learning rate. Let us assume the learning rate → 0.01 (this is often called $\\alpha$)\n",
        "\n",
        "$$\n",
        "\\alpha = 0.01\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYRdSqF43Jfy",
        "colab_type": "text"
      },
      "source": [
        "- Step 4 : Let’s perform some iterations of gradient descent:\n",
        "\n",
        "<figure>\n",
        "  <br><center>\n",
        "    <img src=\"https://github.com/jfogarty/machine-learning-intro-workshop/blob/master/images/gradient_descent_by_hand.png?raw=1\" />\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "- Step 5 : We can observe that the X value is slowly decreasing and should converge to -5 (the local minimum). However, how many iterations should we perform?\n",
        "\n",
        "Let us set a precision variable in our algorithm which calculates the difference between two consecutive “$x$” values.\n",
        "\n",
        "If the difference between $x$ values from 2 consecutive iterations is lesser than the precision we set, stop the algorithm!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3NxGue83Jfz",
        "colab_type": "text"
      },
      "source": [
        "# Now for some Python \n",
        "\n",
        "**Usage NOTE!** Use `Shift+Enter` to step through this notebook, executing the code as you go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsllVvRg3Jf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f  = lambda x: (x + 5)**2  # The function we are trying to minimize (notice we don't actually use it!)\n",
        "df = lambda x: 2*(x+5)     # Gradient of our function\n",
        "\n",
        "rate      = 0.01  # Learning rate\n",
        "precision = 0.000001 # This tells us when to stop the algorithm\n",
        "previous_step_size = 1 # Initialize at 1\n",
        "max_iters = 10000 # Maximum number of iterations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfT4OCbW3Jf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cur_x     = 3 # The algorithm starts at x=3\n",
        "iters = 0 # Iteration counter\n",
        "while previous_step_size > precision and iters < max_iters:\n",
        "    prev_x = cur_x # Store current x value in prev_x\n",
        "    cur_x = cur_x - rate * df(prev_x) # Grad descent\n",
        "    previous_step_size = abs(cur_x - prev_x) # Change in x\n",
        "    iters = iters+1 # Iteration count\n",
        "    print(\"Iteration\",iters,\"\\nX value is\",cur_x) # Print iterations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p36Aatkq3Jf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"The local minimum occurs at {cur_x:0.4f}\")\n",
        "print(f\"The number of iterations to converge was {iters}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN6Ju-g83Jf9",
        "colab_type": "text"
      },
      "source": [
        "### Output\n",
        "\n",
        "From the output above, we can observe the $x$ values for the first 10 iterations- which can be cross checked with our manual calculations. The algorithm runs for 595 iterations before it terminates. \n",
        "\n",
        "**Well that was fun.  Let's try another one.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBbnG0z33Jf9",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent in Python -- with Graphs!\n",
        "\n",
        "Here, we will implement a simple representation of gradient descent using python.\n",
        "We will create an arbitrary loss function and attempt to find a local minimum value for that function.\n",
        "\n",
        "Our function $f(x)$ will be :\n",
        "    \n",
        "$$f(x) = x^3 - 3x^2 + 7$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M88W-aNQ-s6s",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Create the function and plot it \n",
        "function = lambda x: (x ** 3)-(3 *(x ** 2))+7\n",
        "\n",
        "# Get 1000 evenly spaced numbers between -1 and 3 (arbitrarily chosen to ensure steep curve)\n",
        "x = np.linspace(-1,3,500)\n",
        "\n",
        "# Plot the curve\n",
        "plt.plot(x, function(x))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aqbsWYCjGfcv"
      },
      "source": [
        "Note that while this function is defined for $x$ in $[-\\infty, +\\infty]$ it only has a local minimum from $x$ in $[0.0, 2.0]$.\n",
        "\n",
        "We will then proceed to make two functions for the gradient descent implementation:\n",
        "\n",
        "- The first is a derivative function: This function takes in a value of x and returns its derivative based on the initial function we specified. It is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oqAKquEK-vis",
        "colab": {}
      },
      "source": [
        "def deriv(x):\n",
        "    \n",
        "    '''\n",
        "    Description: This function takes in a value of x and returns its derivative based on the \n",
        "    initial function we specified.\n",
        "    \n",
        "    Arguments:\n",
        "    \n",
        "    x - a numerical value of x \n",
        "    \n",
        "    Returns:\n",
        "    \n",
        "    x_deriv - a numerical value of the derivative of x\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    x_deriv = 3* (x**2) - (6 * (x))\n",
        "    return x_deriv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ltBAH7B8GmQH"
      },
      "source": [
        "- The second is a Step function: This is the function where the actual gradient descent takes place. This function takes in an initial or previous value for x, updates it based on steps taken via the learning rate and outputs the most minimum value of x that reaches the stop condition. For our stop condition, we are going to use a precision stop. This means that when the absolute difference between our old and updated x is greater than a value, the algorithm should stop. The function will also print out the minimum value of x as well as the number of steps or descents it took to reach that value.\n",
        "\n",
        "This function is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNgbCCn8E6rM",
        "colab": {}
      },
      "source": [
        "def step(x_new, x_prev, precision, l_r):\n",
        "    \n",
        "    '''\n",
        "    Description: This function takes in an initial or previous value for x, updates it based on \n",
        "    steps taken via the learning rate and outputs the most minimum value of x that reaches the precision satisfaction.\n",
        "    \n",
        "    Arguments:\n",
        "    \n",
        "    x_new - a starting value of x that will get updated based on the learning rate\n",
        "    \n",
        "    x_prev - the previous value of x that is getting updated to the new one\n",
        "    \n",
        "    precision - a precision that determines the stop of the stepwise descent \n",
        "    \n",
        "    l_r - the learning rate (size of each descent step)\n",
        "    \n",
        "    Output:\n",
        "    \n",
        "    1. Prints out the latest new value of x which equates to the minimum we are looking for\n",
        "    2. Prints out the the number of x values which equates to the number of gradient descent steps\n",
        "    3. Plots a first graph of the function with the gradient descent path\n",
        "    4. Plots a second graph of the function with a zoomed in gradient descent path in the important area\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # create empty lists where the updated values of x and y will be appended during each iteration\n",
        "    \n",
        "    x_list, y_list = [x_new], [function(x_new)]\n",
        "    # keep looping until your desired precision\n",
        "    while abs(x_new - x_prev) > precision:\n",
        "        \n",
        "        # change the value of x\n",
        "        x_prev = x_new\n",
        "        \n",
        "        # get the derivation of the old value of x\n",
        "        d_x = - deriv(x_prev)\n",
        "        \n",
        "        # get your new value of x by adding the previous, the multiplication of the derivative and the learning rate\n",
        "        x_new = x_prev + (l_r * d_x)\n",
        "        \n",
        "        # append the new value of x to a list of all x-s for later visualization of path\n",
        "        x_list.append(x_new)\n",
        "        \n",
        "        # append the new value of y to a list of all y-s for later visualization of path\n",
        "        y_list.append(function(x_new))\n",
        "        print(\"step \" +str(x_new))\n",
        "\n",
        "    print (\"Local minimum occurs at: \"+ str(x_new))\n",
        "    print (\"Number of steps: \" + str(len(x_list)))\n",
        "    \n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    plt.scatter(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x,function(x), c=\"r\")\n",
        "    plt.title(\"Gradient descent\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.scatter(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x,function(x), c=\"r\")\n",
        "    plt.xlim([1.0,2.1])\n",
        "    plt.title(\"Zoomed in Gradient descent to Key Area\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XHYXHIHJGyYn"
      },
      "source": [
        "Next, we proceed to plot the gradient descent path as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsKwp9w5FC5-",
        "colab": {}
      },
      "source": [
        "#Implement gradient descent (all the arguments are arbitrarily chosen)\n",
        "\n",
        "step(2.99, 0, 0.001, 0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v8wb26qFG4pQ"
      },
      "source": [
        "The importance of Gradient Descent in Machine Learning is one that will be encountered all through your machine learning journey. This is why it is imperative that you understand the inner workings of this algorithm. This tutorial has introduced you to the simplest form of the gradient descent algorithm as well as its implementation in python. Now, you have an intuitive understanding of this algorithm and you are ready to apply it to real world problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqkyK4Xc3JgL",
        "colab_type": "text"
      },
      "source": [
        "## A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size\n",
        "\n",
        "Stochastic gradient descent is the dominant method used to train deep learning models.\n",
        "\n",
        "There are three main variants of gradient descent and it can be confusing which one to use.\n",
        "\n",
        "In this post, you will discover the one type of gradient descent you should use in general and how to configure it.\n",
        "\n",
        "This is what we'll discuss here:\n",
        "\n",
        "- What gradient descent is and how it works from a high level.\n",
        "- What batch, stochastic, and mini-batch gradient descent are and the benefits and limitations of each method.\n",
        "- That mini-batch gradient descent is the go-to method and how to configure it on your applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN2J970W3JgL",
        "colab_type": "text"
      },
      "source": [
        "## Contrasting the 3 Types of Gradient Descent\n",
        "\n",
        "Gradient descent can vary in terms of the number of training patterns used to calculate error; that is in turn used to update the model.\n",
        "\n",
        "The number of patterns used to calculate the error includes how stable the gradient is that is used to update the model. We will see that there is a tension in gradient descent configurations of computational efficiency and the fidelity of the error gradient.\n",
        "\n",
        "The three main flavors of gradient descent are batch, stochastic, and mini-batch.\n",
        "\n",
        "Let’s take a closer look at each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR3AeUBa3JgM",
        "colab_type": "text"
      },
      "source": [
        "### What is Stochastic Gradient Descent?\n",
        "\n",
        "Stochastic gradient descent, often abbreviated **SGD**, is a variation of the gradient descent algorithm that calculates the error and updates the model for each example in the training dataset.\n",
        "\n",
        "The update of the model for each training example means that stochastic gradient descent is often called an online machine learning algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfrKv_R-3JgM",
        "colab_type": "text"
      },
      "source": [
        "#### Upsides\n",
        "- The frequent updates immediately give an insight into the performance of the model and the rate of improvement.\n",
        "- This variant of gradient descent may be the simplest to understand and implement, especially for beginners.\n",
        "- The increased model update frequency can result in faster learning on some problems.\n",
        "- The noisy update process can allow the model to avoid local minima (e.g. premature convergence).\n",
        "\n",
        "#### Downsides\n",
        "- Updating the model so frequently is more computationally expensive than other configurations of gradient descent, taking significantly longer to train models on large datasets.\n",
        "- The frequent updates can result in a noisy gradient signal, which may cause the model parameters and in turn the model error to jump around (have a higher variance over training epochs).\n",
        "- The noisy learning process down the error gradient can also make it hard for the algorithm to settle on an error minimum for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g325YRHa3JgN",
        "colab_type": "text"
      },
      "source": [
        "### What is Batch Gradient Descent?\n",
        "\n",
        "Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated.\n",
        "\n",
        "One cycle through the entire training dataset is called a training epoch. Therefore, it is often said that batch gradient descent performs model updates at the end of each training epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q-IV7HV3JgN",
        "colab_type": "text"
      },
      "source": [
        "#### Upsides\n",
        "- Fewer updates to the model means this variant of gradient descent is more computationally efficient than stochastic gradient descent.\n",
        "- The decreased update frequency results in a more stable error gradient and may result in a more stable convergence on some problems.\n",
        "- The separation of the calculation of prediction errors and the model update lends the algorithm to parallel processing based implementations.\n",
        "\n",
        "#### Downsides\n",
        "- The more stable error gradient may result in premature convergence of the model to a less optimal set of parameters.\n",
        "- The updates at the end of the training epoch require the additional complexity of accumulating prediction errors across all training examples.\n",
        "- Commonly, batch gradient descent is implemented in such a way that it requires the entire training dataset in memory and available to the algorithm.\n",
        "- Model updates, and in turn training speed, may become very slow for large datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_loocaYb3JgO",
        "colab_type": "text"
      },
      "source": [
        "## What is Mini-Batch Gradient Descent?\n",
        "Mini-batch gradient descent is a variation of the gradient descent algorithm that splits the training dataset into small batches that are used to calculate model error and update model coefficients.\n",
        "\n",
        "Implementations may choose to sum the gradient over the mini-batch which further reduces the variance of the gradient.\n",
        "\n",
        "Mini-batch gradient descent seeks to find a balance between the robustness of stochastic gradient descent and the efficiency of batch gradient descent. It is the most common implementation of gradient descent used in the field of deep learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1z_FYuL3JgP",
        "colab_type": "text"
      },
      "source": [
        "#### Upsides\n",
        "- The model update frequency is higher than batch gradient descent which allows for a more robust convergence, avoiding local minima.\n",
        "- The batched updates provide a computationally more efficient process than stochastic gradient descent.\n",
        "- The batching allows both the efficiency of not having all training data in memory and algorithm implementations.\n",
        "\n",
        "#### Downsides\n",
        "- Mini-batch requires the configuration of an additional “mini-batch size” hyperparameter for the learning algorithm.\n",
        "- Error information must be accumulated across mini-batches of training examples like batch gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "undgZ8Qs3JgP",
        "colab_type": "text"
      },
      "source": [
        "### How to Configure Mini-Batch Gradient Descent\n",
        "\n",
        "Mini-batch gradient descent is the recommended variant of gradient descent for most applications, especially in deep learning.\n",
        "\n",
        "Mini-batch sizes, commonly called “batch sizes” for brevity, are often tuned to an aspect of the computational architecture on which the implementation is being executed. Such as a power of two that fits the memory requirements of the GPU or CPU hardware like 32, 64, 128, 256, and so on.\n",
        "\n",
        "Batch size is a slider on the learning process.\n",
        "\n",
        "- Small values give a learning process that converges quickly at the cost of noise in the training process.\n",
        "- Large values give a learning process that converges slowly with accurate estimates of the error gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJpMYfIO3JgQ",
        "colab_type": "text"
      },
      "source": [
        "**Tip 1**: A good default for batch size might be 32.\n",
        "\n",
        "… [batch size] is typically chosen between 1 and a few hundreds, e.g. [batch size] = 32 is a good default value, with values above 10 taking advantage of the speedup of matrix-matrix products over matrix-vector products.\n",
        "\n",
        "— From [Practical recommendations for gradient-based training of deep architectures, 2012](https://arxiv.org/abs/1206.5533)\n",
        "\n",
        "\n",
        "**Tip 2**: It is a good idea to review learning curves of model validation error against training time with different batch sizes when tuning the batch size.\n",
        "\n",
        "… it can be optimized separately of the other hyperparameters, by comparing training curves (training and validation error vs amount of training time), after the other hyper-parameters (except learning rate) have been selected.\n",
        "\n",
        "**Tip 3**: Tune batch size and learning rate after tuning all other hyperparameters.\n",
        "\n",
        "… [batch size] and [learning rate] may slightly interact with other hyper-parameters so both should be re-optimized at the end. Once [batch size] is selected, it can generally be fixed while the other hyper-parameters can be further optimized (except for a momentum hyper-parameter, if one is used)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dsP3CNPg96A",
        "colab_type": "text"
      },
      "source": [
        "## The Importance of Initial values: AKA The Butterfly Effect\n",
        "Initial values matter for gradient descent.  In the case that there are several local minima, then which one you find may depend on where you start your search.  There could also be local minima which are not global minima; starting values could put you in or near one of these, trapping you and never letting you escape.\n",
        "\n",
        "The image below shows how starting conditions can affect which solution a gradient descent algorithm might find.  Here we use Newton's Method -- which is a Gradient Descent algorithm -- to find the cube roots of 1 in the complex plane.  Of course, we all remember from Trigonometry class that the three solutions are 1 and \n",
        "$$ -0.5 \\pm \\frac{i\\sqrt{3}}{2} .$$  For any point, if you start Newton's Method at that point, the color there indicates which of those three solutions you  will gravitate towards.  Which solution this is can clear when you are in one of the basins of attraction (the big red, green, or blue seas), but if you are on the border between them, it's not obvious which solution you might be pulled to.\n",
        "\n",
        "It's fine if that didn't make much sense.  Just enjoy the pretty picture and remember that even small changes in initial conditions can affect which solution your learning algorithm gravitates toward, and sometimes in surprising ways.  And don't be afraid to run your learning algorithms multiple times, with different starting conditions - you might find a different or even better solution.\n",
        "\n",
        "<figure><br>\n",
        "  <center><img src=\"https://raw.githubusercontent.com/KevinSikorskiBase2S/machine-learning-intro-workshop/master/images/newtonsMethod.png\" />\n",
        "      <figcaption>Newton's Method solving X^3-1=0 in the complex plane.  Each point represents a different starting point for Newton's Method.  The color at that point indicates which of the three solutions the trajectory converges toward.  From https://commons.wikimedia.org/w/index.php?curid=16450353\n",
        "   </figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_ttn0kWezh8",
        "colab_type": "text"
      },
      "source": [
        "## Differentiable Functions\n",
        "Grandient Descent assumes that you have a gradient.  If you think back to your calculus class, this means that the function you are optimizing must be differentiable.  The examples we've looked at today have all been differentiable: smooth and continuous.  \n",
        "\n",
        "When doing machine learning, you might be learning or optimzing such a well-behaved function.  There could be discontinuities (a step function) or corners, it might not be defined for all  points, it might be a step function.\n",
        "\n",
        "Let's set up to do gradient descent on the function: $$ y = |x| $$ and see what exciting things happen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLC3YLRJc9hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our Function\n",
        "function = lambda x: (abs(x))\n",
        "\n",
        "# The Derivative of the function\n",
        "def deriv(x):\n",
        "    if x < 0:\n",
        "      return -1\n",
        "    if x > 0: \n",
        "      return 1\n",
        "    return 0  # Mathematically speaking, the derivative is undefined at zero.  But zero seems as good a number to use as any here.\n",
        "\n",
        "# Plot the graph\n",
        "x = np.array([-3, 0, 3])\n",
        "plt.plot(x, function(x))\n",
        "plt.title(\"Absolute Value Function\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxdaouI1jJ8b",
        "colab_type": "text"
      },
      "source": [
        "Already we've seen some issues with defining the derivative of the function.  But how likely is it that we'll hit the number zero exactly? Pretty unlikely.  So let's try it anyway.  We define a new function similar to the \"step\" function we used above, but we add a little safety to it, to only run up to max_times iterations of the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN-m04PUgnhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stepMaxTimes(x_new, x_prev, precision, l_r, max_times):\n",
        "    x_list, y_list = [x_new], [function(x_new)]\n",
        "    # keep looping until your desired precision\n",
        "    while abs(x_new - x_prev) > precision and max_times > 0:\n",
        "        \n",
        "        x_prev = x_new\n",
        "        d_x = - deriv(x_prev)\n",
        "        x_new = x_prev + (l_r * d_x)\n",
        "        x_list.append(x_new)\n",
        "        y_list.append(function(x_new))\n",
        "        max_times = max_times - 1\n",
        "        print(\"new value is: %23.20f, with %3d steps left\" %(x_new, max_times))\n",
        "\n",
        "    print (\"Local minimum occurs at: \"+ str(x_new))\n",
        "    print (\"Number of steps: \" + str(len(x_list)))\n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    plt.scatter(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x,function(x), c=\"r\")\n",
        "    plt.title(\"Gradient descent\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.scatter(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x_list,y_list,c=\"g\")\n",
        "    plt.plot(x,function(x), c=\"r\")\n",
        "    plt.xlim([-0.1,0.1])\n",
        "    plt.title(\"Zoomed in Gradient descent to Key Area\")\n",
        "    plt.show()\n",
        "    \n",
        "# Run it!\n",
        "stepMaxTimes(1.99, 0, 0.001, 0.05, 70)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCpZm0VymuVy",
        "colab_type": "text"
      },
      "source": [
        "### One last trick\n",
        "Some learning algorithms use a decaying learning rate.  They start off with a high learning rate to jump across large distances, visiting more of the solution space and hopefully settling in a global minimum rather than a local minimum.  Then over time, they decay the learning rate to fine tune the result.  This would allow us to continue getting closer to real minimum of zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh4QpRrL3JgQ",
        "colab_type": "text"
      },
      "source": [
        "### End of note."
      ]
    }
  ]
}