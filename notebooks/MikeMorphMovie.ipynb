{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MikeMorphMovie.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/notebooks/MikeMorphMovie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubpsx_r8-vhv",
        "colab_type": "text"
      },
      "source": [
        "# Make a morph movie\n",
        "\n",
        "This notebook is a mashup of the GameOfThronesStyleGAN and LatentMe notebooks and done by Kevin Sikorski.  The resources in those notebooks (and StyleGAN) are leveraged here, and so due credit is due to the people who wrote the notebooks those are derived from.\n",
        "\n",
        "We are going to make a morph movie from Lionel Richie (Of \"Is it Me You're Looking For?\" Fame) to Mike Haldeman to Bob Ross to Mike Haldeman.\n",
        "\n",
        "Be sure your notebook has a GPU allocated to it (Under Runtime|Change Runtime Type).\n",
        "\n",
        "<figure>\n",
        "<table border = 5 align = center>\n",
        "<tr>\n",
        "<td width=22%>\n",
        "    <img src=\"https://raw.githubusercontent.com/jfogarty/machine-learning-intro-workshop/master/images/isItMeYourLookingFor/lionel.jpg\" />\n",
        "</td>\n",
        "<td width=22%>\n",
        "    <img src=\"https://raw.githubusercontent.com/jfogarty/machine-learning-intro-workshop/master/images/isItMeYourLookingFor/Mike.jpg\" />\n",
        "</td>\n",
        "<td width=22%>\n",
        "    <img src=\"https://raw.githubusercontent.com/jfogarty/machine-learning-intro-workshop/master/images/isItMeYourLookingFor/Bob.jpg\" />\n",
        "</td>\n",
        "<td width=22%>\n",
        "    <img src=\"https://raw.githubusercontent.com/jfogarty/machine-learning-intro-workshop/master/images/isItMeYourLookingFor/Mike.jpg\" />\n",
        "</td>\n",
        "</table>\n",
        "<center>\n",
        "  <figcaption>Our participants.</figcaption>\n",
        "  </center>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfa6euUL_y_O",
        "colab_type": "text"
      },
      "source": [
        "Let's start by downloading and setting up our GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frBc9Kl2ALv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Puzer/stylegan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnWcHKIiAkAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd stylegan\n",
        "# Use the version this notebook was built with\n",
        "!git checkout c3fb250c65840c8837ded78e34485227755c2473"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qQSqipARWtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir raw_images aligned_images generated_images latent_representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppy24iTjSKAy",
        "colab_type": "text"
      },
      "source": [
        "## Add your image(s)\n",
        "\n",
        "There are two ways to do this: \n",
        "- Use the canned images: this is easier and faster, and gives you the morph from Lionel to Mike to Bob to Mike.  This is what this notebook is setup up for if you don't change anything.\n",
        "- Use your own images.  You'll have to read more closely, and comment out/uncomment some code to accomplish this.  Don't be afraid, if you are vaguely not incompetent, you'll do fine.  Probably.\n",
        "\n",
        "### To use your own images...\n",
        "Upload your image using the Sidebar now. \n",
        "\n",
        "To open the sidebar select \"View\" and then \"Table of Contents\".\n",
        "\n",
        "The sidebar should now be open. Click the \"Files\" tab.\n",
        "\n",
        "Before uploading make sure:\n",
        "\n",
        "1.   The image(s) you're using can be opened by PIL (jpg, png, etc)\n",
        "2.   The images are larger than 1024x1024. Preferably significantly larger so the aligner can crop out a high resolution section of the image containing your face.\n",
        "3.   Your face in the image is well lit and facing the camera (for best results)\n",
        "\n",
        "Click ''Upload\" in the sidebar and select the images you want to upload from your computer.\n",
        "\n",
        "Note: All files uploaded in this manner end up in the root of the file tree. We'll move them into the correct spot next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bpprb8pRmNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# e.g. mv ../me.jpg raw_images/\n",
        "#!mv ../Bob.jpg raw_images/\n",
        "#!mv ../Mike.jpg raw_images/\n",
        "#!mv ../lionel.jpg raw_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u4pDjwaKjxo",
        "colab_type": "text"
      },
      "source": [
        "### Or use the canned images\n",
        "\n",
        "Just download some canned images and we can use them.  Bob Ross, Lionel Richie, and Mike Haldeman have been graciously volunteered.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL2FueelKLWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/jfogarty/machine-learning-intro-workshop\n",
        "!cp machine-learning-intro-workshop/images/isItMeYourLookingFor/*.jpg raw_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP7AoP2N-Cwh",
        "colab_type": "text"
      },
      "source": [
        "## Align your images\n",
        "Do this IF you supplied your own image.  If you used the canned ones, skip this step.  This takes about 1-2 minutes per image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEQzXr5T-AcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python align_images.py raw_images aligned_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfIVCApk-JUz",
        "colab_type": "text"
      },
      "source": [
        "This should produce an image in `aligned_images/` for every image in `raw_images/`.\n",
        "\n",
        "It's a good idea to check that this process worked by using the Files browser to download each aligned image and make sure it looks reasonable. If you encounter scrambled images it might be because your original raw images are too small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RbJ1MQJx8EyK"
      },
      "source": [
        "## Search for your latent self\n",
        "\n",
        "Do this IF you supplied your own image.  If you used the canned ones, skip this step.  This takes about 5 minutes per image.\n",
        "\n",
        "The script `encode_images.py` will minimize the perceptual loss between generated images from StyleGAN and each of the images you've uploaded. (By default this happens one at a time)\n",
        "\n",
        "I've had good results at 1000 iterations and it's best to check the general quality before coming back and ramping up the number of iterations to produce a high-quality latent.\n",
        "\n",
        "Higher quality comes at a cost of course. 10000 iterations will take about **one hour** for one image.\n",
        "\n",
        "**NOTE:** You may get a warning about the GPU memory limit when running this script. Don't worry it will still complete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itkKXoOFLDJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python encode_images.py aligned_images/ generated_images/ latent_representations/ --iterations 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6TZovcPCM05",
        "colab_type": "text"
      },
      "source": [
        "## Download Your Results\n",
        "\n",
        "After the above cell has finished writing there should be an image in `generated_images/` for each image in `aligned_images/`.\n",
        "\n",
        "You can right-click and download each of these images to see your final latent self.\n",
        "\n",
        "### Latent Representation\n",
        "\n",
        "You can also download the `npy` files in the `latent_representations/` directory. Each of those is a serialized numpy array which contains the (18, 512) array encoding the point in latent space which corresponds to the generated image. Which you can open with `latent = np.load('filename.npy')`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fse6GaCP7BAA",
        "colab_type": "text"
      },
      "source": [
        "If you used the canned images (Bob, Mike, Lionel), then you need to copy the corresponding canned latent representations..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAMGqiFH7BTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp machine-learning-intro-workshop/images/isItMeYourLookingFor/*.npy latent_representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X77aCUQcAH_q",
        "colab_type": "text"
      },
      "source": [
        "...and load them into memory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rqYj-P1_8Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading already learned representations\n",
        "import numpy as np\n",
        "\n",
        "lionelRep = np.load('latent_representations/lionel_01.npy')\n",
        "mikeRep = np.load('latent_representations/Mike_01.npy')\n",
        "bobRep = np.load('latent_representations/Bob_01.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhLqYf5RB-ga",
        "colab_type": "text"
      },
      "source": [
        "### Change your Smile, Gender, or Age\n",
        "\n",
        "Once your latent representation has been generated and saved you can explore the volume around it through latent vectors. Puzer has provided vectors for Smile, Gender and Age so you can see what you look like as your latent self varies along those axes.\n",
        "\n",
        "Run the following cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S60SiKxu_8AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "from encoder.generator_model import Generator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVYrjvgE_8AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
        "\n",
        "tflib.init_tf()\n",
        "with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n",
        "    generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
        "\n",
        "generator = Generator(Gs_network, batch_size=1, randomize_noise=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY8HzVK5_8Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_image(latent_vector):\n",
        "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
        "    generator.set_dlatents(latent_vector)\n",
        "    img_array = generator.generate_images()[0]\n",
        "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
        "    return img.resize((256, 256))\n",
        "\n",
        "def move_and_show(latent_vector, direction, coeffs):\n",
        "    fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
        "    for i, coeff in enumerate(coeffs):\n",
        "        new_latent_vector = latent_vector.copy()\n",
        "        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "        ax[i].imshow(generate_image(new_latent_vector))\n",
        "        ax[i].set_title('Coeff: %0.1f' % coeff)\n",
        "    [x.axis('off') for x in ax]\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajPDYVyl_8A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading already learned latent directions\n",
        "smile_direction = np.load('ffhq_dataset/latent_directions/smile.npy')\n",
        "gender_direction = np.load('ffhq_dataset/latent_directions/gender.npy')\n",
        "age_direction = np.load('ffhq_dataset/latent_directions/age.npy')\n",
        "\n",
        "# In general it's possible to find directions of almost any face attributes: position, hair style or color ... \n",
        "# Additional scripts for doing so will be realised soon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDhrIyeb_8A8",
        "colab_type": "text"
      },
      "source": [
        "# Smile transformation\n",
        "\n",
        "These next 3 sections have nothing to do with making the morph, I just wanted to see Lionel smile, and Bob Ross as a woman.  Because why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8MPNVhS_8A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "move_and_show(lionelRep, smile_direction, [-2.3, 0, 2.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MIV2loD_8Bc",
        "colab_type": "text"
      },
      "source": [
        "# Gender transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHJ5IhqB_8Bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "move_and_show(bobRep, gender_direction, [-2.2, 0, 2.5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ps3yMN_8B5",
        "colab_type": "text"
      },
      "source": [
        "# Age transformation\n",
        "\n",
        "Apparently old people wear glasses a lot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwSZcOvG_8B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "move_and_show(lionelRep, age_direction, [-2.8, 0, 3.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVml2PorH9F8",
        "colab_type": "text"
      },
      "source": [
        "# Morph Movie happens below\n",
        "\n",
        "We shall morph from Lionel to Mike to Bob to Mike.\n",
        "\n",
        "Some movie parameters..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOF0_fnVH9vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duration_sec = 15.0\n",
        "smoothing_sec = 1.0\n",
        "mp4_fps = 20\n",
        "num_frames = int(np.rint(duration_sec * mp4_fps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTqG8M0UZp45",
        "colab_type": "text"
      },
      "source": [
        "Define a couple helper functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNqVM9v_H-uH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_image_for_video(latent_vector):\n",
        "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
        "    generator.set_dlatents(latent_vector)\n",
        "    img_array = generator.generate_images()[0]\n",
        "\n",
        "    return img_array\n",
        "  \n",
        "  \n",
        "def move_for_video(latent_vector, direction, coeff):\n",
        "  \n",
        "  new_latent_vector = latent_vector.copy()\n",
        "  new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "  \n",
        "  img_array = generate_image(new_latent_vector)\n",
        "  \n",
        "  return img_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKZ6JFxXPPxA",
        "colab_type": "text"
      },
      "source": [
        "We need a directory to collect our output in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HWZ4N7JPAMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "184ax0za83lP",
        "colab_type": "text"
      },
      "source": [
        "Let's define a function for mixing latent vectors based on what frame we are on.  This is where the simple interpolation happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr7ffxv1U8Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_latent_mix(alpha):\n",
        "  coeff = (alpha%100)*0.01\n",
        "  seg=int(alpha/100)\n",
        "  if (seg==0):\n",
        "    leftChar=lionelRep\n",
        "    rightChar=mikeRep\n",
        "  if (seg==1):\n",
        "    leftChar=mikeRep\n",
        "    rightChar=bobRep\n",
        "  if (seg==2):\n",
        "    leftChar=bobRep\n",
        "    rightChar=mikeRep\n",
        "  return (1-coeff)*leftChar + coeff*rightChar\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWEqHVdsXOGQ",
        "colab_type": "text"
      },
      "source": [
        "A simple test mixing Mike and Bob at around 50% each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uKD8SnRTEk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_image(get_latent_mix(255))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68Bw3TPJZwYI",
        "colab_type": "text"
      },
      "source": [
        "Oh that's beautiful.\n",
        "\n",
        "Let's make a movie of the whole transformation.  When it's done, download the movie on the left bar, under the Files tab.  You should see interpolate.mp4 under stylegan/results/.  Double click it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DLZ7OCBIAEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# This creates an nd array that stores all the image frames fot cross-character interpolation\n",
        "src_images = np.stack(generate_image_for_video(get_latent_mix(alpha)) for alpha in range (300))\n",
        "\n",
        "def make_frame(t):\n",
        "    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
        "    src_image = src_images[frame_idx]\n",
        "    return np.array(src_image)\n",
        "\n",
        "# Generate video.\n",
        "import moviepy.editor\n",
        "mp4_file = 'results/interpolate.mp4'\n",
        "mp4_codec = 'libx264'\n",
        "mp4_bitrate = '5M'\n",
        "\n",
        "video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
        "video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5W1zkDMUUpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import os\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "def playvideo(filename):\n",
        "    video = io.open(filename, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return HTML(data='''<video alt=\"test\" controls>\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
        "                 </video>'''.format(encoded.decode('ascii')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukd9s2quS6pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp4 = \"/content/stylegan/results/interpolate.mp4\"\n",
        "if not os.path.exists(mp4):   \n",
        "    print(f\"- Sorry '{mp4}' does not yet exist.\")\n",
        "else:\n",
        "    print('- Run the next line to build the embedded video. You will need to click the arrow start.')\n",
        "    print('- Be patient.  It takes over a minute to render this ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvOxrpD4XMWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "playvideo(mp4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf0CKHFJSYNf",
        "colab_type": "text"
      },
      "source": [
        "### End of notebook."
      ]
    }
  ]
}