{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "least_squares.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4QiRDdVJhea",
        "colab_type": "text"
      },
      "source": [
        "# Least Squares (Linear) Regression\n",
        "\n",
        "- From [this Least Squares example](https://github.com/SergioRAgostinho/bootstrap-ml/blob/master/least_squares.ipynb) Notebook.\n",
        "    - Author:  [Sérgio Agostinho](https://www.linkedin.com/in/sergioagostinho)\n",
        "    - [Sérgio's GitHub repository](https://github.com/SergioRAgostinho/bootstrap-ml)\n",
        "\n",
        "Updated by [John Fogarty](https://github.com/jfogarty) for Python 3.6 and [Base2 MLI](https://github.com/base2solutions/mli) and [colab](https://colab.research.google.com) standalone evaluation.\n",
        "\n",
        "This was made from the [Bootstrap-ML](http://sergioagostinho.com/bootstrap-ml) workshop which took place on the 22nd of March 2018 at the Mathematics Department of [Instituto Superior Técnico](https://tecnico.ulisboa.pt/en/).\n",
        "\n",
        "This workshop, given by Sérgio Agostinh, was a two-hour introductory session in Machine Learning (ML)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLHofm9oJhed",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "We're going to tackle one of the most simple and yet powerful tool of Machine Learning, the Least Squares estimator. Given a function in the shape of \n",
        "\n",
        "\\begin{equation}\n",
        "\\hat y = w^T\\Phi\\left(x\\right) + b \\label{linear}\n",
        "\\end{equation}\n",
        "\n",
        "where $\\hat y, b \\in \\mathbb{R}$ and $\\Phi$ is a mapping from our input space to a given feature space such that $\\Phi: \\mathbb{R}^m \\to \\mathbb{R}^n$, we want to estimate the optimal $w$ which minimizes\n",
        "\n",
        "\\begin{equation}\n",
        "e = \\sum^{N}_{i = 1} \\left(y - \\hat y\\right)^2 \\label{sse}\n",
        "\\end{equation}\n",
        "\n",
        "## Problem: fit the a straight line through a number of points\n",
        "\n",
        "This is the most basic and common use case, so we need to see it in action. Let's generate a number of random points between $\\left[0, 1\\right]$ according to the following model\n",
        "\n",
        "\\begin{equation}\n",
        "y = 2x + 1 + e\n",
        "\\end{equation}\n",
        "\n",
        "where $e \\sim \\mathcal{N} \\left(0, 0.2^2\\right)$. In this case $w \\in \\mathbb{R}$ and is equal to $2$, $x \\in \\mathcal{U} \\left(0, 1\\right)$ and $b=1$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgdssYaVJhee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "\n",
        "n = 100\n",
        "x = np.random.uniform(size=n)\n",
        "e = np.random.normal(scale=0.4, size=n)\n",
        "y = 2*x + 1 + e\n",
        "\n",
        "#\n",
        "plt.scatter(x=x, y=y)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX9o97TnJheg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC3MndDEJhei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCRfGs9AJhel",
        "colab_type": "text"
      },
      "source": [
        "### How to find the best $w$ and $b$?\n",
        "\n",
        "Let's derive this one time so that you understand the most basic concepts of all these algorithms. We are interested in finding the weight vector $w$ which minimizes the sum of the square error\n",
        "\n",
        "\\begin{equation}\n",
        "\\underset{w}{\\operatorname{argmin}} e = \\sum^{N}_{i = 1} \\left(y_i - w^T \\Phi(x_i) - b \\right)^2 \n",
        "\\end{equation}\n",
        "\n",
        "We can augment $w$ such that $w_0 = b$ and $w \\in \\mathbb{R}^{n+1}$ and rerite the expression above as\n",
        "\n",
        "\\begin{equation}\n",
        "\\underset{w}{\\operatorname{argmin}} e = \\sum^{N}_{i = 1} \\left(y_i - w^T \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] \\right)^2 \n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Since the equation is linear, it has a closed-form solution. Let's start by finding the $w$ which gives as a null gradient. We're also going to make use of an important property of matrix derivatives, in this case applied to vectors\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{d x^Ta}{dx} =  a\n",
        "\\end{equation}\n",
        "\n",
        "for $a, x \\in \\mathbb{R}^n$.\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\frac{d}{dw} \\sum^{N}_{i = 1} \\left(y_i - w^T \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] \\right)^2  & = & 0 \\\\\n",
        "\\sum^{N}_{i = 1} \\frac{d}{dw} \\left(y_i - w^T \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] \\right)^2 & = & 0 \\\\\n",
        "\\sum^{N}_{i = 1} -2 \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] \\left(y_i - w^T \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] \\right) & = & 0 \\\\\n",
        "\\sum^{N}_{i = 1} \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] \\left(\\left[\\begin{matrix}\\Phi(x_i)^T & 1 \\end{matrix} \\right] w - y_i\\right) & = & 0 \\\\\n",
        "\\sum^{N}_{i = 1} \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] \\left[\\begin{matrix}\\Phi(x_i)^T & 1 \\end{matrix} \\right] w & = & \\sum^{N}_{i = 1} \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] y_i \\\\\n",
        "\\sum^{N}_{i = 1} \\left[\\begin{matrix}\\Phi(x_i)\\Phi(x_i)^T & \\Phi(x_i) \\\\ \\Phi(x_i)^T & 1 \\end{matrix} \\right] w & = & \\sum^{N}_{i = 1} \\left[\\begin{matrix}\\Phi(x_i) \\\\ 1 \\end{matrix} \\right] y_i \\\\\n",
        " \\left[\\begin{matrix}\\sum^{N}_{i = 1} \\Phi(x_i)\\Phi(x_i)^T & \\sum^{N}_{i = 1} \\Phi(x_i) \\\\ \\sum^{N}_{i = 1} \\Phi(x_i)^T & N \\end{matrix} \\right] w & = & \\left[\\begin{matrix} \\sum^{N}_{i = 1}\\Phi(x_i) y_i \\\\ \\sum^{N}_{i = 1}y_i \\end{matrix} \\right]\n",
        "\\end{eqnarray}\n",
        "\n",
        "resulting of course in\n",
        "\n",
        "\\begin{equation}\n",
        " w = \\left[\\begin{matrix}\\sum^{N}_{i = 1} \\Phi(x_i)\\Phi(x_i)^T & \\sum^{N}_{i = 1} \\Phi(x_i) \\\\ \\sum^{N}_{i = 1} \\Phi(x_i)^T & N \\end{matrix} \\right]^{-1}\\left[\\begin{matrix} \\sum^{N}_{i = 1}\\Phi(x_i) y_i \\\\ \\sum^{N}_{i = 1}y_i \\end{matrix} \\right]\\\\\n",
        "\\end{equation}\n",
        "\n",
        "Let's apply this proof to our case. First we need to figure what is what. We know the data was generated under the following model\n",
        "\n",
        "\\begin{equation}\n",
        "y = 2x + 1\n",
        "\\end{equation}\n",
        "\n",
        "plus some added noise. In this case the $\\Phi(x) = x$, $w = 2$ and $b = 1$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeIcXlC-Jhel",
        "colab_type": "text"
      },
      "source": [
        "## Numpy [linalg.solve](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html)\n",
        "\n",
        "We have a handy function available that solves exactly this kind of system, but we had to do a lot of math first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn-1MzjXJhem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array([[np.dot(x, x), np.sum(x)],[np.sum(x), n]])\n",
        "Y = np.array([np.dot(x,y), np.sum(y)])\n",
        "theta = np.linalg.solve(X,Y)\n",
        "print(theta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kwABdoXJheo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x, y, 'o', label='original data')\n",
        "plt.plot(x, theta[0]*x + theta[1], 'r', label='fitted line')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4vu4gRhJher",
        "colab_type": "text"
      },
      "source": [
        "## Scikit Learn [linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) \n",
        "\n",
        "Scikit already provides linear regression capabilities among others. So everything we went through could have been replaced by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMcy_aetJher",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(x.reshape(-1,1), y)\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "print('Intercept: \\n', regr.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMhnXfaxJhex",
        "colab_type": "text"
      },
      "source": [
        "Note that we needed to use [numpy reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) here so that our inputs to the fit function are a 2D matix \n",
        "\n",
        "See [this example for more on using sklearn linear models](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91D4uKQmJhey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"x's shape was {y.shape}\")\n",
        "print(f\"x is reshaped to {x.reshape(-1,1).shape}\")\n",
        "print(f\"y's shape is {y.shape}\")\n",
        "print(\"--So for each entry in Y we have an input vector in X containing exactly one item.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ457ZAEJhe1",
        "colab_type": "text"
      },
      "source": [
        "## Bonus math\n",
        "\n",
        "If you haven't had enough, feel free to note this nice equivalence in linear algebra using normal equations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNoyDZL5Jhe2",
        "colab_type": "text"
      },
      "source": [
        "### Normal Equations\n",
        "\n",
        "\\begin{equation}\n",
        " w = \\left[\\begin{matrix}\\sum^{N}_{i = 1} \\Phi(x_i)\\Phi(x_i)^T & \\sum^{N}_{i = 1} \\Phi(x_i)^T \\\\ \\sum^{N}_{i = 1} \\Phi(x_i) & N \\end{matrix} \\right]^{-1}\\left[\\begin{matrix} \\sum^{N}_{i = 1}\\Phi(x_i) y_i \\\\ \\sum^{N}_{i = 1}y_i \\end{matrix} \\right]\\\\\n",
        "\\end{equation}\n",
        "\n",
        "Can be written in another way commonly know as the **normal equations**. Just like before, consider you have $N$ samples and you stack your features and your target like this\n",
        "\n",
        "\\begin{equation}\n",
        "X =  \\left[\\begin{matrix}\\Phi(x_1)^T & \\dots  & 1 \\\\\n",
        "                         \\vdots    & \\ddots & \\vdots \\\\\n",
        "                         \\Phi(x_N)^T & \\dots  & 1 \\end{matrix}\\right]\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{y} =  \\left[\\begin{matrix} y_1 \\\\ \\vdots \\\\ y_N \\end{matrix}\\right]\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "The best $w$ is given by\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{w} = (X^TX)^{-1} X^T  \\textbf{y}\n",
        "\\end{equation}\n",
        "\n",
        "Let's test it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H58VjzhJhe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.matrix([x, np.ones(len(x))]).T\n",
        "Y = np.matrix(y).T\n",
        "print(\"X shape:\\n\", X.shape)\n",
        "print(\"Y shape:\\n\", Y.shape)\n",
        "\n",
        "w = np.linalg.solve(X.T * X, X.T * Y)\n",
        "print(\"w:\\n\", w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RNKiq0cJhe6",
        "colab_type": "text"
      },
      "source": [
        "## Bonus LinearRegression Example\n",
        "\n",
        "- [This example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) is pulled directly from the scikit-learn examples, and lightly edited to descr\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0bAGhhXJhe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the dataset and segment it into training and test sets.\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes = datasets.load_diabetes()\n",
        "\n",
        "print(f\"- Available features are : {diabetes.feature_names}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aabZPJbJhe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use only one feature,\n",
        "feature = 2\n",
        "print(f'- Using only feature #{feature} which is \"{diabetes.feature_names[feature]}\"')\n",
        "diabetes_X = diabetes.data[:, np.newaxis, feature]\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "diabetes_X_train = diabetes_X[:-20]\n",
        "diabetes_X_test  = diabetes_X[-20:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "diabetes_y_train = diabetes.target[:-20]\n",
        "diabetes_y_test  = diabetes.target[-20:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkoZvRZDJhfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build and train the model.\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(diabetes_X_train, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred = regr.predict(diabetes_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzG0Ddl4JhfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the results.\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
        "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQSUosnrJhfF",
        "colab_type": "text"
      },
      "source": [
        "### Explore the Diabetes data set\n",
        "\n",
        "Take a closer look that the content of the dataset using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YWfsENMJhfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = diabetes\n",
        "print(ds.DESCR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNHhQMoeJhfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRI89X4vJhfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "X = pd.DataFrame(ds['data'], columns=ds['feature_names'])\n",
        "Y = pd.DataFrame(ds['target'], columns=['target'])\n",
        "\n",
        "df = pd.DataFrame(np.c_[ds['data'], ds['target']],\n",
        "                  columns= np.append(ds['feature_names'], ['target']))\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C6wsebNJhfM",
        "colab_type": "text"
      },
      "source": [
        "### End of notebook."
      ]
    }
  ]
}